---
title: "Introducing Toolathlon"
---

<Tabs>

<Tab title="ğŸ‡ºğŸ‡¸ English">

Today, weâ€™re excited to announce the very first release of Toolathlon â€” a benchmark designed to quantitatively evaluate how well LLM agents perform on longâ€‘horizon tasks across diverse, realistic scenarios.

## Motivation

Over the past six months, weâ€™ve witnessed remarkable progress in LLM agents. Theyâ€™ve become significantly more capable in areas such as *vibe coding*, *deep research*, and *browsing*, delivering substantial convenience for users in these domains.

However, the real world is not limited to those use cases. Consider a few everyday examples:  

- As a teaching assistant, you might need to download studentsâ€™ Python assignments from your email inbox, run the scripts according to a grading rubric, and record the grades in Canvas endâ€‘toâ€‘end.  
- As an online shop owner on Shopify/WooCommerce, you might need to identify problematic items in orders, then email the relevant customers with a customized Google Form link for followâ€‘up.  
- As a web developer, you might need to deploy a service to a Kubernetes cluster, test it in a browser, and archive the test report in your remote GitHub repository.  

While none of these tasks are overly complex for a professional, they *are*:  

1. Tedious and detailâ€‘oriented,  
2. Hard for nonâ€‘experts to pick up quickly, and  
3. Ubiquitous in everyday workflows across many domains.  

On the other hand, we already have the core ingredients to let agents handle such workflows: powerful models (Claudeâ€‘4.5â€‘Sonnet, GPTâ€‘5, etc.) and the ability to connect them to realâ€‘world applications (via MCP, REST APIs, GUI control, etc.). This raises some natural questions:  

- In complex, realistic, and common multiâ€‘step tasks, how do different models actually perform?  
- How big are the performance gaps between them?  
- Can they really take a loosely defined task and deliver exactly the outcome we expect?  

Toolathlon was built to answer these questions. We drew from widely used, genuinely useful realâ€‘world scenarios from various applications â€” avoiding either trivially easy tasks for humans or purely artificial â€œgotchaâ€ challenges â€” and carefully created 108 tasks. Each task comes with fully verifiable scripts to check correctness. Most start from realistic initial states, rather than an empty state like blank documents or databases without any record.  

Through these tasks, we aim to provide fresh insight into the agentic capabilities of todayâ€™s LLMs, and make Toolathlon a compass for driving agents to better meet realâ€‘world needs.  

You can learn more on our website:  

- [Quick Start](https://toolathlon.xyz/docs/test)  
- [Framework Overview](https://toolathlon.xyz/docs/intro)  
- [Available MCPs](https://toolathlon.xyz/docs/selected)  
- [Custom Tool Integration](https://toolathlon.xyz/docs/self-impl)  
- [Task Structure](https://toolathlon.xyz/docs/dataset)  
- [Full Task Examples](https://toolathlon.xyz/docs/tasks/tech/17)  

## Model Performance

<img src="/figs/lb.png" alt="model_scores_comparison" style={{width: "100%", maxWidth: "800px", margin: "20px auto", display: "block"}} />

The results in the figure above are the average results and error bars of the model in three runs. The agent scaffold used is the openai-agent-sdk framework officially adopted by Tooalthlon.

## The Benchmark

Each task in Toolathlon has the following structure:

```
task/
â”œâ”€â”€ preprocess/ # Code for setting up the initial working state (optional)
â”œâ”€â”€ docs/ # Task instructions
	â”œâ”€â”€ task.md
	â””â”€â”€ agent_system_prompt.md
â”œâ”€â”€ initial_workspace/ # Files related to the local initial working state (optional)
â”œâ”€â”€ groundtruth_workspace/ # Files related to the standard answer (optional)
â”œâ”€â”€ evaluation/ # Code for testing the correctness of the task
	â”œâ”€â”€ main.py # Main evaluation script
	...
â”œâ”€â”€ ... # Other required resources (optional)
â””â”€â”€ task_config.json # Set up the tools and MCP server required for the task (optional)
```

As we can see, each task includes a strictly executable verification script. To enable these tasks to be solved by models, we adapted the openai-agent-sdk agent framework and added multiple MCP servers and common tools, allowing models to operate these applications and complete tasks within this framework.

The `task_config.json` file must contain at least the following two properties:

- `needed_mcp_servers` specifies the MCP servers that the agent may use.
- `needed_local_tools` specifies the custom toolkits that the agent may use.

## Task Examples


## Toolathlon Framework

To make our evaluation more realistic and easy to use, we designed the toolathlon framework as follows:

- **Multiple Language Model Support**: Compare OpenAI, Anthropic, Google, and open source models through a standardized API.

- **Autonomous Agent Design**: All functionality is provided as "tools," and models can manage their execution autonomously through prompts.

- **Error Handling**: Tool errors do not terminate the task, but instead return an error message, allowing the agent to retry or adjust its strategy.

- **Overlong Output Management**: Automatically truncates excessively long tool responses and provides paging/search tools to access the full content.

- **Context and History Management**: Provides tools for querying, deleting, and retrieving history, supporting long tasks that exceed the model context limit.

- **Containerized Isolation**: Each task can run in a separate Docker/Podman container, ensuring that tasks do not interfere with each other.

- **Parallel Execution**: Multiple processes batch run tasks, scalable linearly to additional computing resources, and ensuring stable and efficient large-scale evaluation.

- **State preservation and verification**: Save the complete workspace after the task is completed, and use the script to compare the results with the expectations.

</Tab>


<Tab title="ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡">

ä»Šå¤©ï¼Œæˆ‘ä»¬æ­£å¼å‘å¸ƒ Toolathlon çš„é¦–ä¸ªç‰ˆæœ¬â€”â€”ä¸€ä¸ªé¢å‘å¤šæ ·åŒ–çœŸå®åœºæ™¯ä¸éœ€æ±‚ã€ç”¨äºå®šé‡è¯„ä¼° LLM ä»£ç†åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­è¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚

## Motivation

åœ¨è¿‡å»çš„åŠå¹´å¤šæ—¶é—´é‡Œï¼Œæˆ‘ä»¬è§è¯äº†å„ç§å¤§æ¨¡å‹æ™ºèƒ½ä½“èƒ½åŠ›çš„æ˜¾è‘—æå‡ï¼Œå®ƒä»¬åœ¨æ°›å›´ç¼–ç¨‹ï¼ˆVibe Codingï¼‰ã€æ·±åº¦ç ”ç©¶ï¼ˆDeep Researchï¼‰ã€ä¿¡æ¯æµè§ˆä¸æ£€ç´¢ï¼ˆBrowingï¼‰ç­‰é¢†åŸŸå·²å±•ç°å‡ºé•¿è¶³çš„è¿›æ­¥ï¼Œå¹¶åœ¨ä¸Šè¿°é¢†åŸŸä¸­ä¸ºç”¨æˆ·å¸¦æ¥äº†æå¤§çš„ä¾¿åˆ©ã€‚  

ç„¶è€Œï¼Œç°å®ä¸–ç•Œä¸­çš„ä»»åŠ¡ä¸ä»…é™äºè¿™äº›é¢†åŸŸã€‚ä»¥ä¸‹æ˜¯å‡ ä¸ªç®€å•çš„ä¾‹å­ï¼š  

- ä½œä¸ºåŠ©æ•™ï¼Œä½ å¯èƒ½éœ€è¦ç«¯åˆ°ç«¯åœ°å®Œæˆä»é‚®ç®±ä¸‹è½½å­¦ç”Ÿçš„ Python ä½œä¸šã€ä¾æ®è¯„åˆ†æ‰‹å†Œè¿è¡Œç¨‹åºã€å¹¶åœ¨ Canvas ä¸Šæ‰“åˆ†ï¼›  
- ä½œä¸ºåœ¨çº¿å•†åº—åº—ä¸»ï¼Œä½ å¯èƒ½éœ€è¦ä»è®¢å•ä¸­æŸ¥æ‰¾å­˜åœ¨é—®é¢˜çš„å•†å“ï¼Œå¹¶å‘ç›¸å…³ç”¨æˆ·å‘é€åŒ…å«å®šåˆ¶è°·æ­Œé—®å·é“¾æ¥çš„é‚®ä»¶è¿›è¡Œæé†’ï¼›  
- ä½œä¸ºç½‘ç«™å¼€å‘è€…ï¼Œä½ å¯èƒ½éœ€è¦åœ¨ K8s é›†ç¾¤ä¸­éƒ¨ç½²æœåŠ¡ï¼Œæ‰“å¼€æµè§ˆå™¨è¿›è¡Œæµ‹è¯•ï¼Œå¹¶å°†æµ‹è¯•æŠ¥å‘ŠåŒæ­¥åˆ°è¿œç¨‹ GitHub ä»“åº“è¿›è¡Œå½’æ¡£ã€‚  

è¿™äº›ä»»åŠ¡å¹¶ä¸å¤æ‚ï¼Œäº‹å®ä¸Šå®ƒä»¬å¯¹äºä¸“ä¸šäººå£«éƒ½å¾ˆç›´æ¥ä¸”æ˜“æ‡‚çš„ï¼Œä½†æ˜¯è¿™äº›ä»»åŠ¡ä»ç„¶æ˜¯ï¼š1ï¼‰éœ€è¦ä»”ç»†æ“ä½œä¸”å¾ˆè€—è´¹ç²¾åŠ›çš„ 2ï¼‰å¯¹äºéä¸“ä¸šäººå£«éš¾ä»¥ä¸Šæ‰‹çš„ 3ï¼‰åœ¨çœŸå®ä¸–ç•Œä¸­æ¯å¤©éƒ½å¤§é‡å­˜åœ¨çš„ã€‚

å¦ä¸€æ–¹é¢ï¼Œäº‹å®ä¸Šç°åœ¨æˆ‘ä»¬å·²ç»å…·å¤‡äº†è®© Agent å®Œæˆä¸Šè¿°ä»»åŠ¡çš„æ ¸å¿ƒè¦ç´ ï¼šè¶³å¤Ÿèªæ˜çš„æ¨¡å‹ï¼ˆClaude-4.5-Sonnet, GPT-5ç­‰ï¼‰ï¼Œä»¥åŠè®©æ¨¡å‹è¿æ¥åˆ°çœŸå®ä¸–ç•Œå„ç±»åº”ç”¨çš„èƒ½åŠ›ï¼ˆå¦‚ MCPã€REST APIã€GUI ç­‰ï¼‰ã€‚å› æ­¤ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯â€”â€”åœ¨è¿™äº›å¤æ‚ï¼ŒçœŸå®ä¸”å¸¸è§çš„é•¿æµç¨‹ä»»åŠ¡ä¸­ï¼Œä¸åŒå¤§æ¨¡å‹çš„è¡¨ç°ç©¶ç«Ÿå¦‚ä½•ï¼Ÿå„ä¸ªæ¨¡å‹ä¹‹é—´çš„å·®è·æœ‰å¤šå¤§ï¼Ÿå®ƒä»¬æ˜¯å¦çœŸçš„èƒ½å¤Ÿåœ¨æ¥æ”¶åˆ°ä¸€ä¸ªä»»åŠ¡æŒ‡ä»¤ï¼ˆå³ä¾¿æŒ‡ä»¤å¹¶ä¸ååˆ†æ˜ç¡®ï¼‰åï¼Œå‡†ç¡®åœ°ä»¥æˆ‘ä»¬æœŸæœ›çš„æ–¹å¼å®Œæˆå·¥ä½œï¼Ÿ  

Toolathlon æ­£æ˜¯ä¸ºæ­¤è€Œè®¾è®¡ã€‚æˆ‘ä»¬åŸºäºå¤šç§å¸¸ç”¨çš„å¹¿æ³›æ”¶é›†äº†å„ç§çœŸå®å¯èƒ½å‘ç”Ÿï¼Œå¹¶ä¸”ç”¨æˆ·ç¡®å®æœ‰éœ€è¦å€ŸåŠ©å¤§æ¨¡å‹æ™ºèƒ½ä½“æ¥è§£å†³ï¼ˆè€Œéç”¨æˆ·è‡ªå·±å·²ç»å¯ä»¥è½»è€Œæ˜“ä¸¾çš„å®Œæˆï¼Œæˆ–è€…ç”¨å®Œå…¨ä¸çœŸå®çš„åœºæ™¯åˆ»æ„åˆéš¾å¤§æ¨¡å‹ï¼‰çš„åœºæ™¯éœ€æ±‚å¹¶ç²¾å¿ƒæ„å»ºäº† 108 ä¸ªä»»åŠ¡ã€‚æ¯ä¸ªä»»åŠ¡éƒ½é…å¤‡äº†å®Œå…¨å¯éªŒè¯çš„è„šæœ¬ï¼Œç”¨äºè¡¡é‡ä»»åŠ¡çš„æ‰§è¡Œæ­£è¯¯ã€‚å¤§å¤šæ•°ä»»åŠ¡éƒ½å»ºç«‹åœ¨çœŸå®çš„åˆå§‹çŠ¶æ€ä¹‹ä¸Šï¼Œè€Œä¸æ˜¯è®©æ¨¡å‹ä»ç©ºç™½æ–‡æ¡£æˆ–æ•°æ®åº“å¼€å§‹ã€‚  

é€šè¿‡è¿™äº›ä»»åŠ¡ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿä¸ºè¯„ä¼°å½“å‰æ¨¡å‹çš„æ™ºèƒ½ä½“èƒ½åŠ›å¸¦æ¥æ–°çš„æ´å¯Ÿï¼Œå¹¶è®©Toolathlonæˆä¸ºæŒ‡å¼• Agent ä¸æ–­æå‡ã€æ›´åŠ ç¬¦åˆçœŸå®åœºæ™¯éœ€æ±‚çš„æŒ‡å—é’ˆã€‚å…³äºToolathlonçš„è¯¦ç»†ä¿¡æ¯ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‚çœ‹ç«™å†…çš„å…¶ä»–é¡µé¢ï¼š[å¿«é€Ÿä¸Šæ‰‹](https://toolathlon.xyz/docs/test)ï¼Œ[æ¡†æ¶ä»‹ç»](https://toolathlon.xyz/docs/intro)ï¼Œ[å¯ç”¨MCP](https://toolathlon.xyz/docs/selected)ï¼Œ[è‡ªå®šä¹‰å·¥å…·](https://toolathlon.xyz/docs/self-impl)ï¼Œ[ä»»åŠ¡ç»“æ„](https://toolathlon.xyz/docs/dataset)ï¼Œä»¥åŠ[å…¨éƒ¨ä»»åŠ¡ç¤ºä¾‹](https://toolathlon.xyz/docs/tasks/tech/17)ã€‚

## Model Performance

<img src="/figs/lb.png" alt="model_scores_comparison" style={{width: "100%", maxWidth: "800px", margin: "20px auto", display: "block"}} />

ä¸Šå›¾ç»“æœå‡ä¸ºæ¨¡å‹åœ¨ä¸‰æ¬¡è¿è¡Œä¸­çš„å¹³å‡ç»“æœä¸è¯¯å·®æ¡ï¼Œæ‰€ç”¨agent scaffoldå‡ä¸ºTooalthlonå®˜æ–¹è§„å®šçš„åŸºäºopenai-agent-sdkçš„æ¡†æ¶ã€‚

#### The Benchmark

Toolathlonä¸­çš„æ¯ä¸ªä»»åŠ¡éƒ½åŒ…æ‹¬äº†å¦‚ä¸‹ç»“æ„ï¼š

```
task/
â”œâ”€â”€ preprocess/             # è®¾å®šåˆå§‹å·¥ä½œçŠ¶æ€çš„ä»£ç  ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ docs/                   # ä»»åŠ¡æŒ‡ä»¤
    â”œâ”€â”€ task.md
    â””â”€â”€ agent_system_prompt.md
â”œâ”€â”€ initial_workspace/      # æœ¬åœ°åˆå§‹å·¥ä½œçŠ¶æ€çš„ç›¸å…³æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ groundtruth_workspace/  # æ ‡å‡†ç­”æ¡ˆç›¸å…³æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ evaluation/             # æµ‹è¯•ä»»åŠ¡æ­£è¯¯çš„ä»£ç 
	â”œâ”€â”€ main.py				# ä¸»è¦è¯„ä¼°è„šæœ¬ 
	...
â”œâ”€â”€ ...                     # å…¶ä»–æ‰€éœ€èµ„æºï¼ˆå¯é€‰ï¼‰
â””â”€â”€ task_config.json        # è®¾ç½®è¯¥ä»»åŠ¡æ‰€éœ€çš„å·¥å…·ä¸MCPæœåŠ¡å™¨ï¼ˆå¯é€‰ï¼‰
```

å…¶ä¸­å¯ä»¥çœ‹åˆ°æ¯ä¸ªä»»åŠ¡éƒ½åŒ…å«ä¸€ä¸ªä¸¥æ ¼å¯æ‰§è¡Œçš„éªŒè¯è„šæœ¬ã€‚ä¸ºäº†è®©è¿™äº›ä»»åŠ¡å¯ä»¥è¢«æ¨¡å‹å®é™…è§£å†³ï¼Œæˆ‘ä»¬æ”¹ç¼–äº†openai-agent-sdkè¿™ä¸€æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå¹¶åŠ å…¥äº†å¤šä¸ªMCP serverå’Œå¸¸ç”¨å·¥å…·ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥åœ¨è¿™ä¸€æ¡†æ¶ä¸‹å®é™…æ“ä½œè¿™äº›åº”ç”¨ç¨‹åºå®Œæˆä»»åŠ¡ã€‚

`task_config.json` æ–‡ä»¶éœ€è¦è‡³å°‘åŒ…å«ä»¥ä¸‹ä¸¤ä¸ªå±æ€§ï¼š

- `needed_mcp_servers` æ™ºèƒ½ä½“å¯èƒ½ç”¨åˆ°çš„MCPæœåŠ¡å™¨
- `needed_local_tools` æ™ºèƒ½ä½“å¯èƒ½ç”¨åˆ°çš„æˆ‘ä»¬è‡ªè¡Œå®ç°çš„å·¥å…·åŒ…

## Task Examples


## Toolathlon Framework

ä¸ºäº†è®©æˆ‘ä»¬çš„æµ‹è¯„æ›´è´´è¿‘çœŸå®å¹¶ä¸”æ˜“ç”¨ï¼Œæˆ‘ä»¬å¯¹toolathlonçš„æ¡†æ¶è¿›è¡Œäº†å¦‚ä¸‹è®¾è®¡ï¼š

- **æ”¯æŒå¤šç§è¯­è¨€æ¨¡å‹**ï¼šé€šè¿‡æ ‡å‡†åŒ– APIï¼Œæ¯”å¯¹ OpenAIã€Anthropicã€Google åŠå¼€æºæ¨¡å‹ã€‚  
- **è‡ªä¸»æ™ºèƒ½ä½“è®¾è®¡**ï¼šä¸€åˆ‡åŠŸèƒ½éƒ½ä»¥â€œå·¥å…·â€å½¢å¼æä¾›ï¼Œæ¨¡å‹å¯é€šè¿‡æç¤ºè‡ªä¸»ç®¡ç†æ‰§è¡Œã€‚  
- **é”™è¯¯å¤„ç†**ï¼šå·¥å…·å‡ºé”™æ—¶ä¸ä¼šç»ˆæ­¢ä»»åŠ¡ï¼Œè€Œæ˜¯è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œå…è®¸æ™ºèƒ½ä½“è‡ªè¡Œé‡è¯•æˆ–è°ƒæ•´ç­–ç•¥ã€‚  
- **è¶…é•¿è¾“å‡ºç®¡ç†**ï¼šè‡ªåŠ¨æˆªæ–­è¶…é•¿å·¥å…·å“åº”ï¼Œå¹¶æä¾›åˆ†é¡µ/æœç´¢å·¥å…·è®¿é—®å®Œæ•´å†…å®¹ã€‚  
- **ä¸Šä¸‹æ–‡ä¸å†å²ç®¡ç†**ï¼šæä¾›æŸ¥è¯¢ã€åˆ é™¤å’Œæ£€ç´¢å†å²çš„å·¥å…·ï¼Œæ”¯æŒè¶…è¿‡æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶çš„é•¿ä»»åŠ¡ã€‚  
- **å®¹å™¨åŒ–éš”ç¦»**ï¼šæ¯ä¸ªä»»åŠ¡å¯åœ¨ç‹¬ç«‹çš„ Docker/Podman å®¹å™¨ä¸­è¿è¡Œï¼Œä¿è¯ä»»åŠ¡é—´äº’ä¸å¹²æ‰°ã€‚  
- **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¤šè¿›ç¨‹æ‰¹é‡è¿è¡Œä»»åŠ¡ï¼Œçº¿æ€§æ‰©å±•åˆ°æ›´å¤šè®¡ç®—èµ„æºï¼Œå¤§è§„æ¨¡è¯„æµ‹ç¨³å®šé«˜æ•ˆã€‚  
- **çŠ¶æ€ä¿å­˜ä¸éªŒè¯**ï¼šä»»åŠ¡ç»“æŸåä¿å­˜å®Œæ•´å·¥ä½œç©ºé—´ï¼Œç”¨è„šæœ¬å¯¹æ¯”ç»“æœä¸é¢„æœŸã€‚  

</Tab>

</Tabs>