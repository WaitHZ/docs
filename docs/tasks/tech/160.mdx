---
title: "Logical Datasets Collection"
description: "Generate a LaTeX table named datasets.tex listing five logical reasoning datasets with columns for task count, trainable flag, and adjustable difficulty flag."
mode: wide
---

<Card>
<div className="tools-container">
<div className="mcp-servers-container">
<div className="mcp-servers-title">
MCP Servers
</div>
<div className="mcp-servers-grid">
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><path fill="#010202" d="M201.5,22.5C253.575,18.8292,294.909,37.8292,325.5,79.5C348.846,76.447,370.846,80.6137,391.5,92C411.339,105.168,422.339,123.668,424.5,147.5C465.86,161.693,491.694,190.026,502,232.5C508.97,280.701,492.804,318.868,453.5,347C427.526,362.095,399.526,367.929,369.5,364.5C369.988,405.252,369.488,445.919,368,486.5C367.5,487,367,487.5,366.5,488C292.5,488.667,218.5,488.667,144.5,488C144,487.5,143.5,487,143,486.5C141.512,445.919,141.012,405.252,141.5,364.5C106.171,368.921,74.5043,360.421,46.5,339C10.3518,305.536-0.814861,265.036,13,217.5C22.2223,191.95,38.389,172.117,61.5,158C69.8007,153.681,78.134,149.681,86.5,146C92.1136,89.0861,121.447,50.0861,174.5,29C183.492,26.2401,192.492,24.0734,201.5,22.5Z"/></g><g><path fill="#a3d3fe" d="M204.5,36.5C254.543,34.185,292.876,54.0184,319.5,96C340.997,90.9721,361.664,93.3054,381.5,103C401.654,115.47,411.154,133.637,410,157.5C410.903,158.701,412.069,159.535,413.5,160C453.408,170.242,478.242,195.409,488,235.5C493.84,285.282,474.34,321.115,429.5,343C422.574,345.298,415.574,347.298,408.5,349C395.504,349.5,382.504,349.667,369.5,349.5C369.667,302.499,369.5,255.499,369,208.5C367.833,207.333,366.667,206.167,365.5,205C306.833,204.333,248.167,204.333,189.5,205C173,220.167,157.167,236,142,252.5C141.5,284.832,141.333,317.165,141.5,349.5C100.111,355.535,66.2777,342.535,40,310.5C17.3055,276.196,15.6388,240.863,35,204.5C50.4757,180.668,71.9757,165.002,99.5,157.5C101.376,109.215,123.042,73.0487,164.5,49C177.289,42.679,190.622,38.5123,204.5,36.5Z"/></g><g><path fill="#fefefe" d="M354.5,474.5C288.5,474.5,222.5,474.5,156.5,474.5C156.5,403.833,156.5,333.167,156.5,262.5C169.344,262.829,182.011,262.495,194.5,261.5C197.167,260.833,198.833,259.167,199.5,256.5C200.495,244.011,200.829,231.344,200.5,218.5C251.833,218.5,303.167,218.5,354.5,218.5C354.5,303.833,354.5,389.167,354.5,474.5Z"/></g><g><path fill="#979797" d="M354.5,474.5C354.5,389.167,354.5,303.833,354.5,218.5C303.167,218.5,251.833,218.5,200.5,218.5C200.829,231.344,200.495,244.011,199.5,256.5C199.5,243.5,199.5,230.5,199.5,217.5C251.5,217.5,303.5,217.5,355.5,217.5C355.833,303.335,355.499,389.002,354.5,474.5Z"/></g><g><path fill="#dce0e3" d="M185.5,247.5C179.31,247.823,173.31,247.49,167.5,246.5C173.13,240.369,178.964,234.369,185,228.5C185.5,234.825,185.666,241.158,185.5,247.5Z"/></g><g><path fill="#7b7d7e" d="M167.5,246.5C173.31,247.49,179.31,247.823,185.5,247.5C179.322,248.817,172.988,248.817,166.5,247.5C166.624,246.893,166.957,246.56,167.5,246.5Z"/></g><g><path fill="#a3a3a3" d="M194.5,261.5C182.011,262.495,169.344,262.829,156.5,262.5C156.5,333.167,156.5,403.833,156.5,474.5C155.501,403.669,155.167,332.669,155.5,261.5C168.5,261.5,181.5,261.5,194.5,261.5Z"/></g><g><path fill="#030303" d="M252.5,309.5C256.426,309.047,259.592,310.38,262,313.5C262.333,334.833,262.667,356.167,263,377.5C264.979,369.149,269.812,366.649,277.5,370C278.718,371.438,279.385,373.105,279.5,375C274.409,385.346,268.909,395.512,263,405.5C258,413.5,253,413.5,248,405.5C242.091,395.512,236.591,385.346,231.5,375C232.869,369.144,236.536,367.144,242.5,369C244.956,371.408,246.789,374.241,248,377.5C248.333,356.167,248.667,334.833,249,313.5C250.376,312.295,251.542,310.962,252.5,309.5Z"/></g><g><path fill="#050505" d="M199.5,376.5C203.888,375.943,207.055,377.61,209,381.5C209.5,398.83,209.667,416.163,209.5,433.5C240.167,433.5,270.833,433.5,301.5,433.5C301.333,416.163,301.5,398.83,302,381.5C304.553,376.374,308.386,375.207,313.5,378C314.126,378.75,314.626,379.584,315,380.5C315.667,401.5,315.667,422.5,315,443.5C314.626,444.416,314.126,445.25,313.5,446C294.254,447.155,274.921,447.655,255.5,447.5C236.079,447.655,216.746,447.155,197.5,446C196.874,445.25,196.374,444.416,196,443.5C195.333,422.5,195.333,401.5,196,380.5C196.69,378.65,197.856,377.316,199.5,376.5Z"/></g></svg>
<span className="mcp-server-name">fetch</span>
</div>
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48" width="20px" height="20px" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#1e88e5" d="M24,4C12.954,4,4,12.954,4,24s8.954,20,20,20s20-8.954,20-20S35.046,4,24,4z"/><path fill="#1565c0" d="M35,16.592v-3.878L37,11H27l0.917,1.833c-1.236,0-2.265,0-2.265,0S19.095,13,19.095,18.748	c0,5.752,5.732,5.088,5.732,5.088s0,0.865,0,1.453c0,0.594,0.77,0.391,0.864,1.583c-0.388,0-7.964-0.208-7.964,4.998	s6.679,4.959,6.679,4.959s7.722,0.365,7.722-6.104c0-3.871-4.405-5.121-4.405-6.686c0-1.563,3.319-2.012,3.319-5.684	c0-0.823-0.028-1.524-0.149-2.12L34,13.571v3.02c-0.581,0.207-1,0.756-1,1.408v4.5c0,0.829,0.672,1.5,1.5,1.5s1.5-0.671,1.5-1.5V18	C36,17.348,35.581,16.799,35,16.592z M30.047,31.169c0.131,2.024-1.929,3.811-4.603,3.998c-2.671,0.188-4.946-1.295-5.077-3.316	c-0.133-2.016,1.927-3.805,4.6-3.996C27.641,27.667,29.914,29.152,30.047,31.169z M26.109,22.453	c-1.592,0.451-3.375-1.062-3.982-3.367c-0.604-2.312,0.195-4.543,1.786-4.992c1.593-0.453,3.374,1.059,3.981,3.367	C28.499,19.77,27.702,22.004,26.109,22.453z"/><path fill="#e8eaf6" d="M34,16.592V12c0-0.051-0.015-0.097-0.029-0.143L35,11H21l-9,8h5.383	c0.174,5.466,5.715,4.836,5.715,4.836s0,0.865,0,1.453c0,0.594,0.771,0.391,0.865,1.583c-0.388,0-7.964-0.208-7.964,4.998	s6.679,4.959,6.679,4.959s7.721,0.365,7.721-6.104c0-3.871-4.404-5.121-4.404-6.686c0-1.563,3.318-2.012,3.318-5.684	c0-0.971-0.047-1.763-0.232-2.422L33,12.667v3.925c-0.581,0.207-1,0.756-1,1.408v4.5c0,0.829,0.672,1.5,1.5,1.5s1.5-0.671,1.5-1.5	V18C35,17.348,34.581,16.799,34,16.592z M28.319,31.169c0.131,2.024-1.928,3.811-4.602,3.998c-2.671,0.188-4.946-1.295-5.077-3.316	c-0.133-2.016,1.927-3.805,4.599-3.996C25.914,27.667,28.187,29.152,28.319,31.169z M24.38,22.453	c-1.591,0.451-3.373-1.062-3.981-3.367c-0.604-2.312,0.194-4.543,1.785-4.992c1.593-0.453,3.374,1.059,3.982,3.367	C26.77,19.77,25.973,22.004,24.38,22.453z"/></svg>
<span className="mcp-server-name">scholarly</span>
</div>
<div className="mcp-server-item">
<svg width="20px" height="20px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg>
<span className="mcp-server-name">pdf-tools</span>
</div>
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48" width="20px" height="20px" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#FFA000" d="M40,12H22l-4-4H8c-2.2,0-4,1.8-4,4v8h40v-4C44,13.8,42.2,12,40,12z"/><path fill="#FFCA28" d="M40,12H8c-2.2,0-4,1.8-4,4v20c0,2.2,1.8,4,4,4h32c2.2,0,4-1.8,4-4V16C44,13.8,42.2,12,40,12z"/></svg>
<span className="mcp-server-name">filesystem</span>
</div>
<div className="mcp-server-item">
<svg width="20" height="20" viewBox="0 0 17.732 24.269" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#bdb9b4" d="m6.565 9.368 2.266 2.738 6.674-7.84c.353-.47.52-.717.353-1.117a1.218 1.218 0 0 0-1.061-.748.953.953 0 0 0-.712.262Z"/><path fill="#b31b1b" d="M12.541 10.677 1.935.503a1.413 1.413 0 0 0-.834-.5 1.09 1.09 0 0 0-1.027.66c-.167.4-.047.681.319 1.206l8.44 10.242-6.282 7.716a1.336 1.336 0 0 0-.323 1.3 1.114 1.114 0 0 0 1.04.69.992.992 0 0 0 .748-.365l8.519-7.92a1.924 1.924 0 0 0 .006-2.855Z"/><path fill="#bdb9b4" d="M17.336 22.364 8.811 12.089 6.546 9.352l-1.389 1.254a2.063 2.063 0 0 0 0 2.965L15.969 23.99a.925.925 0 0 0 .742.282 1.039 1.039 0 0 0 .953-.667 1.261 1.261 0 0 0-.328-1.241Z"/></svg>
<span className="mcp-server-name">arxiv_local</span>
</div>
</div>
</div>
<div className="local-tools-container">
<div className="mcp-servers-title">
Local Tools
</div>
<div className="local-tools-grid">
<div className="local-tool-item">
<svg width="20px" height="20px" viewBox="0 0 100 100" enable-background="new 0 0 100 100" id="Layer_1" version="1.1" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><g><rect clip-rule="evenodd" fill="#F2F2F2" fill-rule="evenodd" height="83.437" width="67.025" x="9.012" y="7.604"/><path d="M77.454,92.458H7.595V6.187h69.859V92.458z M10.429,89.624H74.62V9.021H10.429V89.624z"/></g><g><rect clip-rule="evenodd" fill="#FF7C24" fill-rule="evenodd" height="10.481" width="17.952" x="46.695" y="34.866"/></g><g><rect height="2.834" width="19.463" x="20.504" y="35.575"/></g><g><rect height="2.834" width="15.561" x="20.718" y="42.508"/></g><g><rect height="2.833" width="15.562" x="20.813" y="49.514"/></g><g><rect height="2.833" width="27.128" x="20.718" y="56.753"/></g><g><rect height="2.833" width="23.51" x="20.718" y="63.688"/></g><g><rect clip-rule="evenodd" fill="#39B6CC" fill-rule="evenodd" height="9.004" width="44.095" x="20.553" y="19.064"/></g><g><rect height="2.833" width="26.272" x="20.718" y="70.32"/></g><g><rect height="2.834" width="32.8" x="20.718" y="77.253"/></g><g><rect height="2.834" width="3.235" x="38.304" y="42.508"/></g><g><path clip-rule="evenodd" d="M77.931,71.902l4.287,4.427l-6.644,6.437l-4.309-4.457    C74.147,76.998,76.504,74.726,77.931,71.902L77.931,71.902z" fill="#F2F2F2" fill-rule="evenodd"/><path d="M75.542,84.77l-6.692-6.92l1.828-0.831c2.579-1.174,4.706-3.218,5.989-5.756l0.897-1.776l6.656,6.874L75.542,84.77z     M73.584,78.669l2.023,2.091l4.605-4.463l-2.007-2.074C76.994,76.012,75.414,77.531,73.584,78.669z"/></g><g><polygon clip-rule="evenodd" fill="#39B6CC" fill-rule="evenodd" points="83.267,75.319 91.984,84.338 83.247,92.779     74.535,83.761   "/><path d="M83.213,94.783L72.531,83.726l10.771-10.41l10.687,11.056L83.213,94.783z M76.538,83.794l6.744,6.981l6.698-6.472    l-6.748-6.981L76.538,83.794z"/></g><g><path clip-rule="evenodd" d="M66.124,50.799c7.742,0,14.018,6.276,14.018,14.019    s-6.275,14.019-14.018,14.019c-7.743,0-14.019-6.276-14.019-14.019S58.381,50.799,66.124,50.799L66.124,50.799z" fill="#F2F2F2" fill-rule="evenodd"/><path d="M66.124,80.253c-8.511,0-15.435-6.924-15.435-15.435s6.924-15.435,15.435-15.435S81.56,56.307,81.56,64.818    S74.635,80.253,66.124,80.253z M66.124,52.216c-6.949,0-12.601,5.653-12.601,12.602s5.651,12.601,12.601,12.601    c6.948,0,12.602-5.652,12.602-12.601S73.072,52.216,66.124,52.216z"/></g><g><rect height="2.833" width="10.313" x="39.902" y="49.514"/></g><g><path d="M76.404,65.586H73.57c0-0.636-0.068-1.255-0.205-1.84c-0.043-0.186-0.096-0.385-0.169-0.63l2.717-0.808    c0.091,0.304,0.158,0.559,0.215,0.801C76.31,63.901,76.404,64.735,76.404,65.586z M72.438,61.433    c-1.489-2.5-4.203-4.058-7.084-4.061l0.004-2.834c3.871,0.005,7.518,2.091,9.516,5.445L72.438,61.433z"/></g></g></svg>
<span className="local-tool-name">history</span>
</div>
<div className="local-tool-item">
<svg height="20" width="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg>
<span className="local-tool-name">web_search</span>
</div>
<div className="local-tool-item">
<svg width="20px" height="20px" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M861.588238 240.133873v-65.792823c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.631049H314.659414v-65.631049c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.792823c-36.317212 0.868255-65.631049 30.539428-65.63105 67.061417v543.745565c0 37.06772 30.155471 67.223191 67.223191 67.223191h696.886045c37.06772 0 67.223191-30.155471 67.223191-67.223191V307.19529c-0.001024-36.52199-29.315885-66.193162-65.633097-67.061417z m-109.385765-65.792823c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m-546.928824 0c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m678.191947 676.600829c0 12.935767-10.532708 23.468476-23.468476 23.468475H163.111076c-12.935767 0-23.468476-10.532708-23.468476-23.468475V307.19529c0-12.402323 9.677764-22.593054 21.877358-23.415233v65.577807c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.631049h393.789368v65.631049c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.577807c12.19857 0.82218 21.877358 11.012911 21.877358 23.415233v543.746589z" fill="#22C67F" /><path d="M706.719439 478.272194l-48.01715-44.741741-182.28128 195.621482-111.468348-122.615387-48.563905 44.148911 159.469116 172.685427z" fill="#74E8AE" /></svg>
<span className="local-tool-name">claim_done</span>
</div>
<div className="local-tool-item">
<Icon icon="bars-progress" size={20} color="#4286f6" />
<span className="local-tool-name">manage_context</span>
</div>
<div className="local-tool-item">
<Icon icon="filter-list" size={20} color="#4286f6" />
<span className="local-tool-name">handle_overlong_tool_outputs</span>
</div>
</div>
</div>
</div>
</Card>







## Instruction

Hello! I am a PhD student engaged in deep learning research. Recently, my collaborators and I have proposed a logical reasoning dataset and are writing a paper to introduce this new dataset to the community. To demonstrate the differences between our work and previous work, I need you to help me summarize a latex table and save it in the workspace with name as `datasets.tex`, the tex file should only contain table content (no commented lines), without any other content. The table needs to include four columns: Dataset (dataset name), Tasks (number of tasks included in the dataset), Trainable (whether it includes a training set, filled with \ding\{55\} or \ding\{51\}), and Adjustable Difficulty (whether it includes different difficulty levels, filled with \ding\{55\} or \ding\{51\}). The table format is as follows:

```tex
\begin\{table\}[!ht]
    \begin\{center\}
    \begin\{tabular\}\{lccc\}
        \toprule
        Dataset & Tasks & Trainable & Adjustable Difficulty\\
        \midrule
        % content
        \bottomrule
    \end\{tabular\}
  \end\{center\}
\end\{table\}
```

The names of the datasets we need to include are (from top to bottom):
- BBH
- Zebra Logic
- KOR-Bench (# of tasks should based the broader categorization in the paper.)
- K&K (https://arxiv.org/abs/2410.23123)
- BBEH

## Model Trajectory

<AccordionGroup>
<Accordion title="gpt-5">

<Columns cols={3}>
<Card title="Task Completion" icon="check">
Completed
</Card>
<Card title="Tool Calls" icon="wrench">
8
</Card>
<Card title="Turns" icon="arrows-rotate">
9
</Card>
</Columns>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query":"Zebra Logic dataset logical reasoning benchmark zebra logic puzzles dataset \"Zebra Logic\"",
	 "num_results": 10
}

```

```json output_result
Title: ZebraLogic: Benchmarking the Logical Reasoning Ability ...
Link: https://huggingface.co/blog/yuchenlin/zebra-logic
Snippet: To evaluate the logical reasoning abilities of LLMs, we have created a benchmark named ZebraLogic. Each example is a Logic Grid Puzzle, also known as a Zebra ...
Sitelinks: No sitelinks

Title: Zebra Logic Bench - a Hugging Face Space by allenai
Link: https://huggingface.co/spaces/allenai/ZebraLogic
Snippet: This application displays a leaderboard for model evaluations, allowing users to filter models by mode and explore specific model predictions on zebra ...
Sitelinks: No sitelinks

Title: Logic.py: Bridging the Gap between LLMs and Constraint ...
Link: https://arxiv.org/html/2502.15776v1
Snippet: The validation function containing the constraints derived from the Zebra Logic clues is equally converted to a C representation, and embedded ...
Sitelinks: No sitelinks

Title: Bill Yuchen Lin
Link: https://x.com/billyuchenlin/status/1814254565128335705
Snippet: Introducing ZebraLogic, designed for evaluating LLMs with Logic Puzzles. Quick summary: Each example is a Zebra Puzzle (a type of Logic Grid Puzzles).
Sitelinks: No sitelinks

Title: e2-research#1: Entering the Next Phase of Cognitive Reasoning
Link: https://embraceable.ai/en/ankuendigung/e2-research1-entering-the-next-phase-of-cognitive-reasoning/
Snippet: To evaluate primarily logical performance, we use the established benchmark ZebraLogicBench from AllenAI (Ai2) & Stanford University, which investigates the ...
Sitelinks: No sitelinks

Title: LLMs reasoning // knowledge representation | by noailabs
Link: https://noailabs.medium.com/llms-reasoning-knowledge-representation-aec5916695c2
Snippet: To evaluate the logical reasoning abilities of LLMs, we have created a benchmark named ZebraLogic. Each example is a Logic Grid Puzzle, also ...
Sitelinks: No sitelinks

Title: 1 Introduction
Link: https://arxiv.org/html/2505.19641v4
Snippet: In this work, to address the gap in comprehensive logic tasks, we present SynLogic: a logical reasoning data synthesis framework and a ...
Sitelinks: No sitelinks

Title: Highlights by Bill Yuchen Lin (@billyuchenlin) ...
Link: https://mobile.x.com/billyuchenlin/highlights
Snippet: ) ⬇️ 1️⃣ It ranks 1st on GSM8K! 2️⃣ Its logical reasoning ability on ZebraLogic is quite similar to Sonnet 3.5, and much better than the others. (note that ...
Sitelinks: No sitelinks

Title: LLMs Project 1 Presentation | PDF | Logic | Cognitive Science
Link: https://www.scribd.com/document/873976944/LLMs-Project-1-Presentation
Snippet: Reviews prompting advanced reasoning puzzles into logic strategies (C-o-T ... with logic-heavy puzzles repeat errors like Zebra logic puzzles. Proposes ...
Sitelinks: No sitelinks

Title: LOGICEVOLVE: ADVANCING LOGICAL REASONING TO
Link: https://openreview.net/pdf/6089285418432b41c8b84bbe037604a3cb0a91b1.pdf
Snippet: This appendix presents the complete meta-data for all logical-reasoning puzzles. ... Logic ... zebralogic : The core of the Zebra Puzzle is to use deductive ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query":"ZebraLogic dataset number of puzzles how many examples ZebraLogic benchmark size",
	 "num_results": 10
}

```

```json output_result
Title: ZebraLogic: Benchmarking the Logical Reasoning Ability of ...
Link: https://huggingface.co/blog/yuchenlin/zebra-logic
Snippet: We programmatically created 1,000 such puzzles, with sizes ranging from 2x2 to 6x6, and there are 40 puzzles for each size. We test large ...
Sitelinks: No sitelinks

Title: ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning
Link: https://arxiv.org/html/2502.01100v1
Snippet: We create the ZebraLogic dataset, a benchmark of 1,000 logic grid puzzles spanning multiple complexity levels, designed to evaluate LLMs' ...
Sitelinks: No sitelinks

Title: ZebraLogic: A Logical Reasoning AI Benchmark Designed ... - i-genie
Link: https://i-genie.co.uk/zebralogic-a-logical-reasoning-ai-benchmark-designed-for-evaluating-llms-with-logic-puzzles/
Snippet: The ZebraLogic benchmark comprises 1,000 programmatically generated puzzles, ranging from 2×2 to 6×6 in size, with 40 puzzles per size category. Large ...
Sitelinks: No sitelinks

Title: [PDF] Probing the Limits of Reasoning Abilities in Large Language Models
Link: https://aclanthology.org/2025.acl-long.664.pdf
Snippet: It includes 4,250 newly generated puzzles in 12 for- mal difficulty classes and 42 sizes. While existing datasets control difficulty mainly based on the grid.
Sitelinks: No sitelinks

Title: ZebraLogic Benchmark - AI Performance for Builders - airank.dev
Link: https://airank.dev/benchmarks/zebralogic
Snippet: ZebraLogic is a comprehensive logical reasoning benchmark featuring 1,000 logic grid puzzles (Zebra puzzles) ranging from 2x2 to 6x6 complexity levels.
Sitelinks: No sitelinks

Title: A Logical Reasoning AI Benchmark Designed for Evaluating LLMs ...
Link: https://app.daily.dev/posts/zebralogic-a-logical-reasoning-ai-benchmark-designed-for-evaluating-llms-with-logic-puzzles-2eszu8nkq
Snippet: ZebraLogic is a benchmark designed to assess the logical reasoning skills of large language models (LLMs) using Logic Grid Puzzles.
Sitelinks: No sitelinks

Title: Logic.py: Bridging the Gap between LLMs and Constraint Solvers
Link: https://arxiv.org/html/2502.15776v1
Snippet: (2024) . ZebraLogicBench is a dataset of 1000 Logic Grid Puzzles, also referred to as Zebra Puzzles. These puzzles consist of a series of clues ...
Sitelinks: No sitelinks

Title: ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning
Link: https://www.researchgate.net/publication/388658069_ZebraLogic_On_the_Scaling_Limits_of_LLMs_for_Logical_Reasoning
Snippet: 1). Dataset Statistics. The dataset consists of 1,000 puzzles. where the size of the search space varies signiﬁcantly. The. puzzles are based ...
Sitelinks: No sitelinks

Title: Large language models struggle with logic puzzles - Facebook
Link: https://www.facebook.com/groups/DeepNetGroup/posts/2240236876369182/
Snippet: This synthetic dataset included 22,000 preference pairs, split between 17,000 prompts from the WildChat corpus and 5,000 mathematical queries.
Sitelinks: No sitelinks

Title: ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning
Link: https://openreview.net/forum?id=sTAJ9QyA6l
Snippet: We created ZebraLogic, a set of 1,000 logic grid puzzles, to test how well these models handle pure logical reasoning, similar to solving a ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query":"KOR-Bench broader categorization tasks KOR-Bench paper tasks categories KOR Bench dataset reasoning",
	 "num_results": 10
}

```

```json output_result
Title: KOR-Bench
Link: https://kor-bench.github.io/
Snippet: KOR-Bench contains five categories, each containing 25 manually defined rules that are suitably modified to ensure that they do not appear in common pre- ...
Sitelinks: No sitelinks

Title: [2410.06526] KOR-Bench: Benchmarking Language Models ... - arXiv
Link: https://arxiv.org/abs/2410.06526
Snippet: We propose the Knowledge-Orthogonal Reasoning Benchmark (KOR-Bench), encompassing five task categories: Operation, Logic, Cipher, Puzzle, and Counterfactual.
Sitelinks: No sitelinks

Title: [PDF] kor-bench: benchmarking language models - ICLR Proceedings
Link: https://proceedings.iclr.cc/paper_files/paper/2025/file/c6f5851a0d9cb435ed8b50e87bd6a257-Paper-Conference.pdf
Snippet: KOR-Bench contains five categories, each containing 25 manually defined rules that are suitably modified to ensure that they do not appear in common pre- ...
Sitelinks: No sitelinks

Title: KOR-Bench: Benchmarking Language Models on Knowledge ...
Link: https://huggingface.co/papers/2410.06526
Snippet: KOR-Bench evaluates models' reasoning capabilities by minimizing domain-specific knowledge impact across five task categories, revealing ...
Sitelinks: No sitelinks

Title: KOR-Bench for Evaluating Intrinsic Reasoning Abilities of Models
Link: https://www.2077ai.com/blog/kor-bench
Snippet: The knowledge orthogonality of the KOR-Bench dataset ensures that evaluation tasks are independent of pre-trained knowledge, requiring models to rely on their ...
Sitelinks: No sitelinks

Title: KOR-Bench: Benchmarking Language Models on Knowledge ...
Link: https://consensus.app/papers/korbench-benchmarking-language-models-on-wang-liu/ff4255f8a0795b1aa0f863c94a958b34/
Snippet: Abstract. In this paper, we introduce Knowledge-Orthogonal Reasoning (KOR), a concept aimed at minimizing reliance on domain-specific ...
Sitelinks: No sitelinks

Title: KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation
Link: https://www.researchgate.net/publication/391911820_KORGym_A_Dynamic_Game_Platform_for_LLM_Reasoning_Evaluation
Snippet: Using KORGym, we conduct extensive experiments on 19 LLMs and 8 VLMs, revealing consistent reasoning patterns within model families and ...
Sitelinks: No sitelinks

Title: [PDF] IFDECORATOR: Wrapping Instruction Following Reinforcement ...
Link: https://arxiv.org/pdf/2508.04632
Snippet: These include general reasoning (KOR-. Bench), math calculation (Math-500), and multi-turn con- versations (MT-Bench). The GA metric covers ...
Sitelinks: No sitelinks

Title: [Revue de papier] KOR-Bench: Benchmarking Language Models on ...
Link: https://www.themoonlight.io/fr/review/kor-bench-benchmarking-language-models-on-knowledge-orthogonal-reasoning-tasks
Snippet: KOR-BENCH Framework: KOR-Bench is structured around five main task categories, each focusing on different types of reasoning: Operation Reasoning: Involves ...
Sitelinks: No sitelinks

Title: [PDF] KRX Bench: Automating Financial Benchmark Creation via Large ...
Link: https://aclanthology.org/2024.finnlp-1.2.pdf
Snippet: To demonstrate the effectiveness of the pipeline, we create KRX-Bench-POC, a benchmark assessing the knowledge of LLMs in real-world companies.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><path fill="#010202" d="M201.5,22.5C253.575,18.8292,294.909,37.8292,325.5,79.5C348.846,76.447,370.846,80.6137,391.5,92C411.339,105.168,422.339,123.668,424.5,147.5C465.86,161.693,491.694,190.026,502,232.5C508.97,280.701,492.804,318.868,453.5,347C427.526,362.095,399.526,367.929,369.5,364.5C369.988,405.252,369.488,445.919,368,486.5C367.5,487,367,487.5,366.5,488C292.5,488.667,218.5,488.667,144.5,488C144,487.5,143.5,487,143,486.5C141.512,445.919,141.012,405.252,141.5,364.5C106.171,368.921,74.5043,360.421,46.5,339C10.3518,305.536-0.814861,265.036,13,217.5C22.2223,191.95,38.389,172.117,61.5,158C69.8007,153.681,78.134,149.681,86.5,146C92.1136,89.0861,121.447,50.0861,174.5,29C183.492,26.2401,192.492,24.0734,201.5,22.5Z"/></g><g><path fill="#a3d3fe" d="M204.5,36.5C254.543,34.185,292.876,54.0184,319.5,96C340.997,90.9721,361.664,93.3054,381.5,103C401.654,115.47,411.154,133.637,410,157.5C410.903,158.701,412.069,159.535,413.5,160C453.408,170.242,478.242,195.409,488,235.5C493.84,285.282,474.34,321.115,429.5,343C422.574,345.298,415.574,347.298,408.5,349C395.504,349.5,382.504,349.667,369.5,349.5C369.667,302.499,369.5,255.499,369,208.5C367.833,207.333,366.667,206.167,365.5,205C306.833,204.333,248.167,204.333,189.5,205C173,220.167,157.167,236,142,252.5C141.5,284.832,141.333,317.165,141.5,349.5C100.111,355.535,66.2777,342.535,40,310.5C17.3055,276.196,15.6388,240.863,35,204.5C50.4757,180.668,71.9757,165.002,99.5,157.5C101.376,109.215,123.042,73.0487,164.5,49C177.289,42.679,190.622,38.5123,204.5,36.5Z"/></g><g><path fill="#fefefe" d="M354.5,474.5C288.5,474.5,222.5,474.5,156.5,474.5C156.5,403.833,156.5,333.167,156.5,262.5C169.344,262.829,182.011,262.495,194.5,261.5C197.167,260.833,198.833,259.167,199.5,256.5C200.495,244.011,200.829,231.344,200.5,218.5C251.833,218.5,303.167,218.5,354.5,218.5C354.5,303.833,354.5,389.167,354.5,474.5Z"/></g><g><path fill="#979797" d="M354.5,474.5C354.5,389.167,354.5,303.833,354.5,218.5C303.167,218.5,251.833,218.5,200.5,218.5C200.829,231.344,200.495,244.011,199.5,256.5C199.5,243.5,199.5,230.5,199.5,217.5C251.5,217.5,303.5,217.5,355.5,217.5C355.833,303.335,355.499,389.002,354.5,474.5Z"/></g><g><path fill="#dce0e3" d="M185.5,247.5C179.31,247.823,173.31,247.49,167.5,246.5C173.13,240.369,178.964,234.369,185,228.5C185.5,234.825,185.666,241.158,185.5,247.5Z"/></g><g><path fill="#7b7d7e" d="M167.5,246.5C173.31,247.49,179.31,247.823,185.5,247.5C179.322,248.817,172.988,248.817,166.5,247.5C166.624,246.893,166.957,246.56,167.5,246.5Z"/></g><g><path fill="#a3a3a3" d="M194.5,261.5C182.011,262.495,169.344,262.829,156.5,262.5C156.5,333.167,156.5,403.833,156.5,474.5C155.501,403.669,155.167,332.669,155.5,261.5C168.5,261.5,181.5,261.5,194.5,261.5Z"/></g><g><path fill="#030303" d="M252.5,309.5C256.426,309.047,259.592,310.38,262,313.5C262.333,334.833,262.667,356.167,263,377.5C264.979,369.149,269.812,366.649,277.5,370C278.718,371.438,279.385,373.105,279.5,375C274.409,385.346,268.909,395.512,263,405.5C258,413.5,253,413.5,248,405.5C242.091,395.512,236.591,385.346,231.5,375C232.869,369.144,236.536,367.144,242.5,369C244.956,371.408,246.789,374.241,248,377.5C248.333,356.167,248.667,334.833,249,313.5C250.376,312.295,251.542,310.962,252.5,309.5Z"/></g><g><path fill="#050505" d="M199.5,376.5C203.888,375.943,207.055,377.61,209,381.5C209.5,398.83,209.667,416.163,209.5,433.5C240.167,433.5,270.833,433.5,301.5,433.5C301.333,416.163,301.5,398.83,302,381.5C304.553,376.374,308.386,375.207,313.5,378C314.126,378.75,314.626,379.584,315,380.5C315.667,401.5,315.667,422.5,315,443.5C314.626,444.416,314.126,445.25,313.5,446C294.254,447.155,274.921,447.655,255.5,447.5C236.079,447.655,216.746,447.155,197.5,446C196.874,445.25,196.374,444.416,196,443.5C195.333,422.5,195.333,401.5,196,380.5C196.69,378.65,197.856,377.316,199.5,376.5Z"/></g></svg> `fetch fetch_json`

<Expandable title="Details">
```json arguments
{
	"url":"https://arxiv.org/abs/2410.23123"
}

```

```json output_result
Unexpected token '<', "<!DOCTYPE "... is not valid JSON
```

</Expandable>
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><path fill="#010202" d="M201.5,22.5C253.575,18.8292,294.909,37.8292,325.5,79.5C348.846,76.447,370.846,80.6137,391.5,92C411.339,105.168,422.339,123.668,424.5,147.5C465.86,161.693,491.694,190.026,502,232.5C508.97,280.701,492.804,318.868,453.5,347C427.526,362.095,399.526,367.929,369.5,364.5C369.988,405.252,369.488,445.919,368,486.5C367.5,487,367,487.5,366.5,488C292.5,488.667,218.5,488.667,144.5,488C144,487.5,143.5,487,143,486.5C141.512,445.919,141.012,405.252,141.5,364.5C106.171,368.921,74.5043,360.421,46.5,339C10.3518,305.536-0.814861,265.036,13,217.5C22.2223,191.95,38.389,172.117,61.5,158C69.8007,153.681,78.134,149.681,86.5,146C92.1136,89.0861,121.447,50.0861,174.5,29C183.492,26.2401,192.492,24.0734,201.5,22.5Z"/></g><g><path fill="#a3d3fe" d="M204.5,36.5C254.543,34.185,292.876,54.0184,319.5,96C340.997,90.9721,361.664,93.3054,381.5,103C401.654,115.47,411.154,133.637,410,157.5C410.903,158.701,412.069,159.535,413.5,160C453.408,170.242,478.242,195.409,488,235.5C493.84,285.282,474.34,321.115,429.5,343C422.574,345.298,415.574,347.298,408.5,349C395.504,349.5,382.504,349.667,369.5,349.5C369.667,302.499,369.5,255.499,369,208.5C367.833,207.333,366.667,206.167,365.5,205C306.833,204.333,248.167,204.333,189.5,205C173,220.167,157.167,236,142,252.5C141.5,284.832,141.333,317.165,141.5,349.5C100.111,355.535,66.2777,342.535,40,310.5C17.3055,276.196,15.6388,240.863,35,204.5C50.4757,180.668,71.9757,165.002,99.5,157.5C101.376,109.215,123.042,73.0487,164.5,49C177.289,42.679,190.622,38.5123,204.5,36.5Z"/></g><g><path fill="#fefefe" d="M354.5,474.5C288.5,474.5,222.5,474.5,156.5,474.5C156.5,403.833,156.5,333.167,156.5,262.5C169.344,262.829,182.011,262.495,194.5,261.5C197.167,260.833,198.833,259.167,199.5,256.5C200.495,244.011,200.829,231.344,200.5,218.5C251.833,218.5,303.167,218.5,354.5,218.5C354.5,303.833,354.5,389.167,354.5,474.5Z"/></g><g><path fill="#979797" d="M354.5,474.5C354.5,389.167,354.5,303.833,354.5,218.5C303.167,218.5,251.833,218.5,200.5,218.5C200.829,231.344,200.495,244.011,199.5,256.5C199.5,243.5,199.5,230.5,199.5,217.5C251.5,217.5,303.5,217.5,355.5,217.5C355.833,303.335,355.499,389.002,354.5,474.5Z"/></g><g><path fill="#dce0e3" d="M185.5,247.5C179.31,247.823,173.31,247.49,167.5,246.5C173.13,240.369,178.964,234.369,185,228.5C185.5,234.825,185.666,241.158,185.5,247.5Z"/></g><g><path fill="#7b7d7e" d="M167.5,246.5C173.31,247.49,179.31,247.823,185.5,247.5C179.322,248.817,172.988,248.817,166.5,247.5C166.624,246.893,166.957,246.56,167.5,246.5Z"/></g><g><path fill="#a3a3a3" d="M194.5,261.5C182.011,262.495,169.344,262.829,156.5,262.5C156.5,333.167,156.5,403.833,156.5,474.5C155.501,403.669,155.167,332.669,155.5,261.5C168.5,261.5,181.5,261.5,194.5,261.5Z"/></g><g><path fill="#030303" d="M252.5,309.5C256.426,309.047,259.592,310.38,262,313.5C262.333,334.833,262.667,356.167,263,377.5C264.979,369.149,269.812,366.649,277.5,370C278.718,371.438,279.385,373.105,279.5,375C274.409,385.346,268.909,395.512,263,405.5C258,413.5,253,413.5,248,405.5C242.091,395.512,236.591,385.346,231.5,375C232.869,369.144,236.536,367.144,242.5,369C244.956,371.408,246.789,374.241,248,377.5C248.333,356.167,248.667,334.833,249,313.5C250.376,312.295,251.542,310.962,252.5,309.5Z"/></g><g><path fill="#050505" d="M199.5,376.5C203.888,375.943,207.055,377.61,209,381.5C209.5,398.83,209.667,416.163,209.5,433.5C240.167,433.5,270.833,433.5,301.5,433.5C301.333,416.163,301.5,398.83,302,381.5C304.553,376.374,308.386,375.207,313.5,378C314.126,378.75,314.626,379.584,315,380.5C315.667,401.5,315.667,422.5,315,443.5C314.626,444.416,314.126,445.25,313.5,446C294.254,447.155,274.921,447.655,255.5,447.5C236.079,447.655,216.746,447.155,197.5,446C196.874,445.25,196.374,444.416,196,443.5C195.333,422.5,195.333,401.5,196,380.5C196.69,378.65,197.856,377.316,199.5,376.5Z"/></g></svg> `fetch fetch_markdown`

<Expandable title="Details">
```json arguments
{
	"url":"https://arxiv.org/abs/2410.23123"
}

```

```json output_result
\[2410.23123\] On Memorization of Large Language Models in Logical Reasoning                              

[Skip to main content](#content)

[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)

We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)

[](/IgnoreMe)

[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/) \> [cs](/list/cs/recent) \> arXiv:2410.23123

[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)

All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text

 Search

[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)

  [![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)

open search

   GO

open navigation menu

quick links
-----------

*   [Login](https://arxiv.org/login)
*   [Help Pages](https://info.arxiv.org/help)
*   [About](https://info.arxiv.org/about)

Computer Science > Computation and Language
===========================================

**arXiv:2410.23123** (cs)

\[Submitted on 30 Oct 2024 ([v1](https://arxiv.org/abs/2410.23123v1)), last revised 4 Mar 2025 (this version, v2)\]

Title:On Memorization of Large Language Models in Logical Reasoning
===================================================================

Authors:[Chulin Xie](https://arxiv.org/search/cs?searchtype=author&query=Xie,+C), [Yangsibo Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+Y), [Chiyuan Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+C), [Da Yu](https://arxiv.org/search/cs?searchtype=author&query=Yu,+D), [Xinyun Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+X), [Bill Yuchen Lin](https://arxiv.org/search/cs?searchtype=author&query=Lin,+B+Y), [Bo Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+B), [Badih Ghazi](https://arxiv.org/search/cs?searchtype=author&query=Ghazi,+B), [Ravi Kumar](https://arxiv.org/search/cs?searchtype=author&query=Kumar,+R)

View a PDF of the paper titled On Memorization of Large Language Models in Logical Reasoning, by Chulin Xie and 8 other authors

[View PDF](/pdf/2410.23123) [HTML (experimental)](https://arxiv.org/html/2410.23123v2)

> Abstract:Large language models (LLMs) achieve good performance on challenging reasoning benchmarks, yet could also make basic reasoning mistakes. This contrasting behavior is puzzling when it comes to understanding the mechanisms behind LLMs' reasoning capabilities. One hypothesis is that the increasingly high and nearly saturated performance on common reasoning benchmarks could be due to the memorization of similar problems. In this paper, we systematically investigate this hypothesis with a quantitative measurement of memorization in reasoning tasks, using a dynamically generated logical reasoning benchmark based on Knights and Knaves (K&K) puzzles. We find that LLMs could interpolate and memorize the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet they struggle with slight variations of these puzzles. On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance. Through in-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers, we establish that LLMs develop reasoning skills on K&K puzzles alongside memorization. Finally, our analysis based on a per-sample memorization score sheds light on how LLMs switch between reasoning and memorization when solving logical puzzles. Our code and data are available at [this https URL](https://memkklogic.github.io).

Subjects:

Computation and Language (cs.CL)

Cite as:

[arXiv:2410.23123](https://arxiv.org/abs/2410.23123) \[cs.CL\]

 

(or [arXiv:2410.23123v2](https://arxiv.org/abs/2410.23123v2) \[cs.CL\] for this version)

 

[https://doi.org/10.48550/arXiv.2410.23123](https://doi.org/10.48550/arXiv.2410.23123)

Focus to learn more

arXiv-issued DOI via DataCite

Submission history
------------------

From: Chulin Xie \[[view email](/show-email/d1541218/2410.23123)\]  
**[\[v1\]](/abs/2410.23123v1)** Wed, 30 Oct 2024 15:31:54 UTC (8,530 KB)  
**\[v2\]** Tue, 4 Mar 2025 06:22:40 UTC (9,623 KB)  

Full-text links:

Access Paper:
-------------

View a PDF of the paper titled On Memorization of Large Language Models in Logical Reasoning, by Chulin Xie and 8 other authors

*   [View PDF](/pdf/2410.23123)
*   [HTML (experimental)](https://arxiv.org/html/2410.23123v2)
*   [TeX Source](/src/2410.23123)
*   [Other Formats](/format/2410.23123)

[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ "Rights to this article")

Current browse context:

cs.CL

[< prev](/prevnext?id=2410.23123&function=prev&context=cs.CL "previous in cs.CL (accesskey p)")   |   [next >](/prevnext?id=2410.23123&function=next&context=cs.CL "next in cs.CL (accesskey n)")  

[new](/list/cs.CL/new) | [recent](/list/cs.CL/recent) | [2024-10](/list/cs.CL/2024-10)

Change to browse by:

[cs](/abs/2410.23123?context=cs)  

### References & Citations

*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.23123)
*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.23123)
*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.23123)

export BibTeX citation Loading...

BibTeX formatted citation
-------------------------

×

loading...

Data provided by:

### Bookmark

 [![BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2410.23123&description=On Memorization of Large Language Models in Logical Reasoning "Bookmark on BibSonomy")[![Reddit logo](/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2410.23123&title=On Memorization of Large Language Models in Logical Reasoning "Bookmark on Reddit")

 Bibliographic Tools

Bibliographic and Citation Tools
================================

 Bibliographic Explorer Toggle

Bibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_

 Connected Papers Toggle

Connected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_

 Litmaps Toggle

Litmaps _([What is Litmaps?](https://www.litmaps.co/))_

 scite.ai Toggle

scite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_

 Code, Data, Media

Code, Data and Media Associated with this Article
=================================================

 alphaXiv Toggle

alphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_

 Links to Code Toggle

CatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com))_

 DagsHub Toggle

DagsHub _([What is DagsHub?](https://dagshub.com/))_

 GotitPub Toggle

Gotit.pub _([What is GotitPub?](http://gotit.pub/faq))_

 Huggingface Toggle

Hugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_

 Links to Code Toggle

Papers with Code _([What is Papers with Code?](https://paperswithcode.com/))_

 ScienceCast Toggle

ScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_

 Demos

Demos
=====

 Replicate Toggle

Replicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_

 Spaces Toggle

Hugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_

 Spaces Toggle

TXYZ.AI _([What is TXYZ.AI?](https://txyz.ai))_

 Related Papers

Recommenders and Search Tools
=============================

 Link to Influence Flower

Influence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_

 Core recommender toggle

CORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_

*   Author
*   Venue
*   Institution
*   Topic

 About arXivLabs

arXivLabs: experimental projects with community collaborators
=============================================================

arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

Have an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).

[Which authors of this paper are endorsers?](/auth/show-endorsers/2410.23123) | [Disable MathJax](javascript:setMathjaxCookie\(\)) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))

mathjaxToggle();

*   [About](https://info.arxiv.org/about)
*   [Help](https://info.arxiv.org/help)

*   contact arXivClick here to contact arXiv [Contact](https://info.arxiv.org/help/contact.html)
*   subscribe to arXiv mailingsClick here to subscribe [Subscribe](https://info.arxiv.org/help/subscribe)

*   [Copyright](https://info.arxiv.org/help/license/index.html)
*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)

*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)
*   [arXiv Operational Status](https://status.arxiv.org)  
    Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)
```

</Expandable>
</div>

<div className="error-box">
⚠️ `fetch fetch_html`
<Expandable title="Details">
```json arguments
{
	"url":"https://arxiv.org/html/2410.23123v2"
}

```
```json error_message
{"type":"text","text":"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n<title>On Memorization of Large Language Models in Logical Reasoning</title>\n<!--Generated on Tue Mar  4 06:22:58 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->\n<meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n<link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n<link href=\"/static/browse/0.3.4/css/ar5iv.0.7.9.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n<link href=\"/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n<link href=\"/static/browse/0.3.4/css/latexml_styles.css\" rel=\"stylesheet\" type=\"text/css\"/>\n<script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js\"></script>\n<script src=\"/static/browse/0.3.4/js/addons_new.js\"></script>\n<script src=\"/static/browse/0.3.4/js/feedbackOverlay.js\"></script>\n<meta content=\"Machine Learning,  ICML\" lang=\"en\" name=\"keywords\"/>\n<base href=\"/html/2410.23123v2/\"/></head>\n<body>\n<nav class=\"ltx_page_navbar\">\n<nav class=\"ltx_TOC\">\n<ol class=\"ltx_toclist\">\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S1\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">1 </span>Introduction</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_section\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">2 </span>Measuring Memorization in Reasoning</span></a>\n<ol class=\"ltx_toclist ltx_toclist_section\">\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.SS1\" title=\"In 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">2.1 </span>Memorization Metrics for Reasoning Tasks</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.SS2\" title=\"In 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">2.2 </span>Knights and Knaves Reasoning Benchmark</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S3\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">3 </span>Quantifying Memorization in Reasoning</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_section\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">4 </span>Learn to Reason by Fine-tuning With Answers Only</span></a>\n<ol class=\"ltx_toclist ltx_toclist_section\">\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4.SS1\" title=\"In 4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">4.1 </span>Reasoning capabilities of Direct FT-ed model</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4.SS2\" title=\"In 4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">4.2 </span>Probing Direct FTed models</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4.SS3\" title=\"In 4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">4.3 </span>Direct FT with Wrong Answers</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S5\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">5 </span>Learn to Reason by Fine-tuning with CoTs</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S6\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">6 </span>Distinguish Memorization from Reasoning</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S7\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">7 </span>Related Work</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_section\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S8\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">8 </span>Conclusion</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_appendix\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A1\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">A </span>Discussion and Future Work</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_appendix\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A2\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">B </span>Extended Related Work</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_appendix\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C </span>Details on K&amp;K Benchmark</span></a>\n<ol class=\"ltx_toclist ltx_toclist_appendix\">\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS1\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.1 </span>The Abstract Representation</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS2\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.2 </span>The Abstract Puzzle Module: Generator</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS3\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.3 </span>The Abstract Puzzle Module: Solver and Reasoner</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS4\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.4 </span>The Abstract Puzzle Module: Perturber</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS5\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.5 </span>The Natural Language Module: NL-Generator</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS6\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.6 </span>The Natural Language Module: NL-Reasoner</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS7\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.7 </span>The Natural Language Module: NL-Perturber</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS8\" title=\"In Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">C.8 </span>Dataset Generation</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS8.SSS0.Px1\" title=\"In C.8 Dataset Generation ‣ Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">K&amp;K dataset</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A3.SS8.SSS0.Px2\" title=\"In C.8 Dataset Generation ‣ Appendix C Details on K&amp;K Benchmark ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Local perturbation</span></a></li>\n</ol>\n</li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_appendix\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D </span>Experimental Setups</span></a>\n<ol class=\"ltx_toclist ltx_toclist_appendix\">\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS1\" title=\"In Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.1 </span>Models</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2\" title=\"In Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2 </span>Experimental Details</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS1\" title=\"In D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2.1 </span>Evaluation</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS2\" title=\"In D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2.2 </span>Fine-tuning</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsubsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS2.Px1\" title=\"In D.2.2 Fine-tuning ‣ D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Training instance</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS2.Px2\" title=\"In D.2.2 Fine-tuning ‣ D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Training loss</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS2.Px3\" title=\"In D.2.2 Fine-tuning ‣ D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Training hyperparameters</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS2.Px4\" title=\"In D.2.2 Fine-tuning ‣ D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Reported Training accuracy</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS3\" title=\"In D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2.3 </span>Probing</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS4\" title=\"In D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2.4 </span>Distinguishing Memorization from Reasoning</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A4.SS2.SSS5\" title=\"In D.2 Experimental Details ‣ Appendix D Experimental Setups ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">D.2.5 </span>Computation Resources</span></a></li>\n</ol>\n</li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_appendix\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5\" title=\"In On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E </span>Additional Experimental Results</span></a>\n<ol class=\"ltx_toclist ltx_toclist_appendix\">\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS1\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.1 </span>Benchmark Performance of Off-the-shelf Models</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS1.SSS0.Px1\" title=\"In E.1 Benchmark Performance of Off-the-shelf Models ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Off-the-shelf models</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS2\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.2 </span>Memorization Measurement</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS2.SSS0.Px1\" title=\"In E.2 Memorization Measurement ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Fine-tuned models</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.3 </span>Evaluation on Reasoning Capability</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS1\" title=\"In E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.3.1 </span>Llama3-8B</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsubsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS1.Px1\" title=\"In E.3.1 Llama3-8B ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Accuracy over epochs</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS1.Px2\" title=\"In E.3.1 Llama3-8B ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Transferability</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS1.Px3\" title=\"In E.3.1 Llama3-8B ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Fine-tuning on 10<math alttext=\"k\" class=\"ltx_Math\" display=\"inline\"><semantics><mi>k</mi><annotation-xml encoding=\"MathML-Content\"><ci>𝑘</ci></annotation-xml><annotation encoding=\"application/x-tex\">k</annotation><annotation encoding=\"application/x-llamapun\">italic_k</annotation></semantics></math> 8-people K&amp;K samples</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS2\" title=\"In E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.3.2 </span>GPT4o-mini</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsubsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS2.Px1\" title=\"In E.3.2 GPT4o-mini ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Accuracy over epochs</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS2.Px2\" title=\"In E.3.2 GPT4o-mini ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Transferability</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS3.SSS2.Px3\" title=\"In E.3.2 GPT4o-mini ‣ E.3 Evaluation on Reasoning Capability ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Fine-tuning on 10<math alttext=\"k\" class=\"ltx_Math\" display=\"inline\"><semantics><mi>k</mi><annotation-xml encoding=\"MathML-Content\"><ci>𝑘</ci></annotation-xml><annotation encoding=\"application/x-tex\">k</annotation><annotation encoding=\"application/x-llamapun\">italic_k</annotation></semantics></math> 8-people K&amp;K samples</span></a></li>\n</ol>\n</li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS4\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.4 </span>Direct FT with Wrong Answers</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS4.SSS1\" title=\"In E.4 Direct FT with Wrong Answers ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.4.1 </span>Llama3-8B</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsubsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS4.SSS2\" title=\"In E.4 Direct FT with Wrong Answers ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.4.2 </span>GPT4o-mini</span></a></li>\n</ol>\n</li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS5\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.5 </span>Probing</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_subsection\">\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS6\" title=\"In Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\"><span class=\"ltx_tag ltx_tag_ref\">E.6 </span>Distinguishing Memorization from Reasoning</span></a>\n<ol class=\"ltx_toclist ltx_toclist_subsection\">\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS6.SSS0.Px1\" title=\"In E.6 Distinguishing Memorization from Reasoning ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Puzzle-based indicators</span></a></li>\n<li class=\"ltx_tocentry ltx_tocentry_paragraph\"><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.SS6.SSS0.Px2\" title=\"In E.6 Distinguishing Memorization from Reasoning ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_title\">Model-based indicators</span></a></li>\n</ol>\n</li>\n</ol>\n</li>\n</ol></nav>\n</nav>\n<div class=\"ltx_page_main\">\n<div class=\"ltx_page_content\">\n<article class=\"ltx_document ltx_pruned_first\">\n<h1 class=\"ltx_title ltx_title_document\">On Memorization of Large Language Models in Logical Reasoning</h1>\n<div class=\"ltx_authors\">\n<span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Chulin Xie\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Yangsibo Huang\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Chiyuan Zhang\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Da Yu\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Xinyun Chen\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Bill Yuchen Lin\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Bo Li\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Badih Ghazi\n</span></span>\n<span class=\"ltx_author_before\">  </span><span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Ravi Kumar\n</span></span>\n</div>\n<div class=\"ltx_abstract\">\n<h6 class=\"ltx_title ltx_title_abstract\">Abstract</h6>\n<p class=\"ltx_p\" id=\"id1.id1\">Large language models (LLMs) achieve good performance on challenging reasoning benchmarks, yet could also make basic reasoning mistakes. This contrasting behavior is puzzling when it comes to understanding the mechanisms behind LLMs’ reasoning capabilities. One hypothesis is that the increasingly high and nearly saturated performance on common reasoning benchmarks could be due to the memorization of similar problems. In this paper, we systematically investigate this hypothesis with a quantitative measurement of memorization in reasoning tasks, using a dynamically generated logical reasoning benchmark based on Knights and Knaves (K&amp;K) puzzles. We find that LLMs could interpolate and memorize the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet they struggle with slight variations of these puzzles. On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance. Through in-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers, we establish that LLMs develop reasoning skills on K&amp;K puzzles alongside memorization.\nFinally, our analysis based on a per-sample memorization score sheds light on how LLMs switch between reasoning and memorization when solving logical puzzles.</p>\n</div>\n<div class=\"ltx_keywords\">Machine Learning, ICML\n</div>\n<div class=\"ltx_para\" id=\"p2\">\n<br class=\"ltx_break\"/>\n</div>\n<section class=\"ltx_section\" id=\"S1\">\n<h2 class=\"ltx_title ltx_title_section\">\n<span class=\"ltx_tag ltx_tag_section\">1 </span>Introduction</h2>\n<div class=\"ltx_para\" id=\"S1.p1\">\n<p class=\"ltx_p\" id=\"S1.p1.1\">Modern Large Language Models (LLMs) show impressive reasoning capabilities\nthat allow them to solve a wide range of challenging problems including commonsense reasoning and mathematical reasoning.\nIn the meantime, LLMs also make mistakes on some of the most basic problems, such as comparing which number is bigger—13.11 or 13.8 <cite class=\"ltx_cite ltx_citemacro_citep\">(Lin, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib35\" title=\"\">2024</a>)</cite>, and counting the number of sisters that Alice’s brother has <cite class=\"ltx_cite ltx_citemacro_citep\">(Nezhurina et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib46\" title=\"\">2024</a>)</cite>.\nThis contrast is puzzling when it comes to understanding how exactly LLMs solve reasoning tasks. This question is important both scientifically and practically: understanding how LLMs reason could shed light on their learning and generalization behaviors. It is also crucial for real-world applications where robust reasoning is required due to safety\nand trustworthiness concerns <cite class=\"ltx_cite ltx_citemacro_citep\">(Wang et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib66\" title=\"\">2023a</a>; Wallace et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib64\" title=\"\">2024</a>; Lee et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib33\" title=\"\">2024</a>; Wei et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib70\" title=\"\">2024a</a>)</cite>.</p>\n</div>\n<div class=\"ltx_para\" id=\"S1.p2\">\n<p class=\"ltx_p\" id=\"S1.p2.1\">One hypothesis is that LLMs could be relying on <em class=\"ltx_emph ltx_font_italic\" id=\"S1.p2.1.1\">memorization</em> when solving those reasoning tasks, especially when measured by popular benchmarks that could be accidentally leaked into various massive internet-crawled pre-training datasets. Previous work <cite class=\"ltx_cite ltx_citemacro_citep\">(Tirumala et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib63\" title=\"\">2022</a>; Carlini et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib9\" title=\"\">2023</a>)</cite> show that LLMs could indeed memorize the training data, which may lead to potential privacy <cite class=\"ltx_cite ltx_citemacro_citep\">(Carlini et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib8\" title=\"\">2021</a>)</cite> or copyright <cite class=\"ltx_cite ltx_citemacro_citep\">(Karamolegkou et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib30\" title=\"\">2023</a>; Wei et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib71\" title=\"\">2024b</a>)</cite> concerns. Additional evidences of potential memorization come from extensive studies on data contamination in LLMs <cite class=\"ltx_cite ltx_citemacro_citep\">(Magar &amp; Schwartz, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib40\" title=\"\">2022</a>; Balloccu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib2\" title=\"\">2024</a>; Shi et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib60\" title=\"\">2024</a>; Xu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib76\" title=\"\">2024</a>; Oren et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib48\" title=\"\">2024</a>)</cite>. To mitigate the issue of benchmark saturation potentially due to memorization, some papers focus on designing dynamic benchmarks <cite class=\"ltx_cite ltx_citemacro_citep\">(Roberts et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib56\" title=\"\">2023</a>; Zhu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib85\" title=\"\">2024</a>; Srivastava et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib62\" title=\"\">2024</a>; Jain et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib26\" title=\"\">2024</a>; Wu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib74\" title=\"\">2024a</a>)</cite> or alternative evaluation protocols <cite class=\"ltx_cite ltx_citemacro_citep\">(Zeng et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib81\" title=\"\">2023</a>; Zhang et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib82\" title=\"\">2024</a>; Xu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib76\" title=\"\">2024</a>; Srivastava et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib62\" title=\"\">2024</a>)</cite>.</p>\n</div>\n<figure class=\"ltx_figure\" id=\"S1.F1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"252\" id=\"S1.F1.g1\" src=\"x1.png\" width=\"789\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 1: </span>\n<span class=\"ltx_text\" id=\"S1.F1.2.1\" style=\"font-size:90%;\">Illustration of the definition of Local Inconsistency based Memorization Score, <math alttext=\"\\mathsf{LiMem}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.F1.2.1.m1.1\"><semantics id=\"S1.F1.2.1.m1.1b\"><mi id=\"S1.F1.2.1.m1.1.1\" xref=\"S1.F1.2.1.m1.1.1.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><annotation-xml encoding=\"MathML-Content\" id=\"S1.F1.2.1.m1.1c\"><ci id=\"S1.F1.2.1.m1.1.1.cmml\" xref=\"S1.F1.2.1.m1.1.1\">𝖫𝗂𝖬𝖾𝗆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.F1.2.1.m1.1d\">\\mathsf{LiMem}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S1.F1.2.1.m1.1e\">sansserif_LiMem</annotation></semantics></math>. High level of memorization occurs when the model shows high accuracy in solving some problems but fails to consistently solve those problems under local perturbations that require similar underlying reasoning principles.\n</span></figcaption>\n</figure>\n<div class=\"ltx_para\" id=\"S1.p3\">\n<p class=\"ltx_p\" id=\"S1.p3.1\">In this paper, we take a direct approach to quantify the memorization behaviors of LLMs in reasoning tasks within a controlled setting. Specifically, we seek to understand: (i) whether LLMs rely on memorization to solve reasoning tasks, and (ii) whether memorization is only detrimental to learning to reason. Both questions are inspired by human behavior. For instance, when a student works hard on the preparation material for an exam, the preparation could help them get familiarized with the problems, and their ability to solve new problems could usually improve with enough exercises. However, without genuinely understanding the principles, they might fail when the same problem is slightly changed despite doing well on prepared problems.\nOur metric of memorization <math alttext=\"\\mathsf{LiMem}\" class=\"ltx_Math\" display=\"inline\" id=\"S1.p3.1.m1.1\"><semantics id=\"S1.p3.1.m1.1a\"><mi id=\"S1.p3.1.m1.1.1\" xref=\"S1.p3.1.m1.1.1.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><annotation-xml encoding=\"MathML-Content\" id=\"S1.p3.1.m1.1b\"><ci id=\"S1.p3.1.m1.1.1.cmml\" xref=\"S1.p3.1.m1.1.1\">𝖫𝗂𝖬𝖾𝗆</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.p3.1.m1.1c\">\\mathsf{LiMem}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S1.p3.1.m1.1d\">sansserif_LiMem</annotation></semantics></math>, illustrated in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S1.F1\" title=\"In 1 Introduction ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">Fig.</span> <span class=\"ltx_text ltx_ref_tag\">1</span></a>, is based on this intuition: an LLM shows a high level of memorization when it solves reasoning problems with high accuracy but struggles to consistently solve those problems under local perturbations requiring similar mathematical principles (i.e., low consistency).\nWe note that a similar perturbation (mostly at language-level) idea has been used in previous work, especially in detecting contamination <cite class=\"ltx_cite ltx_citemacro_citep\">(Golchin &amp; Surdeanu, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib19\" title=\"\">2023</a>; Yang et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib77\" title=\"\">2023</a>; Xu et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib76\" title=\"\">2024</a>)</cite>.\nHowever, given our focus on understanding memorization in logical reasoning tasks, we further consider problem-level perturbation that slightly changes the mathematical structure of a puzzle, in addition to language-level perturbations.\nTo facilitate our study, we propose a new logical reasoning benchmark that supports automatic problem-level perturbation.\nWith this tool, we evaluate the reasoning power of 17 off-the-shelf LLMs. We then fine-tune Llama3-8B and GPT4o-mini to quantify their memorization in reasoning tasks, and reveal interesting interplay: while models indeed tend to memorize many training logical puzzles, they also develop reasoning capabilities during fine-tuning (even directly on question-answer pairs without reasoning steps), and the reasoning performance improves when memorizing more training puzzles.</p>\n</div>\n<div class=\"ltx_para\" id=\"S1.p4\">\n<p class=\"ltx_p\" id=\"S1.p4.1\">In the following, we\nsummarize our key contributions:</p>\n<ul class=\"ltx_itemize\" id=\"S1.I1\">\n<li class=\"ltx_item\" id=\"S1.I1.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i1.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i1.p1.1\">To quantify memorization in reasoning tasks, we define a memorization score based on the notions of performance inconsistency under local perturbation, inspired by human behavior (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.SS1\" title=\"2.1 Memorization Metrics for Reasoning Tasks ‣ 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">2.1</span></a>).</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i2.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i2.p1.1\">To facilitate the measurement, we propose a new logical reasoning benchmark based on the <em class=\"ltx_emph ltx_font_italic\" id=\"S1.I1.i2.p1.1.1\">Knights and Knaves</em> <cite class=\"ltx_cite ltx_citemacro_citep\">(K&amp;K, Smullyan, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib61\" title=\"\">1978</a>; Johnson-Laird &amp; Byrne, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib29\" title=\"\">1990</a>)</cite> puzzles, that can generate new puzzles at different difficulty levels, locally perturb existing puzzles, and automatically synthesize detailed reasoning steps to solve a given puzzle (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.SS2\" title=\"2.2 Knights and Knaves Reasoning Benchmark ‣ 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">2.2</span></a>).</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i3.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i3.p1.1\">We show that K&amp;K puzzles are challenging, and only the most advanced LLMs could solve them well.\nMoreover, our analysis suggests those models exhibit some level of memorization (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S3\" title=\"3 Quantifying Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">3</span></a>).</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i4\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i4.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i4.p1.1\">By fine-tuning on K&amp;K samples, we confirm that modern LLMs are capable of memorizing a large collection of puzzles, and reach high memorization score when interpolating <cite class=\"ltx_cite ltx_citemacro_citep\">(i.e., fitting, Belkin et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib5\" title=\"\">2018</a>)</cite> the training set. We observe that the models’ generalization accuracies continue to improve as memorization grows (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4\" title=\"4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">4</span></a>).</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i5\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i5.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i5.p1.1\">We design various in-depth analyses (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4.SS1\" title=\"4.1 Reasoning capabilities of Direct FT-ed model ‣ 4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">4.1</span></a><math alttext=\"\\sim\" class=\"ltx_Math\" display=\"inline\" id=\"S1.I1.i5.p1.1.m1.1\"><semantics id=\"S1.I1.i5.p1.1.m1.1a\"><mo id=\"S1.I1.i5.p1.1.m1.1.1\" xref=\"S1.I1.i5.p1.1.m1.1.1.cmml\">∼</mo><annotation-xml encoding=\"MathML-Content\" id=\"S1.I1.i5.p1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S1.I1.i5.p1.1.m1.1.1.cmml\" xref=\"S1.I1.i5.p1.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.I1.i5.p1.1.m1.1c\">\\sim</annotation><annotation encoding=\"application/x-llamapun\" id=\"S1.I1.i5.p1.1.m1.1d\">∼</annotation></semantics></math><a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S4.SS3\" title=\"4.3 Direct FT with Wrong Answers ‣ 4 Learn to Reason by Fine-tuning With Answers Only ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">4.3</span></a>) to verify that LLMs developed improved reasoning capabilities (i.e., generalization)\nafter fine-tuning even with only question-answer pairs, via local perturbation tests, cross difficulty-level transferability, fine-tuning with wrong answers,\nand model internal probing.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i6\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i6.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i6.p1.1\">We show that fine-tuning with detailed reasoning steps can further boost the generalization on K&amp;K puzzles, even when fine-tuned with wrong reasoning steps (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S5\" title=\"5 Learn to Reason by Fine-tuning with CoTs ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">5</span></a>).</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i7\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">•</span>\n<div class=\"ltx_para\" id=\"S1.I1.i7.p1\">\n<p class=\"ltx_p\" id=\"S1.I1.i7.p1.1\">To analyze the interplay between memorization and reasoning, we measure per-sample memorization and study how LLMs switch between memorization and reasoning to solve a puzzle (<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S6\" title=\"6 Distinguish Memorization from Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">6</span></a>).</p>\n</div>\n</li>\n</ul>\n</div>\n</section>\n<section class=\"ltx_section\" id=\"S2\">\n<h2 class=\"ltx_title ltx_title_section\">\n<span class=\"ltx_tag ltx_tag_section\">2 </span>Measuring Memorization in Reasoning</h2>\n<section class=\"ltx_subsection\" id=\"S2.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\">\n<span class=\"ltx_tag ltx_tag_subsection\">2.1 </span>Memorization Metrics for Reasoning Tasks</h3>\n<figure class=\"ltx_figure\" id=\"S2.F3\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top\" id=\"S2.F3.7\" style=\"width:273.2pt;\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"339\" id=\"S2.F3.1.g1\" src=\"x2.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 2: </span>\n<span class=\"ltx_text\" id=\"S2.F3.7.6.3\" style=\"font-size:90%;\">K&amp;K data generation framework employs abstract module and natural language module to generate question-answer pair and synthetic CoTs for each K&amp;K puzzle, based on the problem specification: number of persons (<math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.5.4.1.m1.1\"><semantics id=\"S2.F3.5.4.1.m1.1b\"><mi id=\"S2.F3.5.4.1.m1.1.1\" xref=\"S2.F3.5.4.1.m1.1.1.cmml\">N</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.F3.5.4.1.m1.1c\"><ci id=\"S2.F3.5.4.1.m1.1.1.cmml\" xref=\"S2.F3.5.4.1.m1.1.1\">𝑁</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.F3.5.4.1.m1.1d\">N</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.F3.5.4.1.m1.1e\">italic_N</annotation></semantics></math>), tree width (<math alttext=\"W\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.6.5.2.m2.1\"><semantics id=\"S2.F3.6.5.2.m2.1b\"><mi id=\"S2.F3.6.5.2.m2.1.1\" xref=\"S2.F3.6.5.2.m2.1.1.cmml\">W</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.F3.6.5.2.m2.1c\"><ci id=\"S2.F3.6.5.2.m2.1.1.cmml\" xref=\"S2.F3.6.5.2.m2.1.1\">𝑊</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.F3.6.5.2.m2.1d\">W</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.F3.6.5.2.m2.1e\">italic_W</annotation></semantics></math>), and depth (<math alttext=\"D\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F3.7.6.3.m3.1\"><semantics id=\"S2.F3.7.6.3.m3.1b\"><mi id=\"S2.F3.7.6.3.m3.1.1\" xref=\"S2.F3.7.6.3.m3.1.1.cmml\">D</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.F3.7.6.3.m3.1c\"><ci id=\"S2.F3.7.6.3.m3.1.1.cmml\" xref=\"S2.F3.7.6.3.m3.1.1\">𝐷</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.F3.7.6.3.m3.1d\">D</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.F3.7.6.3.m3.1e\">italic_D</annotation></semantics></math>).\nPerturbers in these modules can alter the math structure and language description, respectively, and recompute the question-answer pair.</span></figcaption>\n</figure>\n</div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top\" id=\"S2.F3.8\" style=\"width:151.8pt;\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"550\" id=\"S2.F3.8.g1\" src=\"x3.png\" width=\"831\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 3: </span>\n<span class=\"ltx_text\" id=\"S2.F3.8.2.1\" style=\"font-size:90%;\">Test acc of off-the-shelf LLMs under 0-shot direct prompting drops with increasing puzzle complexity. For reference, OpenAI o1 model with test-time compute achieves an acc of 0.86 on 8-ppl task and 0.67 on 18-ppl task.\n\n</span></figcaption>\n</figure>\n</div>\n</div>\n</figure>\n<div class=\"ltx_para\" id=\"S2.SS1.p1\">\n<p class=\"ltx_p\" id=\"S2.SS1.p1.1\">Memorization of LLMs has been studied in various contexts such as privacy <cite class=\"ltx_cite ltx_citemacro_citep\">(Carlini et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib9\" title=\"\">2023</a>)</cite>, copyright  <cite class=\"ltx_cite ltx_citemacro_citep\">(Carlini et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib8\" title=\"\">2021</a>; Karamolegkou et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib30\" title=\"\">2023</a>; Wei et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib71\" title=\"\">2024b</a>; He et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib22\" title=\"\">2024</a>)</cite>, and solving knowledge intensive tasks <cite class=\"ltx_cite ltx_citemacro_citep\">(Hartmann et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib21\" title=\"\">2023</a>)</cite>. In this paper, we are specifically interested in measuring the level of memorization when solving reasoning tasks, by borrowing intuition from human behavior.\nFor example, when preparing for an exam, a student may not be able to fully digest the underlying principles due to various reasons or constraints. But when (luckily) facing the same problem the student had prepared for, they would still be able to solve it. A key characteristic of this type of memorization is: (A) high accuracy on observed problems and (B) low accuracy when the problem is slightly changed.\nBased on this intuition, for a dataset <math alttext=\"\\mathcal{D}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.1.m1.1\"><semantics id=\"S2.SS1.p1.1.m1.1a\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.1.m1.1.1\" xref=\"S2.SS1.p1.1.m1.1.1.cmml\">𝒟</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.1.m1.1b\"><ci id=\"S2.SS1.p1.1.m1.1.1.cmml\" xref=\"S2.SS1.p1.1.m1.1.1\">𝒟</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.1.m1.1c\">\\mathcal{D}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.1.m1.1d\">caligraphic_D</annotation></semantics></math> of reasoning puzzles, we combine the following two quantities to measure memorization:</p>\n<ol class=\"ltx_enumerate\" id=\"S2.I1\">\n<li class=\"ltx_item\" id=\"S2.I1.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">1.</span>\n<div class=\"ltx_para\" id=\"S2.I1.i1.p1\">\n<p class=\"ltx_p\" id=\"S2.I1.i1.p1.6\">For (A), we measure the accuracy of a target model <math alttext=\"f\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.1.m1.1\"><semantics id=\"S2.I1.i1.p1.1.m1.1a\"><mi id=\"S2.I1.i1.p1.1.m1.1.1\" xref=\"S2.I1.i1.p1.1.m1.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.1.m1.1b\"><ci id=\"S2.I1.i1.p1.1.m1.1.1.cmml\" xref=\"S2.I1.i1.p1.1.m1.1.1\">𝑓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.1.m1.1c\">f</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.1.m1.1d\">italic_f</annotation></semantics></math> on <math alttext=\"\\mathcal{D}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.2.m2.1\"><semantics id=\"S2.I1.i1.p1.2.m2.1a\"><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.I1.i1.p1.2.m2.1.1\" xref=\"S2.I1.i1.p1.2.m2.1.1.cmml\">𝒟</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.2.m2.1b\"><ci id=\"S2.I1.i1.p1.2.m2.1.1.cmml\" xref=\"S2.I1.i1.p1.2.m2.1.1\">𝒟</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.2.m2.1c\">\\mathcal{D}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.2.m2.1d\">caligraphic_D</annotation></semantics></math>, denoted as <math alttext=\"\\mathsf{Acc}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.3.m3.2\"><semantics id=\"S2.I1.i1.p1.3.m3.2a\"><mrow id=\"S2.I1.i1.p1.3.m3.2.3\" xref=\"S2.I1.i1.p1.3.m3.2.3.cmml\"><mi id=\"S2.I1.i1.p1.3.m3.2.3.2\" xref=\"S2.I1.i1.p1.3.m3.2.3.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.I1.i1.p1.3.m3.2.3.1\" xref=\"S2.I1.i1.p1.3.m3.2.3.1.cmml\">⁢</mo><mrow id=\"S2.I1.i1.p1.3.m3.2.3.3.2\" xref=\"S2.I1.i1.p1.3.m3.2.3.3.1.cmml\"><mo id=\"S2.I1.i1.p1.3.m3.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.I1.i1.p1.3.m3.2.3.3.1.cmml\">(</mo><mi id=\"S2.I1.i1.p1.3.m3.1.1\" xref=\"S2.I1.i1.p1.3.m3.1.1.cmml\">f</mi><mo id=\"S2.I1.i1.p1.3.m3.2.3.3.2.2\" xref=\"S2.I1.i1.p1.3.m3.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.I1.i1.p1.3.m3.2.2\" xref=\"S2.I1.i1.p1.3.m3.2.2.cmml\">𝒟</mi><mo id=\"S2.I1.i1.p1.3.m3.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.I1.i1.p1.3.m3.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.3.m3.2b\"><apply id=\"S2.I1.i1.p1.3.m3.2.3.cmml\" xref=\"S2.I1.i1.p1.3.m3.2.3\"><times id=\"S2.I1.i1.p1.3.m3.2.3.1.cmml\" xref=\"S2.I1.i1.p1.3.m3.2.3.1\"></times><ci id=\"S2.I1.i1.p1.3.m3.2.3.2.cmml\" xref=\"S2.I1.i1.p1.3.m3.2.3.2\">𝖠𝖼𝖼</ci><list id=\"S2.I1.i1.p1.3.m3.2.3.3.1.cmml\" xref=\"S2.I1.i1.p1.3.m3.2.3.3.2\"><ci id=\"S2.I1.i1.p1.3.m3.1.1.cmml\" xref=\"S2.I1.i1.p1.3.m3.1.1\">𝑓</ci><ci id=\"S2.I1.i1.p1.3.m3.2.2.cmml\" xref=\"S2.I1.i1.p1.3.m3.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.3.m3.2c\">\\mathsf{Acc}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.3.m3.2d\">sansserif_Acc ( italic_f ; caligraphic_D )</annotation></semantics></math>. We are especially interested in measuring on the set of <em class=\"ltx_emph ltx_font_italic\" id=\"S2.I1.i1.p1.6.1\">observed puzzles</em>, i.e., the training set, <math alttext=\"\\mathsf{Acc}(f;\\mathsf{Tr})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.4.m4.2\"><semantics id=\"S2.I1.i1.p1.4.m4.2a\"><mrow id=\"S2.I1.i1.p1.4.m4.2.3\" xref=\"S2.I1.i1.p1.4.m4.2.3.cmml\"><mi id=\"S2.I1.i1.p1.4.m4.2.3.2\" xref=\"S2.I1.i1.p1.4.m4.2.3.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.I1.i1.p1.4.m4.2.3.1\" xref=\"S2.I1.i1.p1.4.m4.2.3.1.cmml\">⁢</mo><mrow id=\"S2.I1.i1.p1.4.m4.2.3.3.2\" xref=\"S2.I1.i1.p1.4.m4.2.3.3.1.cmml\"><mo id=\"S2.I1.i1.p1.4.m4.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.I1.i1.p1.4.m4.2.3.3.1.cmml\">(</mo><mi id=\"S2.I1.i1.p1.4.m4.1.1\" xref=\"S2.I1.i1.p1.4.m4.1.1.cmml\">f</mi><mo id=\"S2.I1.i1.p1.4.m4.2.3.3.2.2\" xref=\"S2.I1.i1.p1.4.m4.2.3.3.1.cmml\">;</mo><mi id=\"S2.I1.i1.p1.4.m4.2.2\" xref=\"S2.I1.i1.p1.4.m4.2.2.cmml\">𝖳𝗋</mi><mo id=\"S2.I1.i1.p1.4.m4.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.I1.i1.p1.4.m4.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.4.m4.2b\"><apply id=\"S2.I1.i1.p1.4.m4.2.3.cmml\" xref=\"S2.I1.i1.p1.4.m4.2.3\"><times id=\"S2.I1.i1.p1.4.m4.2.3.1.cmml\" xref=\"S2.I1.i1.p1.4.m4.2.3.1\"></times><ci id=\"S2.I1.i1.p1.4.m4.2.3.2.cmml\" xref=\"S2.I1.i1.p1.4.m4.2.3.2\">𝖠𝖼𝖼</ci><list id=\"S2.I1.i1.p1.4.m4.2.3.3.1.cmml\" xref=\"S2.I1.i1.p1.4.m4.2.3.3.2\"><ci id=\"S2.I1.i1.p1.4.m4.1.1.cmml\" xref=\"S2.I1.i1.p1.4.m4.1.1\">𝑓</ci><ci id=\"S2.I1.i1.p1.4.m4.2.2.cmml\" xref=\"S2.I1.i1.p1.4.m4.2.2\">𝖳𝗋</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.4.m4.2c\">\\mathsf{Acc}(f;\\mathsf{Tr})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.4.m4.2d\">sansserif_Acc ( italic_f ; sansserif_Tr )</annotation></semantics></math>. We say <math alttext=\"f\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.5.m5.1\"><semantics id=\"S2.I1.i1.p1.5.m5.1a\"><mi id=\"S2.I1.i1.p1.5.m5.1.1\" xref=\"S2.I1.i1.p1.5.m5.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.5.m5.1b\"><ci id=\"S2.I1.i1.p1.5.m5.1.1.cmml\" xref=\"S2.I1.i1.p1.5.m5.1.1\">𝑓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.5.m5.1c\">f</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.5.m5.1d\">italic_f</annotation></semantics></math> <span class=\"ltx_text ltx_font_italic\" id=\"S2.I1.i1.p1.6.2\">interpolates</span> <cite class=\"ltx_cite ltx_citemacro_citep\">(Belkin et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib5\" title=\"\">2018</a>; Muthukumar et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib45\" title=\"\">2020</a>; Belkin, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib4\" title=\"\">2021</a>; Bartlett et al., <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib3\" title=\"\">2021</a>)</cite> the training puzzles if <math alttext=\"\\mathsf{Acc}(f;\\mathsf{Tr})\\approx 100\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i1.p1.6.m6.2\"><semantics id=\"S2.I1.i1.p1.6.m6.2a\"><mrow id=\"S2.I1.i1.p1.6.m6.2.3\" xref=\"S2.I1.i1.p1.6.m6.2.3.cmml\"><mrow id=\"S2.I1.i1.p1.6.m6.2.3.2\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.cmml\"><mi id=\"S2.I1.i1.p1.6.m6.2.3.2.2\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.I1.i1.p1.6.m6.2.3.2.1\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.1.cmml\">⁢</mo><mrow id=\"S2.I1.i1.p1.6.m6.2.3.2.3.2\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.3.1.cmml\"><mo id=\"S2.I1.i1.p1.6.m6.2.3.2.3.2.1\" stretchy=\"false\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.3.1.cmml\">(</mo><mi id=\"S2.I1.i1.p1.6.m6.1.1\" xref=\"S2.I1.i1.p1.6.m6.1.1.cmml\">f</mi><mo id=\"S2.I1.i1.p1.6.m6.2.3.2.3.2.2\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.3.1.cmml\">;</mo><mi id=\"S2.I1.i1.p1.6.m6.2.2\" xref=\"S2.I1.i1.p1.6.m6.2.2.cmml\">𝖳𝗋</mi><mo id=\"S2.I1.i1.p1.6.m6.2.3.2.3.2.3\" stretchy=\"false\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.3.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.I1.i1.p1.6.m6.2.3.1\" xref=\"S2.I1.i1.p1.6.m6.2.3.1.cmml\">≈</mo><mrow id=\"S2.I1.i1.p1.6.m6.2.3.3\" xref=\"S2.I1.i1.p1.6.m6.2.3.3.cmml\"><mn id=\"S2.I1.i1.p1.6.m6.2.3.3.2\" xref=\"S2.I1.i1.p1.6.m6.2.3.3.2.cmml\">100</mn><mo id=\"S2.I1.i1.p1.6.m6.2.3.3.1\" xref=\"S2.I1.i1.p1.6.m6.2.3.3.1.cmml\">%</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i1.p1.6.m6.2b\"><apply id=\"S2.I1.i1.p1.6.m6.2.3.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3\"><approx id=\"S2.I1.i1.p1.6.m6.2.3.1.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.1\"></approx><apply id=\"S2.I1.i1.p1.6.m6.2.3.2.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.2\"><times id=\"S2.I1.i1.p1.6.m6.2.3.2.1.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.1\"></times><ci id=\"S2.I1.i1.p1.6.m6.2.3.2.2.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.2\">𝖠𝖼𝖼</ci><list id=\"S2.I1.i1.p1.6.m6.2.3.2.3.1.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.2.3.2\"><ci id=\"S2.I1.i1.p1.6.m6.1.1.cmml\" xref=\"S2.I1.i1.p1.6.m6.1.1\">𝑓</ci><ci id=\"S2.I1.i1.p1.6.m6.2.2.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.2\">𝖳𝗋</ci></list></apply><apply id=\"S2.I1.i1.p1.6.m6.2.3.3.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.3\"><csymbol cd=\"latexml\" id=\"S2.I1.i1.p1.6.m6.2.3.3.1.cmml\" xref=\"S2.I1.i1.p1.6.m6.2.3.3.1\">percent</csymbol><cn id=\"S2.I1.i1.p1.6.m6.2.3.3.2.cmml\" type=\"integer\" xref=\"S2.I1.i1.p1.6.m6.2.3.3.2\">100</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i1.p1.6.m6.2c\">\\mathsf{Acc}(f;\\mathsf{Tr})\\approx 100\\%</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i1.p1.6.m6.2d\">sansserif_Acc ( italic_f ; sansserif_Tr ) ≈ 100 %</annotation></semantics></math>.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S2.I1.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">2.</span>\n<div class=\"ltx_para\" id=\"S2.I1.i2.p1\">\n<p class=\"ltx_p\" id=\"S2.I1.i2.p1.1\">For (B), we measure a <em class=\"ltx_emph ltx_font_italic\" id=\"S2.I1.i2.p1.1.1\">consistency ratio</em> <math alttext=\"\\mathsf{CR}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.I1.i2.p1.1.m1.2\"><semantics id=\"S2.I1.i2.p1.1.m1.2a\"><mrow id=\"S2.I1.i2.p1.1.m1.2.3\" xref=\"S2.I1.i2.p1.1.m1.2.3.cmml\"><mi id=\"S2.I1.i2.p1.1.m1.2.3.2\" xref=\"S2.I1.i2.p1.1.m1.2.3.2.cmml\">𝖢𝖱</mi><mo id=\"S2.I1.i2.p1.1.m1.2.3.1\" xref=\"S2.I1.i2.p1.1.m1.2.3.1.cmml\">⁢</mo><mrow id=\"S2.I1.i2.p1.1.m1.2.3.3.2\" xref=\"S2.I1.i2.p1.1.m1.2.3.3.1.cmml\"><mo id=\"S2.I1.i2.p1.1.m1.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.I1.i2.p1.1.m1.2.3.3.1.cmml\">(</mo><mi id=\"S2.I1.i2.p1.1.m1.1.1\" xref=\"S2.I1.i2.p1.1.m1.1.1.cmml\">f</mi><mo id=\"S2.I1.i2.p1.1.m1.2.3.3.2.2\" xref=\"S2.I1.i2.p1.1.m1.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.I1.i2.p1.1.m1.2.2\" xref=\"S2.I1.i2.p1.1.m1.2.2.cmml\">𝒟</mi><mo id=\"S2.I1.i2.p1.1.m1.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.I1.i2.p1.1.m1.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.I1.i2.p1.1.m1.2b\"><apply id=\"S2.I1.i2.p1.1.m1.2.3.cmml\" xref=\"S2.I1.i2.p1.1.m1.2.3\"><times id=\"S2.I1.i2.p1.1.m1.2.3.1.cmml\" xref=\"S2.I1.i2.p1.1.m1.2.3.1\"></times><ci id=\"S2.I1.i2.p1.1.m1.2.3.2.cmml\" xref=\"S2.I1.i2.p1.1.m1.2.3.2\">𝖢𝖱</ci><list id=\"S2.I1.i2.p1.1.m1.2.3.3.1.cmml\" xref=\"S2.I1.i2.p1.1.m1.2.3.3.2\"><ci id=\"S2.I1.i2.p1.1.m1.1.1.cmml\" xref=\"S2.I1.i2.p1.1.m1.1.1\">𝑓</ci><ci id=\"S2.I1.i2.p1.1.m1.2.2.cmml\" xref=\"S2.I1.i2.p1.1.m1.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.I1.i2.p1.1.m1.2c\">\\mathsf{CR}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.I1.i2.p1.1.m1.2d\">sansserif_CR ( italic_f ; caligraphic_D )</annotation></semantics></math> between the number of <em class=\"ltx_emph ltx_font_italic\" id=\"S2.I1.i2.p1.1.2\">consistently solved puzzles</em> after some <em class=\"ltx_emph ltx_font_italic\" id=\"S2.I1.i2.p1.1.3\">local perturbations</em>,\nand the number of solved puzzles (without perturbation). We are interested in local perturbations that make minimal changes to the puzzle and maintain the same underlying principle for solving it, and a similar difficulty level (to be specified in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.SS2\" title=\"2.2 Knights and Knaves Reasoning Benchmark ‣ 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">§</span> <span class=\"ltx_text ltx_ref_tag\">2.2</span></a>).</p>\n</div>\n</li>\n</ol>\n<p class=\"ltx_p\" id=\"S2.SS1.p1.2\">We combine the two factors to define a <span class=\"ltx_text ltx_font_italic\" id=\"S2.SS1.p1.2.1\">Local Inconsistency-based Memorization Score</span> <math alttext=\"\\mathsf{LiMem}(f;\\mathcal{D})\\in[0,1]\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.2.m1.4\"><semantics id=\"S2.SS1.p1.2.m1.4a\"><mrow id=\"S2.SS1.p1.2.m1.4.5\" xref=\"S2.SS1.p1.2.m1.4.5.cmml\"><mrow id=\"S2.SS1.p1.2.m1.4.5.2\" xref=\"S2.SS1.p1.2.m1.4.5.2.cmml\"><mi id=\"S2.SS1.p1.2.m1.4.5.2.2\" xref=\"S2.SS1.p1.2.m1.4.5.2.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.SS1.p1.2.m1.4.5.2.1\" xref=\"S2.SS1.p1.2.m1.4.5.2.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.2.m1.4.5.2.3.2\" xref=\"S2.SS1.p1.2.m1.4.5.2.3.1.cmml\"><mo id=\"S2.SS1.p1.2.m1.4.5.2.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.2.m1.4.5.2.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.2.m1.1.1\" xref=\"S2.SS1.p1.2.m1.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.2.m1.4.5.2.3.2.2\" xref=\"S2.SS1.p1.2.m1.4.5.2.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.2.m1.2.2\" xref=\"S2.SS1.p1.2.m1.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p1.2.m1.4.5.2.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.2.m1.4.5.2.3.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.SS1.p1.2.m1.4.5.1\" xref=\"S2.SS1.p1.2.m1.4.5.1.cmml\">∈</mo><mrow id=\"S2.SS1.p1.2.m1.4.5.3.2\" xref=\"S2.SS1.p1.2.m1.4.5.3.1.cmml\"><mo id=\"S2.SS1.p1.2.m1.4.5.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.2.m1.4.5.3.1.cmml\">[</mo><mn id=\"S2.SS1.p1.2.m1.3.3\" xref=\"S2.SS1.p1.2.m1.3.3.cmml\">0</mn><mo id=\"S2.SS1.p1.2.m1.4.5.3.2.2\" xref=\"S2.SS1.p1.2.m1.4.5.3.1.cmml\">,</mo><mn id=\"S2.SS1.p1.2.m1.4.4\" xref=\"S2.SS1.p1.2.m1.4.4.cmml\">1</mn><mo id=\"S2.SS1.p1.2.m1.4.5.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.2.m1.4.5.3.1.cmml\">]</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.2.m1.4b\"><apply id=\"S2.SS1.p1.2.m1.4.5.cmml\" xref=\"S2.SS1.p1.2.m1.4.5\"><in id=\"S2.SS1.p1.2.m1.4.5.1.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.1\"></in><apply id=\"S2.SS1.p1.2.m1.4.5.2.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.2\"><times id=\"S2.SS1.p1.2.m1.4.5.2.1.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.2.1\"></times><ci id=\"S2.SS1.p1.2.m1.4.5.2.2.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.2.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.SS1.p1.2.m1.4.5.2.3.1.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.2.3.2\"><ci id=\"S2.SS1.p1.2.m1.1.1.cmml\" xref=\"S2.SS1.p1.2.m1.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.2.m1.2.2.cmml\" xref=\"S2.SS1.p1.2.m1.2.2\">𝒟</ci></list></apply><interval closure=\"closed\" id=\"S2.SS1.p1.2.m1.4.5.3.1.cmml\" xref=\"S2.SS1.p1.2.m1.4.5.3.2\"><cn id=\"S2.SS1.p1.2.m1.3.3.cmml\" type=\"integer\" xref=\"S2.SS1.p1.2.m1.3.3\">0</cn><cn id=\"S2.SS1.p1.2.m1.4.4.cmml\" type=\"integer\" xref=\"S2.SS1.p1.2.m1.4.4\">1</cn></interval></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.2.m1.4c\">\\mathsf{LiMem}(f;\\mathcal{D})\\in[0,1]</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.2.m1.4d\">sansserif_LiMem ( italic_f ; caligraphic_D ) ∈ [ 0 , 1 ]</annotation></semantics></math>:</p>\n<table class=\"ltx_equationgroup ltx_eqn_align ltx_eqn_table\" id=\"A5.EGx1\">\n<tbody id=\"S2.E1\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math alttext=\"\\displaystyle\\mathsf{LiMem}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.E1.m1.2\"><semantics id=\"S2.E1.m1.2a\"><mrow id=\"S2.E1.m1.2.3\" xref=\"S2.E1.m1.2.3.cmml\"><mi id=\"S2.E1.m1.2.3.2\" xref=\"S2.E1.m1.2.3.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.E1.m1.2.3.1\" xref=\"S2.E1.m1.2.3.1.cmml\">⁢</mo><mrow id=\"S2.E1.m1.2.3.3.2\" xref=\"S2.E1.m1.2.3.3.1.cmml\"><mo id=\"S2.E1.m1.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.E1.m1.2.3.3.1.cmml\">(</mo><mi id=\"S2.E1.m1.1.1\" xref=\"S2.E1.m1.1.1.cmml\">f</mi><mo id=\"S2.E1.m1.2.3.3.2.2\" xref=\"S2.E1.m1.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.E1.m1.2.2\" xref=\"S2.E1.m1.2.2.cmml\">𝒟</mi><mo id=\"S2.E1.m1.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.E1.m1.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.E1.m1.2b\"><apply id=\"S2.E1.m1.2.3.cmml\" xref=\"S2.E1.m1.2.3\"><times id=\"S2.E1.m1.2.3.1.cmml\" xref=\"S2.E1.m1.2.3.1\"></times><ci id=\"S2.E1.m1.2.3.2.cmml\" xref=\"S2.E1.m1.2.3.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.E1.m1.2.3.3.1.cmml\" xref=\"S2.E1.m1.2.3.3.2\"><ci id=\"S2.E1.m1.1.1.cmml\" xref=\"S2.E1.m1.1.1\">𝑓</ci><ci id=\"S2.E1.m1.2.2.cmml\" xref=\"S2.E1.m1.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.E1.m1.2c\">\\displaystyle\\mathsf{LiMem}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.E1.m1.2d\">sansserif_LiMem ( italic_f ; caligraphic_D )</annotation></semantics></math></td>\n<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math alttext=\"\\displaystyle=\\mathsf{Acc}(f;\\mathcal{D})\\cdot(1-\\mathsf{CR}(f;\\mathcal{D}))\" class=\"ltx_Math\" display=\"inline\" id=\"S2.E1.m2.5\"><semantics id=\"S2.E1.m2.5a\"><mrow id=\"S2.E1.m2.5.5\" xref=\"S2.E1.m2.5.5.cmml\"><mi id=\"S2.E1.m2.5.5.3\" xref=\"S2.E1.m2.5.5.3.cmml\"></mi><mo id=\"S2.E1.m2.5.5.2\" xref=\"S2.E1.m2.5.5.2.cmml\">=</mo><mrow id=\"S2.E1.m2.5.5.1\" xref=\"S2.E1.m2.5.5.1.cmml\"><mrow id=\"S2.E1.m2.5.5.1.3\" xref=\"S2.E1.m2.5.5.1.3.cmml\"><mi id=\"S2.E1.m2.5.5.1.3.2\" xref=\"S2.E1.m2.5.5.1.3.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.E1.m2.5.5.1.3.1\" xref=\"S2.E1.m2.5.5.1.3.1.cmml\">⁢</mo><mrow id=\"S2.E1.m2.5.5.1.3.3.2\" xref=\"S2.E1.m2.5.5.1.3.3.1.cmml\"><mo id=\"S2.E1.m2.5.5.1.3.3.2.1\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.3.3.1.cmml\">(</mo><mi id=\"S2.E1.m2.1.1\" xref=\"S2.E1.m2.1.1.cmml\">f</mi><mo id=\"S2.E1.m2.5.5.1.3.3.2.2\" xref=\"S2.E1.m2.5.5.1.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.E1.m2.2.2\" xref=\"S2.E1.m2.2.2.cmml\">𝒟</mi><mo id=\"S2.E1.m2.5.5.1.3.3.2.3\" rspace=\"0.055em\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.3.3.1.cmml\">)</mo></mrow></mrow><mo id=\"S2.E1.m2.5.5.1.2\" rspace=\"0.222em\" xref=\"S2.E1.m2.5.5.1.2.cmml\">⋅</mo><mrow id=\"S2.E1.m2.5.5.1.1.1\" xref=\"S2.E1.m2.5.5.1.1.1.1.cmml\"><mo id=\"S2.E1.m2.5.5.1.1.1.2\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.1.1.1.cmml\">(</mo><mrow id=\"S2.E1.m2.5.5.1.1.1.1\" xref=\"S2.E1.m2.5.5.1.1.1.1.cmml\"><mn id=\"S2.E1.m2.5.5.1.1.1.1.2\" xref=\"S2.E1.m2.5.5.1.1.1.1.2.cmml\">1</mn><mo id=\"S2.E1.m2.5.5.1.1.1.1.1\" xref=\"S2.E1.m2.5.5.1.1.1.1.1.cmml\">−</mo><mrow id=\"S2.E1.m2.5.5.1.1.1.1.3\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.cmml\"><mi id=\"S2.E1.m2.5.5.1.1.1.1.3.2\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.2.cmml\">𝖢𝖱</mi><mo id=\"S2.E1.m2.5.5.1.1.1.1.3.1\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.1.cmml\">⁢</mo><mrow id=\"S2.E1.m2.5.5.1.1.1.1.3.3.2\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.3.1.cmml\"><mo id=\"S2.E1.m2.5.5.1.1.1.1.3.3.2.1\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.3.1.cmml\">(</mo><mi id=\"S2.E1.m2.3.3\" xref=\"S2.E1.m2.3.3.cmml\">f</mi><mo id=\"S2.E1.m2.5.5.1.1.1.1.3.3.2.2\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.E1.m2.4.4\" xref=\"S2.E1.m2.4.4.cmml\">𝒟</mi><mo id=\"S2.E1.m2.5.5.1.1.1.1.3.3.2.3\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.3.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S2.E1.m2.5.5.1.1.1.3\" stretchy=\"false\" xref=\"S2.E1.m2.5.5.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.E1.m2.5b\"><apply id=\"S2.E1.m2.5.5.cmml\" xref=\"S2.E1.m2.5.5\"><eq id=\"S2.E1.m2.5.5.2.cmml\" xref=\"S2.E1.m2.5.5.2\"></eq><csymbol cd=\"latexml\" id=\"S2.E1.m2.5.5.3.cmml\" xref=\"S2.E1.m2.5.5.3\">absent</csymbol><apply id=\"S2.E1.m2.5.5.1.cmml\" xref=\"S2.E1.m2.5.5.1\"><ci id=\"S2.E1.m2.5.5.1.2.cmml\" xref=\"S2.E1.m2.5.5.1.2\">⋅</ci><apply id=\"S2.E1.m2.5.5.1.3.cmml\" xref=\"S2.E1.m2.5.5.1.3\"><times id=\"S2.E1.m2.5.5.1.3.1.cmml\" xref=\"S2.E1.m2.5.5.1.3.1\"></times><ci id=\"S2.E1.m2.5.5.1.3.2.cmml\" xref=\"S2.E1.m2.5.5.1.3.2\">𝖠𝖼𝖼</ci><list id=\"S2.E1.m2.5.5.1.3.3.1.cmml\" xref=\"S2.E1.m2.5.5.1.3.3.2\"><ci id=\"S2.E1.m2.1.1.cmml\" xref=\"S2.E1.m2.1.1\">𝑓</ci><ci id=\"S2.E1.m2.2.2.cmml\" xref=\"S2.E1.m2.2.2\">𝒟</ci></list></apply><apply id=\"S2.E1.m2.5.5.1.1.1.1.cmml\" xref=\"S2.E1.m2.5.5.1.1.1\"><minus id=\"S2.E1.m2.5.5.1.1.1.1.1.cmml\" xref=\"S2.E1.m2.5.5.1.1.1.1.1\"></minus><cn id=\"S2.E1.m2.5.5.1.1.1.1.2.cmml\" type=\"integer\" xref=\"S2.E1.m2.5.5.1.1.1.1.2\">1</cn><apply id=\"S2.E1.m2.5.5.1.1.1.1.3.cmml\" xref=\"S2.E1.m2.5.5.1.1.1.1.3\"><times id=\"S2.E1.m2.5.5.1.1.1.1.3.1.cmml\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.1\"></times><ci id=\"S2.E1.m2.5.5.1.1.1.1.3.2.cmml\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.2\">𝖢𝖱</ci><list id=\"S2.E1.m2.5.5.1.1.1.1.3.3.1.cmml\" xref=\"S2.E1.m2.5.5.1.1.1.1.3.3.2\"><ci id=\"S2.E1.m2.3.3.cmml\" xref=\"S2.E1.m2.3.3\">𝑓</ci><ci id=\"S2.E1.m2.4.4.cmml\" xref=\"S2.E1.m2.4.4\">𝒟</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.E1.m2.5c\">\\displaystyle=\\mathsf{Acc}(f;\\mathcal{D})\\cdot(1-\\mathsf{CR}(f;\\mathcal{D}))</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.E1.m2.5d\">= sansserif_Acc ( italic_f ; caligraphic_D ) ⋅ ( 1 - sansserif_CR ( italic_f ; caligraphic_D ) )</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(1)</span></td>\n</tr></tbody>\n<tbody id=\"S2.Ex1\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_eqn_cell\"></td>\n<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math alttext=\"\\displaystyle=\\frac{\\texttt{\\#Correct}-\\texttt{\\#Consistently\\_Correct}}{%\n\\texttt{\\#Total}}.\" class=\"ltx_Math\" display=\"inline\" id=\"S2.Ex1.m1.1\"><semantics id=\"S2.Ex1.m1.1a\"><mrow id=\"S2.Ex1.m1.1.1.1\" xref=\"S2.Ex1.m1.1.1.1.1.cmml\"><mrow id=\"S2.Ex1.m1.1.1.1.1\" xref=\"S2.Ex1.m1.1.1.1.1.cmml\"><mi id=\"S2.Ex1.m1.1.1.1.1.2\" xref=\"S2.Ex1.m1.1.1.1.1.2.cmml\"></mi><mo id=\"S2.Ex1.m1.1.1.1.1.1\" xref=\"S2.Ex1.m1.1.1.1.1.1.cmml\">=</mo><mstyle displaystyle=\"true\" id=\"S2.Ex1.m1.1.1.1.1.3\" xref=\"S2.Ex1.m1.1.1.1.1.3.cmml\"><mfrac id=\"S2.Ex1.m1.1.1.1.1.3a\" xref=\"S2.Ex1.m1.1.1.1.1.3.cmml\"><mrow id=\"S2.Ex1.m1.1.1.1.1.3.2\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.cmml\"><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.2.2\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.2a.cmml\">#Correct</mtext><mo id=\"S2.Ex1.m1.1.1.1.1.3.2.1\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.1.cmml\">−</mo><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.2.3\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.3a.cmml\">#Consistently_Correct</mtext></mrow><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.3\" xref=\"S2.Ex1.m1.1.1.1.1.3.3a.cmml\">#Total</mtext></mfrac></mstyle></mrow><mo id=\"S2.Ex1.m1.1.1.1.2\" lspace=\"0em\" xref=\"S2.Ex1.m1.1.1.1.1.cmml\">.</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.Ex1.m1.1b\"><apply id=\"S2.Ex1.m1.1.1.1.1.cmml\" xref=\"S2.Ex1.m1.1.1.1\"><eq id=\"S2.Ex1.m1.1.1.1.1.1.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.1\"></eq><csymbol cd=\"latexml\" id=\"S2.Ex1.m1.1.1.1.1.2.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.2\">absent</csymbol><apply id=\"S2.Ex1.m1.1.1.1.1.3.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3\"><divide id=\"S2.Ex1.m1.1.1.1.1.3.1.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3\"></divide><apply id=\"S2.Ex1.m1.1.1.1.1.3.2.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2\"><minus id=\"S2.Ex1.m1.1.1.1.1.3.2.1.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.1\"></minus><ci id=\"S2.Ex1.m1.1.1.1.1.3.2.2a.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.2\"><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.2.2.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.2\">#Correct</mtext></ci><ci id=\"S2.Ex1.m1.1.1.1.1.3.2.3a.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.3\"><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.2.3.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.2.3\">#Consistently_Correct</mtext></ci></apply><ci id=\"S2.Ex1.m1.1.1.1.1.3.3a.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.3\"><mtext class=\"ltx_mathvariant_monospace\" id=\"S2.Ex1.m1.1.1.1.1.3.3.cmml\" xref=\"S2.Ex1.m1.1.1.1.1.3.3\">#Total</mtext></ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.Ex1.m1.1c\">\\displaystyle=\\frac{\\texttt{\\#Correct}-\\texttt{\\#Consistently\\_Correct}}{%\n\\texttt{\\#Total}}.</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.Ex1.m1.1d\">= divide start_ARG #Correct - #Consistently_Correct end_ARG start_ARG #Total end_ARG .</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n</tr></tbody>\n</table>\n<p class=\"ltx_p\" id=\"S2.SS1.p1.8\">When there is no ambiguity, we call it the memorization score. A larger score provides stronger evidence of memorization (i.e., a larger proportion of memorized examples in the given dataset).\nSpecifically, a high <math alttext=\"\\mathsf{LiMem}(f;\\mathsf{Tr})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.3.m1.2\"><semantics id=\"S2.SS1.p1.3.m1.2a\"><mrow id=\"S2.SS1.p1.3.m1.2.3\" xref=\"S2.SS1.p1.3.m1.2.3.cmml\"><mi id=\"S2.SS1.p1.3.m1.2.3.2\" xref=\"S2.SS1.p1.3.m1.2.3.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.SS1.p1.3.m1.2.3.1\" xref=\"S2.SS1.p1.3.m1.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.3.m1.2.3.3.2\" xref=\"S2.SS1.p1.3.m1.2.3.3.1.cmml\"><mo id=\"S2.SS1.p1.3.m1.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.3.m1.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.3.m1.1.1\" xref=\"S2.SS1.p1.3.m1.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.3.m1.2.3.3.2.2\" xref=\"S2.SS1.p1.3.m1.2.3.3.1.cmml\">;</mo><mi id=\"S2.SS1.p1.3.m1.2.2\" xref=\"S2.SS1.p1.3.m1.2.2.cmml\">𝖳𝗋</mi><mo id=\"S2.SS1.p1.3.m1.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.3.m1.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.3.m1.2b\"><apply id=\"S2.SS1.p1.3.m1.2.3.cmml\" xref=\"S2.SS1.p1.3.m1.2.3\"><times id=\"S2.SS1.p1.3.m1.2.3.1.cmml\" xref=\"S2.SS1.p1.3.m1.2.3.1\"></times><ci id=\"S2.SS1.p1.3.m1.2.3.2.cmml\" xref=\"S2.SS1.p1.3.m1.2.3.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.SS1.p1.3.m1.2.3.3.1.cmml\" xref=\"S2.SS1.p1.3.m1.2.3.3.2\"><ci id=\"S2.SS1.p1.3.m1.1.1.cmml\" xref=\"S2.SS1.p1.3.m1.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.3.m1.2.2.cmml\" xref=\"S2.SS1.p1.3.m1.2.2\">𝖳𝗋</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.3.m1.2c\">\\mathsf{LiMem}(f;\\mathsf{Tr})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.3.m1.2d\">sansserif_LiMem ( italic_f ; sansserif_Tr )</annotation></semantics></math> matches the characteristic behavior of human memorizing observed puzzles, and in this case we say <math alttext=\"f\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.4.m2.1\"><semantics id=\"S2.SS1.p1.4.m2.1a\"><mi id=\"S2.SS1.p1.4.m2.1.1\" xref=\"S2.SS1.p1.4.m2.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.4.m2.1b\"><ci id=\"S2.SS1.p1.4.m2.1.1.cmml\" xref=\"S2.SS1.p1.4.m2.1.1\">𝑓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.4.m2.1c\">f</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.4.m2.1d\">italic_f</annotation></semantics></math> <span class=\"ltx_text ltx_font_italic\" id=\"S2.SS1.p1.8.1\">memorized</span> the training puzzles.\nNote that the <math alttext=\"\\mathsf{Acc}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.5.m3.2\"><semantics id=\"S2.SS1.p1.5.m3.2a\"><mrow id=\"S2.SS1.p1.5.m3.2.3\" xref=\"S2.SS1.p1.5.m3.2.3.cmml\"><mi id=\"S2.SS1.p1.5.m3.2.3.2\" xref=\"S2.SS1.p1.5.m3.2.3.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.SS1.p1.5.m3.2.3.1\" xref=\"S2.SS1.p1.5.m3.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.5.m3.2.3.3.2\" xref=\"S2.SS1.p1.5.m3.2.3.3.1.cmml\"><mo id=\"S2.SS1.p1.5.m3.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.5.m3.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.5.m3.1.1\" xref=\"S2.SS1.p1.5.m3.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.5.m3.2.3.3.2.2\" xref=\"S2.SS1.p1.5.m3.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.5.m3.2.2\" xref=\"S2.SS1.p1.5.m3.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p1.5.m3.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.5.m3.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.5.m3.2b\"><apply id=\"S2.SS1.p1.5.m3.2.3.cmml\" xref=\"S2.SS1.p1.5.m3.2.3\"><times id=\"S2.SS1.p1.5.m3.2.3.1.cmml\" xref=\"S2.SS1.p1.5.m3.2.3.1\"></times><ci id=\"S2.SS1.p1.5.m3.2.3.2.cmml\" xref=\"S2.SS1.p1.5.m3.2.3.2\">𝖠𝖼𝖼</ci><list id=\"S2.SS1.p1.5.m3.2.3.3.1.cmml\" xref=\"S2.SS1.p1.5.m3.2.3.3.2\"><ci id=\"S2.SS1.p1.5.m3.1.1.cmml\" xref=\"S2.SS1.p1.5.m3.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.5.m3.2.2.cmml\" xref=\"S2.SS1.p1.5.m3.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.5.m3.2c\">\\mathsf{Acc}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.5.m3.2d\">sansserif_Acc ( italic_f ; caligraphic_D )</annotation></semantics></math> factor is necessary, as there can be three types of behaviors: (i) solving by memorization, (ii) solving by reasoning, (iii) not solving (e.g., random guessing). A high <math alttext=\"\\mathsf{LiMem}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.6.m4.2\"><semantics id=\"S2.SS1.p1.6.m4.2a\"><mrow id=\"S2.SS1.p1.6.m4.2.3\" xref=\"S2.SS1.p1.6.m4.2.3.cmml\"><mi id=\"S2.SS1.p1.6.m4.2.3.2\" xref=\"S2.SS1.p1.6.m4.2.3.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.SS1.p1.6.m4.2.3.1\" xref=\"S2.SS1.p1.6.m4.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.6.m4.2.3.3.2\" xref=\"S2.SS1.p1.6.m4.2.3.3.1.cmml\"><mo id=\"S2.SS1.p1.6.m4.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.6.m4.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.6.m4.1.1\" xref=\"S2.SS1.p1.6.m4.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.6.m4.2.3.3.2.2\" xref=\"S2.SS1.p1.6.m4.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.6.m4.2.2\" xref=\"S2.SS1.p1.6.m4.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p1.6.m4.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.6.m4.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.6.m4.2b\"><apply id=\"S2.SS1.p1.6.m4.2.3.cmml\" xref=\"S2.SS1.p1.6.m4.2.3\"><times id=\"S2.SS1.p1.6.m4.2.3.1.cmml\" xref=\"S2.SS1.p1.6.m4.2.3.1\"></times><ci id=\"S2.SS1.p1.6.m4.2.3.2.cmml\" xref=\"S2.SS1.p1.6.m4.2.3.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.SS1.p1.6.m4.2.3.3.1.cmml\" xref=\"S2.SS1.p1.6.m4.2.3.3.2\"><ci id=\"S2.SS1.p1.6.m4.1.1.cmml\" xref=\"S2.SS1.p1.6.m4.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.6.m4.2.2.cmml\" xref=\"S2.SS1.p1.6.m4.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.6.m4.2c\">\\mathsf{LiMem}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.6.m4.2d\">sansserif_LiMem ( italic_f ; caligraphic_D )</annotation></semantics></math> indicates (i), but a low <math alttext=\"\\mathsf{LiMem}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.7.m5.2\"><semantics id=\"S2.SS1.p1.7.m5.2a\"><mrow id=\"S2.SS1.p1.7.m5.2.3\" xref=\"S2.SS1.p1.7.m5.2.3.cmml\"><mi id=\"S2.SS1.p1.7.m5.2.3.2\" xref=\"S2.SS1.p1.7.m5.2.3.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.SS1.p1.7.m5.2.3.1\" xref=\"S2.SS1.p1.7.m5.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.7.m5.2.3.3.2\" xref=\"S2.SS1.p1.7.m5.2.3.3.1.cmml\"><mo id=\"S2.SS1.p1.7.m5.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.7.m5.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.7.m5.1.1\" xref=\"S2.SS1.p1.7.m5.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.7.m5.2.3.3.2.2\" xref=\"S2.SS1.p1.7.m5.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.7.m5.2.2\" xref=\"S2.SS1.p1.7.m5.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p1.7.m5.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.7.m5.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.7.m5.2b\"><apply id=\"S2.SS1.p1.7.m5.2.3.cmml\" xref=\"S2.SS1.p1.7.m5.2.3\"><times id=\"S2.SS1.p1.7.m5.2.3.1.cmml\" xref=\"S2.SS1.p1.7.m5.2.3.1\"></times><ci id=\"S2.SS1.p1.7.m5.2.3.2.cmml\" xref=\"S2.SS1.p1.7.m5.2.3.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.SS1.p1.7.m5.2.3.3.1.cmml\" xref=\"S2.SS1.p1.7.m5.2.3.3.2\"><ci id=\"S2.SS1.p1.7.m5.1.1.cmml\" xref=\"S2.SS1.p1.7.m5.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.7.m5.2.2.cmml\" xref=\"S2.SS1.p1.7.m5.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.7.m5.2c\">\\mathsf{LiMem}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.7.m5.2d\">sansserif_LiMem ( italic_f ; caligraphic_D )</annotation></semantics></math> would only indicate (ii) if we separately check that <math alttext=\"\\mathsf{Acc}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p1.8.m6.2\"><semantics id=\"S2.SS1.p1.8.m6.2a\"><mrow id=\"S2.SS1.p1.8.m6.2.3\" xref=\"S2.SS1.p1.8.m6.2.3.cmml\"><mi id=\"S2.SS1.p1.8.m6.2.3.2\" xref=\"S2.SS1.p1.8.m6.2.3.2.cmml\">𝖠𝖼𝖼</mi><mo id=\"S2.SS1.p1.8.m6.2.3.1\" xref=\"S2.SS1.p1.8.m6.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p1.8.m6.2.3.3.2\" xref=\"S2.SS1.p1.8.m6.2.3.3.1.cmml\"><mo id=\"S2.SS1.p1.8.m6.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p1.8.m6.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p1.8.m6.1.1\" xref=\"S2.SS1.p1.8.m6.1.1.cmml\">f</mi><mo id=\"S2.SS1.p1.8.m6.2.3.3.2.2\" xref=\"S2.SS1.p1.8.m6.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p1.8.m6.2.2\" xref=\"S2.SS1.p1.8.m6.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p1.8.m6.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p1.8.m6.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p1.8.m6.2b\"><apply id=\"S2.SS1.p1.8.m6.2.3.cmml\" xref=\"S2.SS1.p1.8.m6.2.3\"><times id=\"S2.SS1.p1.8.m6.2.3.1.cmml\" xref=\"S2.SS1.p1.8.m6.2.3.1\"></times><ci id=\"S2.SS1.p1.8.m6.2.3.2.cmml\" xref=\"S2.SS1.p1.8.m6.2.3.2\">𝖠𝖼𝖼</ci><list id=\"S2.SS1.p1.8.m6.2.3.3.1.cmml\" xref=\"S2.SS1.p1.8.m6.2.3.3.2\"><ci id=\"S2.SS1.p1.8.m6.1.1.cmml\" xref=\"S2.SS1.p1.8.m6.1.1\">𝑓</ci><ci id=\"S2.SS1.p1.8.m6.2.2.cmml\" xref=\"S2.SS1.p1.8.m6.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p1.8.m6.2c\">\\mathsf{Acc}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p1.8.m6.2d\">sansserif_Acc ( italic_f ; caligraphic_D )</annotation></semantics></math> is high.</p>\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p2\">\n<p class=\"ltx_p\" id=\"S2.SS1.p2.1\">To effectively measure the memorization score <math alttext=\"\\mathsf{LiMem}(f;\\mathcal{D})\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS1.p2.1.m1.2\"><semantics id=\"S2.SS1.p2.1.m1.2a\"><mrow id=\"S2.SS1.p2.1.m1.2.3\" xref=\"S2.SS1.p2.1.m1.2.3.cmml\"><mi id=\"S2.SS1.p2.1.m1.2.3.2\" xref=\"S2.SS1.p2.1.m1.2.3.2.cmml\">𝖫𝗂𝖬𝖾𝗆</mi><mo id=\"S2.SS1.p2.1.m1.2.3.1\" xref=\"S2.SS1.p2.1.m1.2.3.1.cmml\">⁢</mo><mrow id=\"S2.SS1.p2.1.m1.2.3.3.2\" xref=\"S2.SS1.p2.1.m1.2.3.3.1.cmml\"><mo id=\"S2.SS1.p2.1.m1.2.3.3.2.1\" stretchy=\"false\" xref=\"S2.SS1.p2.1.m1.2.3.3.1.cmml\">(</mo><mi id=\"S2.SS1.p2.1.m1.1.1\" xref=\"S2.SS1.p2.1.m1.1.1.cmml\">f</mi><mo id=\"S2.SS1.p2.1.m1.2.3.3.2.2\" xref=\"S2.SS1.p2.1.m1.2.3.3.1.cmml\">;</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S2.SS1.p2.1.m1.2.2\" xref=\"S2.SS1.p2.1.m1.2.2.cmml\">𝒟</mi><mo id=\"S2.SS1.p2.1.m1.2.3.3.2.3\" stretchy=\"false\" xref=\"S2.SS1.p2.1.m1.2.3.3.1.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS1.p2.1.m1.2b\"><apply id=\"S2.SS1.p2.1.m1.2.3.cmml\" xref=\"S2.SS1.p2.1.m1.2.3\"><times id=\"S2.SS1.p2.1.m1.2.3.1.cmml\" xref=\"S2.SS1.p2.1.m1.2.3.1\"></times><ci id=\"S2.SS1.p2.1.m1.2.3.2.cmml\" xref=\"S2.SS1.p2.1.m1.2.3.2\">𝖫𝗂𝖬𝖾𝗆</ci><list id=\"S2.SS1.p2.1.m1.2.3.3.1.cmml\" xref=\"S2.SS1.p2.1.m1.2.3.3.2\"><ci id=\"S2.SS1.p2.1.m1.1.1.cmml\" xref=\"S2.SS1.p2.1.m1.1.1\">𝑓</ci><ci id=\"S2.SS1.p2.1.m1.2.2.cmml\" xref=\"S2.SS1.p2.1.m1.2.2\">𝒟</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS1.p2.1.m1.2c\">\\mathsf{LiMem}(f;\\mathcal{D})</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS1.p2.1.m1.2d\">sansserif_LiMem ( italic_f ; caligraphic_D )</annotation></semantics></math>, we need a principled way to (1) locally perturb the puzzle while maintaining its difficulty level; (2) compute the new correct answer after perturbation. Towards this goal, we design and implement a functional dataset based on the Knights and Knaves puzzles <cite class=\"ltx_cite ltx_citemacro_citep\">(Smullyan, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib61\" title=\"\">1978</a>; Johnson-Laird &amp; Byrne, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib29\" title=\"\">1990</a>)</cite>.</p>\n</div>\n<figure class=\"ltx_figure\" id=\"S2.F5\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top\" id=\"S2.F5.6\" style=\"width:160.4pt;\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_figure_panel ltx_img_square\" height=\"324\" id=\"S2.F5.1.g1\" src=\"x4.png\" width=\"374\"/></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_square\" height=\"324\" id=\"S2.F5.2.g2\" src=\"x5.png\" width=\"374\"/></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_square\" height=\"315\" id=\"S2.F5.3.g3\" src=\"x6.png\" width=\"374\"/></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_square\" height=\"334\" id=\"S2.F5.4.g4\" src=\"x7.png\" width=\"374\"/></div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 4: </span><span class=\"ltx_text\" id=\"S2.F5.6.2.1\" style=\"font-size:90%;\">Train &amp; test accuracy increases over the epochs. FTed LLMs can achieve interpolation (<math alttext=\"\\approx 100\\%\" class=\"ltx_Math\" display=\"inline\" id=\"S2.F5.6.2.1.m1.1\"><semantics id=\"S2.F5.6.2.1.m1.1b\"><mrow id=\"S2.F5.6.2.1.m1.1.1\" xref=\"S2.F5.6.2.1.m1.1.1.cmml\"><mi id=\"S2.F5.6.2.1.m1.1.1.2\" xref=\"S2.F5.6.2.1.m1.1.1.2.cmml\"></mi><mo id=\"S2.F5.6.2.1.m1.1.1.1\" xref=\"S2.F5.6.2.1.m1.1.1.1.cmml\">≈</mo><mrow id=\"S2.F5.6.2.1.m1.1.1.3\" xref=\"S2.F5.6.2.1.m1.1.1.3.cmml\"><mn id=\"S2.F5.6.2.1.m1.1.1.3.2\" xref=\"S2.F5.6.2.1.m1.1.1.3.2.cmml\">100</mn><mo id=\"S2.F5.6.2.1.m1.1.1.3.1\" xref=\"S2.F5.6.2.1.m1.1.1.3.1.cmml\">%</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.F5.6.2.1.m1.1c\"><apply id=\"S2.F5.6.2.1.m1.1.1.cmml\" xref=\"S2.F5.6.2.1.m1.1.1\"><approx id=\"S2.F5.6.2.1.m1.1.1.1.cmml\" xref=\"S2.F5.6.2.1.m1.1.1.1\"></approx><csymbol cd=\"latexml\" id=\"S2.F5.6.2.1.m1.1.1.2.cmml\" xref=\"S2.F5.6.2.1.m1.1.1.2\">absent</csymbol><apply id=\"S2.F5.6.2.1.m1.1.1.3.cmml\" xref=\"S2.F5.6.2.1.m1.1.1.3\"><csymbol cd=\"latexml\" id=\"S2.F5.6.2.1.m1.1.1.3.1.cmml\" xref=\"S2.F5.6.2.1.m1.1.1.3.1\">percent</csymbol><cn id=\"S2.F5.6.2.1.m1.1.1.3.2.cmml\" type=\"integer\" xref=\"S2.F5.6.2.1.m1.1.1.3.2\">100</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.F5.6.2.1.m1.1d\">\\approx 100\\%</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.F5.6.2.1.m1.1e\">≈ 100 %</annotation></semantics></math> train accuracy) for easy tasks, e.g., 3/5-ppl puzzles. Llama3-8B struggles with CoT FT on K&amp;K tasks, likely due to limited model capacity.\n</span></figcaption>\n</figure>\n</div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<figure class=\"ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top\" id=\"S2.F5.9\" style=\"width:260.2pt;\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_figure_panel ltx_img_landscape\" height=\"137\" id=\"S2.F5.7.g1\" src=\"x8.png\" width=\"830\"/></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape\" height=\"137\" id=\"S2.F5.8.g2\" src=\"x9.png\" width=\"830\"/></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape\" height=\"156\" id=\"S2.F5.9.g3\" src=\"x10.png\" width=\"830\"/></div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 5: </span><span class=\"ltx_text\" id=\"S2.F5.9.2.1\" style=\"font-size:90%;\">Fine-tuned LLMs generally exhibit\nboth higher clean accuracy (x-axis) &amp; inconsistency ratio under perturbations (y-axis) on the train set than test set, resulting in a higher memorization score (color spectrum).\nLLMs show stronger memorization under math-level perturbations (statement/leaf) than language level.\nWe separately report memorization score in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.F23.3\" title=\"In Fine-tuned models ‣ E.2 Memorization Measurement ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">Fig.</span> <span class=\"ltx_text ltx_ref_tag\">23</span></a> and consistency ratio in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.F24.5\" title=\"In Fine-tuned models ‣ E.2 Memorization Measurement ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">Fig.</span> <span class=\"ltx_text ltx_ref_tag\">24</span></a>, and results under combined math &amp; language-level perturbations in <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#A5.F25.1\" title=\"In Fine-tuned models ‣ E.2 Memorization Measurement ‣ Appendix E Additional Experimental Results ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">Fig.</span> <span class=\"ltx_text ltx_ref_tag\">25</span></a>.\n\n</span></figcaption>\n</figure>\n</div>\n</div>\n</figure>\n</section>\n<section class=\"ltx_subsection\" id=\"S2.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\">\n<span class=\"ltx_tag ltx_tag_subsection\">2.2 </span>Knights and Knaves Reasoning Benchmark</h3>\n<div class=\"ltx_para\" id=\"S2.SS2.p1\">\n<p class=\"ltx_p\" id=\"S2.SS2.p1.3\"><em class=\"ltx_emph ltx_font_italic\" id=\"S2.SS2.p1.3.1\">Knights and Knaves (K&amp;K)</em> is a type of logical puzzle, where the goal is to infer each character <math alttext=\"i\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.1.m1.1\"><semantics id=\"S2.SS2.p1.1.m1.1a\"><mi id=\"S2.SS2.p1.1.m1.1.1\" xref=\"S2.SS2.p1.1.m1.1.1.cmml\">i</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS2.p1.1.m1.1b\"><ci id=\"S2.SS2.p1.1.m1.1.1.cmml\" xref=\"S2.SS2.p1.1.m1.1.1\">𝑖</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS2.p1.1.m1.1c\">i</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS2.p1.1.m1.1d\">italic_i</annotation></semantics></math>’s truthfulness <math alttext=\"B_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.2.m2.1\"><semantics id=\"S2.SS2.p1.2.m2.1a\"><msub id=\"S2.SS2.p1.2.m2.1.1\" xref=\"S2.SS2.p1.2.m2.1.1.cmml\"><mi id=\"S2.SS2.p1.2.m2.1.1.2\" xref=\"S2.SS2.p1.2.m2.1.1.2.cmml\">B</mi><mi id=\"S2.SS2.p1.2.m2.1.1.3\" xref=\"S2.SS2.p1.2.m2.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS2.p1.2.m2.1b\"><apply id=\"S2.SS2.p1.2.m2.1.1.cmml\" xref=\"S2.SS2.p1.2.m2.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.SS2.p1.2.m2.1.1.1.cmml\" xref=\"S2.SS2.p1.2.m2.1.1\">subscript</csymbol><ci id=\"S2.SS2.p1.2.m2.1.1.2.cmml\" xref=\"S2.SS2.p1.2.m2.1.1.2\">𝐵</ci><ci id=\"S2.SS2.p1.2.m2.1.1.3.cmml\" xref=\"S2.SS2.p1.2.m2.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS2.p1.2.m2.1c\">B_{i}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS2.p1.2.m2.1d\">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> (Boolean value) by judging the logical consistency of the statements <math alttext=\"S_{i}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p1.3.m3.1\"><semantics id=\"S2.SS2.p1.3.m3.1a\"><msub id=\"S2.SS2.p1.3.m3.1.1\" xref=\"S2.SS2.p1.3.m3.1.1.cmml\"><mi id=\"S2.SS2.p1.3.m3.1.1.2\" xref=\"S2.SS2.p1.3.m3.1.1.2.cmml\">S</mi><mi id=\"S2.SS2.p1.3.m3.1.1.3\" xref=\"S2.SS2.p1.3.m3.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS2.p1.3.m3.1b\"><apply id=\"S2.SS2.p1.3.m3.1.1.cmml\" xref=\"S2.SS2.p1.3.m3.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.SS2.p1.3.m3.1.1.1.cmml\" xref=\"S2.SS2.p1.3.m3.1.1\">subscript</csymbol><ci id=\"S2.SS2.p1.3.m3.1.1.2.cmml\" xref=\"S2.SS2.p1.3.m3.1.1.2\">𝑆</ci><ci id=\"S2.SS2.p1.3.m3.1.1.3.cmml\" xref=\"S2.SS2.p1.3.m3.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS2.p1.3.m3.1c\">S_{i}</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS2.p1.3.m3.1d\">italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> they made.\n<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#S2.F3\" title=\"In 2.1 Memorization Metrics for Reasoning Tasks ‣ 2 Measuring Memorization in Reasoning ‣ On Memorization of Large Language Models in Logical Reasoning\"><span class=\"ltx_text ltx_ref_tag\">Fig.</span> <span class=\"ltx_text ltx_ref_tag\">3</span></a> shows an example.</p>\n</div>\n<div class=\"ltx_para\" id=\"S2.SS2.p2\">\n<p class=\"ltx_p\" id=\"S2.SS2.p2.6\">The principle underlying K&amp;K is the Boolean satisfiability problem (SAT) <cite class=\"ltx_cite ltx_citemacro_citep\">(<a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib7\" title=\"\">Boolean satisfiability problem, </a>)</cite>. SAT was the first problem proven to be NP-complete and many well-known problems can be translated into SAT, such as hardware and software verification and theorem proving <cite class=\"ltx_cite ltx_citemacro_citep\">(SAT solver, <a class=\"ltx_ref\" href=\"https://arxiv.org/html/2410.23123v2#bib.bib59\" title=\"\">2024</a>)</cite>. Hence, the performance of a model on SAT (i.e., K&amp;K puzzles) can be important indicative of its reasoning capabilities.\nSpecifically, consider a K&amp;K puzzle involving <math alttext=\"N\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.1.m1.1\"><semantics id=\"S2.SS2.p2.1.m1.1a\"><mi id=\"S2.SS2.p2.1.m1.1.1\" xref=\"S2.SS2.p2.1.m1.1.1.cmml\">N</mi><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS2.p2.1.m1.1b\"><ci id=\"S2.SS2.p2.1.m1.1.1.cmml\" xref=\"S2.SS2.p2.1.m1.1.1\">𝑁</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.SS2.p2.1.m1.1c\">N</annotation><annotation encoding=\"application/x-llamapun\" id=\"S2.SS2.p2.1.m1.1d\">italic_N</annotation></semantics></math> people, and a possible Boolean value assignments to <math alttext=\"\\{B_{i}\\}_{i=1}^{N}\" class=\"ltx_Math\" display=\"inline\" id=\"S2.SS2.p2.2.m2.1\"><semantics id=\"S2.SS2.p2.2.m2.1a\"><msubsup id=\"S2.SS2.p2.2.m2.1.1\" xref=\"S2.SS2.p2.2.m2.1.1.cmml\"><mrow id=\"S2.SS2.p2.2.m2.1.1.1.1.1\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.2.cmml\"><mo id=\"S2.SS2.p2.2.m2.1.1.1.1.1.2\" stretchy=\"false\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.2.cmml\">{</mo><msub id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.cmml\"><mi id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.2\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml\">B</mi><mi id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.3\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S2.SS2.p2.2.m2.1.1.1.1.1.3\" stretchy=\"false\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.2.cmml\">}</mo></mrow><mrow id=\"S2.SS2.p2.2.m2.1.1.1.3\" xref=\"S2.SS2.p2.2.m2.1.1.1.3.cmml\"><mi id=\"S2.SS2.p2.2.m2.1.1.1.3.2\" xref=\"S2.SS2.p2.2.m2.1.1.1.3.2.cmml\">i</mi><mo id=\"S2.SS2.p2.2.m2.1.1.1.3.1\" xref=\"S2.SS2.p2.2.m2.1.1.1.3.1.cmml\">=</mo><mn id=\"S2.SS2.p2.2.m2.1.1.1.3.3\" xref=\"S2.SS2.p2.2.m2.1.1.1.3.3.cmml\">1</mn></mrow><mi id=\"S2.SS2.p2.2.m2.1.1.3\" xref=\"S2.SS2.p2.2.m2.1.1.3.cmml\">N</mi></msubsup><annotation-xml encoding=\"MathML-Content\" id=\"S2.SS2.p2.2.m2.1b\"><apply id=\"S2.SS2.p2.2.m2.1.1.cmml\" xref=\"S2.SS2.p2.2.m2.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.SS2.p2.2.m2.1.1.2.cmml\" xref=\"S2.SS2.p2.2.m2.1.1\">superscript</csymbol><apply id=\"S2.SS2.p2.2.m2.1.1.1.cmml\" xref=\"S2.SS2.p2.2.m2.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.SS2.p2.2.m2.1.1.1.2.cmml\" xref=\"S2.SS2.p2.2.m2.1.1\">subscript</csymbol><set id=\"S2.SS2.p2.2.m2.1.1.1.1.2.cmml\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1\"><apply id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.cmml\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.1.cmml\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.2\">𝐵</ci><ci id=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml\" xref=\"S2.SS2.p2.2.m2.1.1.1.1.1.1.3\">𝑖</ci></apply></set><apply id=\"S2.SS2.p2.2.m2.1.1.1.3 ...

(The output of the tool call (shortuuid identifier: 8BuGBrSdJGs9y82WvMKpyb) is too long! Only the first 100000 characters are shown here. The original output length is 531036 characters. The full output has been saved to the file /workspace/dumps/workspace/.overlong_tool_outputs/8BuGBrSdJGs9y82WvMKpyb.json. Please check this file carefully, as it may be very long!)
```

</Expandable>
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query":"BBEH dataset logical reasoning BBEH benchmark",
	 "num_results": 10
}

```

```json output_result
Title: google-deepmind/bbeh - GitHub
Link: https://github.com/google-deepmind/bbeh
Snippet: A new benchmark designed to push the boundaries of LLM reasoning evaluation. BBEH replaces each task in BBH with a novel task that probes a similar reasoning ...
Sitelinks: No sitelinks

Title: BIG-Bench Extra Hard - arXiv
Link: https://arxiv.org/html/2502.19187v1
Snippet: We introduce BIG-Bench Extra Hard (BBEH), a new benchmark designed to push the boundaries of LLM reasoning evaluation.
Sitelinks: No sitelinks

Title: [2502.19187] BIG-Bench Extra Hard - arXiv
Link: https://arxiv.org/abs/2502.19187
Snippet: We introduce BIG-Bench Extra Hard (BBEH), a new benchmark designed to push the boundaries of LLM reasoning evaluation.
Sitelinks: No sitelinks

Title: Paper page - BIG-Bench Extra Hard - Hugging Face
Link: https://huggingface.co/papers/2502.19187
Snippet: We introduce BIG-Bench Extra Hard (BBEH), a new benchmark designed to push the boundaries of LLM reasoning evaluation.
Sitelinks: No sitelinks

Title: (PDF) BIG-Bench Extra Hard - ResearchGate
Link: https://www.researchgate.net/publication/389392420_BIG-Bench_Extra_Hard
Snippet: To address this limitation, we introduce BIG-Bench Extra Hard (BBEH), a new benchmark designed to push the boundaries of LLM reasoning ...
Sitelinks: No sitelinks

Title: [Literature Review] BIG-Bench Extra Hard - Moonlight
Link: https://www.themoonlight.io/en/review/big-bench-extra-hard
Snippet: BBEH replaces each of the 23 tasks from the BBH dataset with novel tasks which maintain a similar reasoning domain but significantly increase in ...
Sitelinks: No sitelinks

Title: 90: Why AI's Reasoning Tests Keep Failing Us - Ksenia Se - Medium
Link: https://kseniase.medium.com/90-why-ais-reasoning-tests-keep-failing-us-8c82df4fe4f1
Snippet: In response, researchers have introduced BIG-Bench Extra Hard (BBEH), a new benchmark designed to push AI reasoning to its limits. But if ...
Sitelinks: No sitelinks

Title: Sweet spots for reasoning models - by Kendra Vant - Data Runs Deep
Link: https://kendravant.substack.com/p/sweet-spots-for-reasoning-models
Snippet: For me, the BBEH paper highlights beautifully why benchmarks saturate, why evaluations are hard and why both are vital. I hope I've prompted you ...
Sitelinks: No sitelinks

Title: Daily Papers - Hugging Face
Link: https://huggingface.co/papers?q=benchmark%20suite%20BBH
Snippet: Improvements include gains of up to 30 points on logical reasoning benchmarks ... BenchHub aggregates and automatically classifies benchmark datasets from ...
Sitelinks: No sitelinks

Title: LLM Benchmark Datasets for Training and Evaluation | by Sulbha Jain
Link: https://medium.com/@sulbha.jindal/llm-benchmark-datasets-for-training-and-evaluation-1ec271129d7c
Snippet: BIG-Bench, BIG-Bench Hard (BBH), BIG-Bench Extra Hard (BBEH): These are collections of challenging tasks aimed at pushing the boundaries of LLM ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
workspace/datasets.tex
\begin{table}[!ht]
    \begin{center}
    \begin{tabular}{lccc}
        \toprule
        Dataset & Tasks & Trainable & Adjustable Difficulty\\
        \midrule
        BBH & 23 & \ding{55} & \ding{55}\\
        Zebra Logic & 1 & \ding{55} & \ding{51}\\
        KOR-Bench & 5 & \ding{55} & \ding{55}\\
        K\&K & 1 & \ding{51} & \ding{51}\\
        BBEH & 23 & \ding{55} & \ding{55}\\
        \bottomrule
    \end{tabular}
  \end{center}
\end{table}

```

```json output_result
Successfully wrote to /workspace/dumps/workspace/datasets.tex
```

</Expandable>
</div>

<div className="thinking-box">
🧐`Agent`

I’ve created datasets.tex in the workspace with the requested LaTeX table.

Notes on entries:
- BBH: 23 tasks (the “hard” subset of BIG-Bench), evaluation-only, no difficulty tiers.
- Zebra Logic: single task family (logic grid puzzles), evaluation benchmark with multiple puzzle sizes (adjustable difficulty).
- KOR-Bench: 5 task categories (Operation, Logic, Cipher, Puzzle, Counterfactual) as broader categorization; evaluation benchmark without train split or explicit difficulty tiers.
- K&K (arXiv:2410.23123): single task family (Knights & Knaves), includes generated training data and supports multiple difficulty levels; thus trainable and adjustable difficulty.
- BBEH: 23 tasks (one novel replacement per BBH task), evaluation-only, no difficulty tiers.

File path: /workspace/dumps/workspace/datasets.tex
</div>

</Accordion>

</AccordionGroup>
