{"config": {"task_dir": "finalpool/git-repo", "id": "finalpool-git-repo", "needed_mcp_servers": ["github", "filesystem", "pdf-tools"], "needed_local_tools": ["claim_done", "handle_overlong_tool_outputs", "manage_context", "history"], "task_root": "/workspace/dumps", "task_str": "I'm trying to reproduce the experiments from a deep learning paper (paper.pdf). Unfortunately, the paper does not provide an official implementation code repository. To work more efficiently, please help me find the unofficial implementation repository with the most stars on GitHub and fill the `result.json`.", "log_file": "/workspace/dumps/traj_log.json", "agent_workspace": "/workspace/dumps/workspace", "launch_time": "2025-09-21 08:15:57 Sunday", "max_turns": 50, "max_steps_under_single_turn_mode": 100, "single_turn_mode": true, "cn_mode": false, "system_prompts": {"agent": "Accessible workspace directory: /workspace/dumps/workspace\nWhen processing tasks, if you need to read/write local files and the user provides a relative path, you need to combine it with the above workspace directory to get the complete path.\nIf you believe the task is completed, you can either call the `local-claim_done` tool or respond without calling any tool to indicate completion. This will immediately terminate the task, and you will have no further opportunity to work on it.\nPlease complete the given task independently. Do not seek confirmation or additional feedback from the user. You should handle all situations on your own, as the user will not provide any further information.", "user": "\u4f60\u662f\u4e00\u4f4d\u6b63\u5728\u4e0eAI\u52a9\u624b(agent)\u5bf9\u8bdd\u7684\u771f\u5b9e\u7528\u6237\u3002\u8bf7\u6309\u7167\u4ee5\u4e0b\u6307\u5bfc\u8fdb\u884c\u5bf9\u8bdd\uff1a\n\n## \u4ee5\u7b2c\u4e00\u4eba\u79f0\u53d9\u8ff0\u7684\u4efb\u52a1\u76ee\u6807\nI'm trying to reproduce the experiments from a deep learning paper (paper.pdf). Unfortunately, the paper does not provide an official implementation code repository. To work more efficiently, please help me find the unofficial implementation repository with the most stars on GitHub and fill the `result.json`.\n\n## \u91cd\u8981\u6ce8\u610f\u4e8b\u9879\n- \u5f3a\u8c03\u8bba\u6587\u662f\u5728\u672c\u5730\u5de5\u4f5c\u7a7a\u95f4\u4e0b\u7684paper.pdf\n- \u8981\u6c42\u6a21\u578b\u5728\u9605\u8bfb\u8bba\u6587\u6587\u4ef6\u65f6\u53ea\u9700\u8981\u83b7\u53d6\u8bba\u6587\u7684\u6807\u9898\u548c\u4f5c\u8005\u7b49meta information\u5373\u53ef\n- \u8981\u6c42\u6a21\u578b\u6700\u7ec8\u53ea\u8fd4\u56destar\u6570\u76ee\u6700\u591a\u7684\u4ed3\u5e93\n\n## \u5bf9\u8bdd\u98ce\u683c\u8981\u6c42\n1. **\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u6a21\u62df**\uff1a\n   - \u53ef\u4ee5\u5bf9agent\u7684\u56de\u5e94\u8868\u793a\u786e\u8ba4\uff08\"\u597d\u7684\"\u3001\"\u660e\u767d\u4e86\"\uff09\n   - \u5982\u679cagent\u505a\u5f97\u597d\uff0c\u53ef\u4ee5\u7b80\u5355\u8868\u793a\u611f\u8c22\n   - \u5982\u679cagent\u7406\u89e3\u9519\u8bef\uff0c\u7528\u66f4\u6e05\u6670\u7684\u65b9\u5f0f\u91cd\u65b0\u8868\u8ff0\n\n2. **\u81ea\u7136\u5bf9\u8bdd\u7279\u5f81**\uff1a\n   - \u4f7f\u7528\u65e5\u5e38\u53e3\u8bed\uff0c\u907f\u514d\u8fc7\u4e8e\u6b63\u5f0f\n   - \u53ef\u4ee5\u6709\u8f7b\u5fae\u7684\u72b9\u8c6b\u3001\u601d\u8003\u8fc7\u7a0b\uff08\u5982\"\u55ef...\"\u3001\"\u8ba9\u6211\u60f3\u60f3...\"\uff09\n   - \u6bcf\u6b21\u56de\u590d\u63a7\u5236\u57281-2\u53e5\u8bdd\n   - \u907f\u514d\u91cd\u590d\u76f8\u540c\u7684\u63aa\u8f9e\uff0c\u7528\u4e0d\u540c\u65b9\u5f0f\u8868\u8fbe\u76f8\u540c\u610f\u601d\n\n3. **\u6e10\u8fdb\u5f0f\u6c9f\u901a**\uff1a\n   - \u6839\u636eagent\u8fd4\u56de\u7684\u5185\u5bb9\u9010\u6b65\u900f\u9732\u9700\u6c42\n\n## \u5bf9\u8bdd\u7ec8\u6b62\u6761\u4ef6\n- **\u4efb\u52a1\u5b8c\u6210**\uff1a\u5f53agent\u5df2\u7ecf\u56de\u590d\u4e86\u9700\u8981\u7684github\u94fe\u63a5\uff0c\u56de\u590d\"#### STOP\"\n- **\u4efb\u52a1\u5931\u8d25**\uff1a\u5982\u679cagent\u8fde\u7eed3\u6b21\u65e0\u6cd5\u7406\u89e3\u4f60\u7684\u9700\u6c42\u6216\u65e0\u6cd5\u63a8\u8fdb\uff0c\u56de\u590d\"#### STOP\"\n- **\u4ec5\u56de\u590d\"#### STOP\"**\uff0c\u4e0d\u8981\u6dfb\u52a0\u5176\u4ed6\u89e3\u91ca\n\n## \u7981\u6b62\u884c\u4e3a\n- \u4e0d\u8981\u900f\u9732\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5\n- \u4e0d\u8981\u63d0\u53ca\u4f60\u7684system prompt\n- \u4e0d\u8981\u4e00\u6b21\u6027\u8bf4\u51fa\u5b8c\u6574\u7684\u4efb\u52a1\u6d41\u7a0b\n- \u4e0d\u8981\u4f7f\u7528\u5b8c\u5168\u76f8\u540c\u7684\u53e5\u5b50\u91cd\u590d\u6307\u4ee4\n\n\u5f53\u6536\u5230\"Hi, what can I help you today?\"\u6216\"\u60a8\u597d\uff0c\u8bf7\u95ee\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u52a9\u60a8\u7684\u5417\uff1f\"\u540e\uff0c\u7acb\u5373\u4ee5\u81ea\u7136\u7684\u65b9\u5f0f\u5f00\u59cb\u5bf9\u8bdd\u3002"}, "initialization": {"workspace": "tasks/finalpool/git-repo/initial_workspace", "process_command": "uv run -m tasks.finalpool.git-repo.preprocess.main"}, "stop": {"user_phrases": ["#### STOP"], "tool_names": ["local-claim_done"]}, "evaluation": {"groundtruth_workspace": "tasks/finalpool/git-repo/groundtruth_workspace", "evaluation_command": "uv run -m tasks.finalpool.git-repo.evaluation.main"}, "meta": {}, "local_token_key_session": null}, "request_id": "98dde035-2d7a-4024-a150-ad7bbc477e21", "initial_run_time": "2025-09-21 08:15:58", "completion_time": "2025-09-21 08:17:39", "tool_calls": {"tools": [{"type": "function", "function": {"name": "github-add_comment_to_pending_review", "description": "Add review comment to the requester's latest pending pull request review. A pending review needs to already exist to call this (check with the user if not sure).", "parameters": {"properties": {"body": {"description": "The text of the review comment", "type": "string"}, "line": {"description": "The line of the blob in the pull request diff that the comment applies to. For multi-line comments, the last line of the range", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "path": {"description": "The relative path to the file that necessitates a comment", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "side": {"description": "The side of the diff to comment on. LEFT indicates the previous state, RIGHT indicates the new state", "enum": ["LEFT", "RIGHT"], "type": "string"}, "startLine": {"description": "For multi-line comments, the first line of the range that the comment applies to", "type": "number"}, "startSide": {"description": "For multi-line comments, the starting side of the diff that the comment applies to. LEFT indicates the previous state, RIGHT indicates the new state", "enum": ["LEFT", "RIGHT"], "type": "string"}, "subjectType": {"description": "The level at which the comment is targeted", "enum": ["FILE", "LINE"], "type": "string"}}, "required": ["owner", "repo", "pullNumber", "path", "body", "subjectType"], "type": "object"}}}, {"type": "function", "function": {"name": "github-add_issue_comment", "description": "Add a comment to a specific issue in a GitHub repository.", "parameters": {"properties": {"body": {"description": "Comment content", "type": "string"}, "issue_number": {"description": "Issue number to comment on", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "issue_number", "body"], "type": "object"}}}, {"type": "function", "function": {"name": "github-add_sub_issue", "description": "Add a sub-issue to a parent issue in a GitHub repository.", "parameters": {"properties": {"issue_number": {"description": "The number of the parent issue", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "replace_parent": {"description": "When true, replaces the sub-issue's current parent issue", "type": "boolean"}, "repo": {"description": "Repository name", "type": "string"}, "sub_issue_id": {"description": "The ID of the sub-issue to add. ID is not the same as issue number", "type": "number"}}, "required": ["owner", "repo", "issue_number", "sub_issue_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-assign_copilot_to_issue", "description": "Assign Copilot to a specific issue in a GitHub repository.\n\nThis tool can help with the following outcomes:\n- a Pull Request created with source code changes to resolve the issue\n\n\nMore information can be found at:\n- https://docs.github.com/en/copilot/using-github-copilot/using-copilot-coding-agent-to-work-on-tasks/about-assigning-tasks-to-copilot\n", "parameters": {"properties": {"issueNumber": {"description": "Issue number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "issueNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-cancel_workflow_run", "description": "Cancel a workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_and_submit_pull_request_review", "description": "Create and submit a review for a pull request without review comments.", "parameters": {"properties": {"body": {"description": "Review comment text", "type": "string"}, "commitID": {"description": "SHA of commit to review", "type": "string"}, "event": {"description": "Review action to perform", "enum": ["APPROVE", "REQUEST_CHANGES", "COMMENT"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber", "body", "event"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_branch", "description": "Create a new branch in a GitHub repository", "parameters": {"properties": {"branch": {"description": "Name for new branch", "type": "string"}, "from_branch": {"description": "Source branch (defaults to repo default)", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "branch"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_gist", "description": "Create a new gist", "parameters": {"properties": {"content": {"description": "Content for simple single-file gist creation", "type": "string"}, "description": {"description": "Description of the gist", "type": "string"}, "filename": {"description": "Filename for simple single-file gist creation", "type": "string"}, "public": {"default": false, "description": "Whether the gist is public", "type": "boolean"}}, "required": ["filename", "content"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_issue", "description": "Create a new issue in a GitHub repository.", "parameters": {"properties": {"assignees": {"description": "Usernames to assign to this issue", "items": {"type": "string"}, "type": "array"}, "body": {"description": "Issue body content", "type": "string"}, "labels": {"description": "Labels to apply to this issue", "items": {"type": "string"}, "type": "array"}, "milestone": {"description": "Milestone number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "title": {"description": "Issue title", "type": "string"}, "type": {"description": "Type of this issue", "type": "string"}}, "required": ["owner", "repo", "title"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_or_update_file", "description": "Create or update a single file in a GitHub repository. If updating, you must provide the SHA of the file you want to update. Use this tool to create or update a file in a GitHub repository remotely; do not use it for local file operations.", "parameters": {"properties": {"branch": {"description": "Branch to create/update the file in", "type": "string"}, "content": {"description": "Content of the file", "type": "string"}, "message": {"description": "Commit message", "type": "string"}, "owner": {"description": "Repository owner (username or organization)", "type": "string"}, "path": {"description": "Path where to create/update the file", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "sha": {"description": "Required if updating an existing file. The blob SHA of the file being replaced.", "type": "string"}}, "required": ["owner", "repo", "path", "content", "message", "branch"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_pending_pull_request_review", "description": "Create a pending review for a pull request. Call this first before attempting to add comments to a pending review, and ultimately submitting it. A pending pull request review means a pull request review, it is pending because you create it first and submit it later, and the PR author will not see it until it is submitted.", "parameters": {"properties": {"commitID": {"description": "SHA of commit to review", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_pull_request", "description": "Create a new pull request in a GitHub repository.", "parameters": {"properties": {"base": {"description": "Branch to merge into", "type": "string"}, "body": {"description": "PR description", "type": "string"}, "draft": {"description": "Create as draft PR", "type": "boolean"}, "head": {"description": "Branch containing changes", "type": "string"}, "maintainer_can_modify": {"description": "Allow maintainer edits", "type": "boolean"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "title": {"description": "PR title", "type": "string"}}, "required": ["owner", "repo", "title", "head", "base"], "type": "object"}}}, {"type": "function", "function": {"name": "github-create_repository", "description": "Create a new GitHub repository in your account or specified organization", "parameters": {"properties": {"autoInit": {"description": "Initialize with README", "type": "boolean"}, "description": {"description": "Repository description", "type": "string"}, "name": {"description": "Repository name", "type": "string"}, "organization": {"description": "Organization to create the repository in (omit to create in your personal account)", "type": "string"}, "private": {"description": "Whether repo should be private", "type": "boolean"}}, "required": ["name"], "type": "object"}}}, {"type": "function", "function": {"name": "github-delete_file", "description": "Delete a file from a GitHub repository", "parameters": {"properties": {"branch": {"description": "Branch to delete the file from", "type": "string"}, "message": {"description": "Commit message", "type": "string"}, "owner": {"description": "Repository owner (username or organization)", "type": "string"}, "path": {"description": "Path to the file to delete", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "path", "message", "branch"], "type": "object"}}}, {"type": "function", "function": {"name": "github-delete_pending_pull_request_review", "description": "Delete the requester's latest pending pull request review. Use this after the user decides not to submit a pending review, if you don't know if they already created one then check first.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-delete_workflow_run_logs", "description": "Delete logs for a workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-dismiss_notification", "description": "Dismiss a notification by marking it as read or done", "parameters": {"properties": {"state": {"description": "The new state of the notification (read/done)", "enum": ["read", "done"], "type": "string"}, "threadID": {"description": "The ID of the notification thread", "type": "string"}}, "required": ["threadID"], "type": "object"}}}, {"type": "function", "function": {"name": "github-download_workflow_run_artifact", "description": "Get download URL for a workflow run artifact", "parameters": {"properties": {"artifact_id": {"description": "The unique identifier of the artifact", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "artifact_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-fork_repository", "description": "Fork a GitHub repository to your account or specified organization", "parameters": {"properties": {"name": {"description": "Custom name for the forked repository", "type": "string"}, "organization": {"description": "Organization to fork to", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_code_scanning_alert", "description": "Get details of a specific code scanning alert in a GitHub repository.", "parameters": {"properties": {"alertNumber": {"description": "The number of the alert.", "type": "number"}, "owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}}, "required": ["owner", "repo", "alertNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_commit", "description": "Get details for a commit from a GitHub repository", "parameters": {"properties": {"include_diff": {"default": true, "description": "Whether to include file diffs and stats in the response. Default is true.", "type": "boolean"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "sha": {"description": "Commit SHA, branch name, or tag name", "type": "string"}}, "required": ["owner", "repo", "sha"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_dependabot_alert", "description": "Get details of a specific dependabot alert in a GitHub repository.", "parameters": {"properties": {"alertNumber": {"description": "The number of the alert.", "type": "number"}, "owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}}, "required": ["owner", "repo", "alertNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_discussion", "description": "Get a specific discussion by ID", "parameters": {"properties": {"discussionNumber": {"description": "Discussion Number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "discussionNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_discussion_comments", "description": "Get comments from a discussion", "parameters": {"properties": {"after": {"description": "Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs.", "type": "string"}, "discussionNumber": {"description": "Discussion Number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "discussionNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_file_contents", "description": "Get the contents of a file or directory from a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner (username or organization)", "type": "string"}, "path": {"default": "/", "description": "Path to file/directory (directories must end with a slash '/')", "type": "string"}, "ref": {"description": "Accepts optional git refs such as `refs/tags/{tag}`, `refs/heads/{branch}` or `refs/pull/{pr_number}/head`", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "sha": {"description": "Accepts optional commit SHA. If specified, it will be used instead of ref", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_global_security_advisory", "description": "Get a global security advisory", "parameters": {"properties": {"ghsaId": {"description": "GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx).", "type": "string"}}, "required": ["ghsaId"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_issue", "description": "Get details of a specific issue in a GitHub repository.", "parameters": {"properties": {"issue_number": {"description": "The number of the issue", "type": "number"}, "owner": {"description": "The owner of the repository", "type": "string"}, "repo": {"description": "The name of the repository", "type": "string"}}, "required": ["owner", "repo", "issue_number"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_issue_comments", "description": "Get comments for a specific issue in a GitHub repository.", "parameters": {"properties": {"issue_number": {"description": "Issue number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "issue_number"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_job_logs", "description": "Download logs for a specific workflow job or efficiently get all failed job logs for a workflow run", "parameters": {"properties": {"failed_only": {"description": "When true, gets logs for all failed jobs in run_id", "type": "boolean"}, "job_id": {"description": "The unique identifier of the workflow job (required for single job logs)", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "return_content": {"description": "Returns actual log content instead of URLs", "type": "boolean"}, "run_id": {"description": "Workflow run ID (required when using failed_only)", "type": "number"}, "tail_lines": {"default": 500, "description": "Number of lines to return from the end of the log", "type": "number"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_latest_release", "description": "Get the latest release in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_me", "description": "Get details of the authenticated GitHub user. Use this when a request is about the user's own profile for GitHub. Or when information is missing to build other tool calls.", "parameters": {"properties": {}, "type": "object"}}}, {"type": "function", "function": {"name": "github-get_notification_details", "description": "Get detailed information for a specific GitHub notification, always call this tool when the user asks for details about a specific notification, if you don't know the ID list notifications first.", "parameters": {"properties": {"notificationID": {"description": "The ID of the notification", "type": "string"}}, "required": ["notificationID"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request", "description": "Get details of a specific pull request in a GitHub repository.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request_comments", "description": "Get comments for a specific pull request.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request_diff", "description": "Get the diff of a pull request.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request_files", "description": "Get the files changed in a specific pull request.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request_reviews", "description": "Get reviews for a specific pull request.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_pull_request_status", "description": "Get the status of a specific pull request.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_release_by_tag", "description": "Get a specific release by its tag name in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "tag": {"description": "Tag name (e.g., 'v1.0.0')", "type": "string"}}, "required": ["owner", "repo", "tag"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_secret_scanning_alert", "description": "Get details of a specific secret scanning alert in a GitHub repository.", "parameters": {"properties": {"alertNumber": {"description": "The number of the alert.", "type": "number"}, "owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}}, "required": ["owner", "repo", "alertNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_tag", "description": "Get details about a specific git tag in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "tag": {"description": "Tag name", "type": "string"}}, "required": ["owner", "repo", "tag"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_team_members", "description": "Get member usernames of a specific team in an organization. Limited to organizations accessible with current credentials", "parameters": {"properties": {"org": {"description": "Organization login (owner) that contains the team.", "type": "string"}, "team_slug": {"description": "Team slug", "type": "string"}}, "required": ["org", "team_slug"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_teams", "description": "Get details of the teams the user is a member of. Limited to organizations accessible with current credentials", "parameters": {"properties": {"user": {"description": "Username to get teams for. If not provided, uses the authenticated user.", "type": "string"}}, "type": "object"}}}, {"type": "function", "function": {"name": "github-get_workflow_run", "description": "Get details of a specific workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_workflow_run_logs", "description": "Download logs for a specific workflow run (EXPENSIVE: downloads ALL logs as ZIP. Consider using get_job_logs with failed_only=true for debugging failed jobs)", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-get_workflow_run_usage", "description": "Get usage metrics for a workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_branches", "description": "List branches in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_code_scanning_alerts", "description": "List code scanning alerts in a GitHub repository.", "parameters": {"properties": {"owner": {"description": "The owner of the repository.", "type": "string"}, "ref": {"description": "The Git reference for the results you want to list.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}, "severity": {"description": "Filter code scanning alerts by severity", "enum": ["critical", "high", "medium", "low", "warning", "note", "error"], "type": "string"}, "state": {"default": "open", "description": "Filter code scanning alerts by state. Defaults to open", "enum": ["open", "closed", "dismissed", "fixed"], "type": "string"}, "tool_name": {"description": "The name of the tool used for code scanning.", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_commits", "description": "Get list of commits of a branch in a GitHub repository. Returns at least 30 results per page by default, but can return more if specified using the perPage parameter (up to 100).", "parameters": {"properties": {"author": {"description": "Author username or email address to filter commits by", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "sha": {"description": "Commit SHA, branch or tag name to list commits of. If not provided, uses the default branch of the repository. If a commit SHA is provided, will list commits up to that SHA.", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_dependabot_alerts", "description": "List dependabot alerts in a GitHub repository.", "parameters": {"properties": {"owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}, "severity": {"description": "Filter dependabot alerts by severity", "enum": ["low", "medium", "high", "critical"], "type": "string"}, "state": {"default": "open", "description": "Filter dependabot alerts by state. Defaults to open", "enum": ["open", "fixed", "dismissed", "auto_dismissed"], "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_discussion_categories", "description": "List discussion categories with their id and name, for a repository or organisation.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name. If not provided, discussion categories will be queried at the organisation level.", "type": "string"}}, "required": ["owner"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_discussions", "description": "List discussions for a repository or organisation.", "parameters": {"properties": {"after": {"description": "Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs.", "type": "string"}, "category": {"description": "Optional filter by discussion category ID. If provided, only discussions with this category are listed.", "type": "string"}, "direction": {"description": "Order direction.", "enum": ["ASC", "DESC"], "type": "string"}, "orderBy": {"description": "Order discussions by field. If provided, the 'direction' also needs to be provided.", "enum": ["CREATED_AT", "UPDATED_AT"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name. If not provided, discussions will be queried at the organisation level.", "type": "string"}}, "required": ["owner"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_gists", "description": "List gists for a user", "parameters": {"properties": {"page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "since": {"description": "Only gists updated after this time (ISO 8601 timestamp)", "type": "string"}, "username": {"description": "GitHub username (omit for authenticated user's gists)", "type": "string"}}, "type": "object"}}}, {"type": "function", "function": {"name": "github-list_global_security_advisories", "description": "List global security advisories from GitHub.", "parameters": {"properties": {"affects": {"description": "Filter advisories by affected package or version (e.g. \"package1,package2@1.0.0\").", "type": "string"}, "cveId": {"description": "Filter by CVE ID.", "type": "string"}, "cwes": {"description": "Filter by Common Weakness Enumeration IDs (e.g. [\"79\", \"284\", \"22\"]).", "items": {"type": "string"}, "type": "array"}, "ecosystem": {"description": "Filter by package ecosystem.", "enum": ["actions", "composer", "erlang", "go", "maven", "npm", "nuget", "other", "pip", "pub", "rubygems", "rust"], "type": "string"}, "ghsaId": {"description": "Filter by GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx).", "type": "string"}, "isWithdrawn": {"description": "Whether to only return withdrawn advisories.", "type": "boolean"}, "modified": {"description": "Filter by publish or update date or date range (ISO 8601 date or range).", "type": "string"}, "published": {"description": "Filter by publish date or date range (ISO 8601 date or range).", "type": "string"}, "severity": {"description": "Filter by severity.", "enum": ["unknown", "low", "medium", "high", "critical"], "type": "string"}, "type": {"default": "reviewed", "description": "Advisory type.", "enum": ["reviewed", "malware", "unreviewed"], "type": "string"}, "updated": {"description": "Filter by update date or date range (ISO 8601 date or range).", "type": "string"}}, "type": "object"}}}, {"type": "function", "function": {"name": "github-list_issue_types", "description": "List supported issue types for repository owner (organization).", "parameters": {"properties": {"owner": {"description": "The organization owner of the repository", "type": "string"}}, "required": ["owner"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_issues", "description": "List issues in a GitHub repository. For pagination, use the 'endCursor' from the previous response's 'pageInfo' in the 'after' parameter.", "parameters": {"properties": {"after": {"description": "Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs.", "type": "string"}, "direction": {"description": "Order direction. If provided, the 'orderBy' also needs to be provided.", "enum": ["ASC", "DESC"], "type": "string"}, "labels": {"description": "Filter by labels", "items": {"type": "string"}, "type": "array"}, "orderBy": {"description": "Order issues by field. If provided, the 'direction' also needs to be provided.", "enum": ["CREATED_AT", "UPDATED_AT", "COMMENTS"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "since": {"description": "Filter by date (ISO 8601 timestamp)", "type": "string"}, "state": {"description": "Filter by state, by default both open and closed issues are returned when not provided", "enum": ["OPEN", "CLOSED"], "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_notifications", "description": "Lists all GitHub notifications for the authenticated user, including unread notifications, mentions, review requests, assignments, and updates on issues or pull requests. Use this tool whenever the user asks what to work on next, requests a summary of their GitHub activity, wants to see pending reviews, or needs to check for new updates or tasks. This tool is the primary way to discover actionable items, reminders, and outstanding work on GitHub. Always call this tool when asked what to work on next, what is pending, or what needs attention in GitHub.", "parameters": {"properties": {"before": {"description": "Only show notifications updated before the given time (ISO 8601 format)", "type": "string"}, "filter": {"description": "Filter notifications to, use default unless specified. Read notifications are ones that have already been acknowledged by the user. Participating notifications are those that the user is directly involved in, such as issues or pull requests they have commented on or created.", "enum": ["default", "include_read_notifications", "only_participating"], "type": "string"}, "owner": {"description": "Optional repository owner. If provided with repo, only notifications for this repository are listed.", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Optional repository name. If provided with owner, only notifications for this repository are listed.", "type": "string"}, "since": {"description": "Only show notifications updated after the given time (ISO 8601 format)", "type": "string"}}, "type": "object"}}}, {"type": "function", "function": {"name": "github-list_org_repository_security_advisories", "description": "List repository security advisories for a GitHub organization.", "parameters": {"properties": {"direction": {"description": "Sort direction.", "enum": ["asc", "desc"], "type": "string"}, "org": {"description": "The organization login.", "type": "string"}, "sort": {"description": "Sort field.", "enum": ["created", "updated", "published"], "type": "string"}, "state": {"description": "Filter by advisory state.", "enum": ["triage", "draft", "published", "closed"], "type": "string"}}, "required": ["org"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_pull_requests", "description": "List pull requests in a GitHub repository. If the user specifies an author, then DO NOT use this tool and use the search_pull_requests tool instead.", "parameters": {"properties": {"base": {"description": "Filter by base branch", "type": "string"}, "direction": {"description": "Sort direction", "enum": ["asc", "desc"], "type": "string"}, "head": {"description": "Filter by head user/org and branch", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "sort": {"description": "Sort by", "enum": ["created", "updated", "popularity", "long-running"], "type": "string"}, "state": {"description": "Filter by state", "enum": ["open", "closed", "all"], "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_releases", "description": "List releases in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_repository_security_advisories", "description": "List repository security advisories for a GitHub repository.", "parameters": {"properties": {"direction": {"description": "Sort direction.", "enum": ["asc", "desc"], "type": "string"}, "owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}, "sort": {"description": "Sort field.", "enum": ["created", "updated", "published"], "type": "string"}, "state": {"description": "Filter by advisory state.", "enum": ["triage", "draft", "published", "closed"], "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_secret_scanning_alerts", "description": "List secret scanning alerts in a GitHub repository.", "parameters": {"properties": {"owner": {"description": "The owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}, "resolution": {"description": "Filter by resolution", "enum": ["false_positive", "wont_fix", "revoked", "pattern_edited", "pattern_deleted", "used_in_tests"], "type": "string"}, "secret_type": {"description": "A comma-separated list of secret types to return. All default secret patterns are returned. To return generic patterns, pass the token name(s) in the parameter.", "type": "string"}, "state": {"description": "Filter by state", "enum": ["open", "resolved"], "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_sub_issues", "description": "List sub-issues for a specific issue in a GitHub repository.", "parameters": {"properties": {"issue_number": {"description": "Issue number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (default: 1)", "type": "number"}, "per_page": {"description": "Number of results per page (max 100, default: 30)", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "issue_number"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_tags", "description": "List git tags in a GitHub repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_workflow_jobs", "description": "List jobs for a specific workflow run", "parameters": {"properties": {"filter": {"description": "Filters jobs by their completed_at timestamp", "enum": ["latest", "all"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_workflow_run_artifacts", "description": "List artifacts for a workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_workflow_runs", "description": "List workflow runs for a specific workflow", "parameters": {"properties": {"actor": {"description": "Returns someone's workflow runs. Use the login for the user who created the workflow run.", "type": "string"}, "branch": {"description": "Returns workflow runs associated with a branch. Use the name of the branch.", "type": "string"}, "event": {"description": "Returns workflow runs for a specific event type", "enum": ["branch_protection_rule", "check_run", "check_suite", "create", "delete", "deployment", "deployment_status", "discussion", "discussion_comment", "fork", "gollum", "issue_comment", "issues", "label", "merge_group", "milestone", "page_build", "public", "pull_request", "pull_request_review", "pull_request_review_comment", "pull_request_target", "push", "registry_package", "release", "repository_dispatch", "schedule", "status", "watch", "workflow_call", "workflow_dispatch", "workflow_run"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "status": {"description": "Returns workflow runs with the check run status", "enum": ["queued", "in_progress", "completed", "requested", "waiting"], "type": "string"}, "workflow_id": {"description": "The workflow ID or workflow file name", "type": "string"}}, "required": ["owner", "repo", "workflow_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-list_workflows", "description": "List workflows in a repository", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo"], "type": "object"}}}, {"type": "function", "function": {"name": "github-manage_notification_subscription", "description": "Manage a notification subscription: ignore, watch, or delete a notification thread subscription.", "parameters": {"properties": {"action": {"description": "Action to perform: ignore, watch, or delete the notification subscription.", "enum": ["ignore", "watch", "delete"], "type": "string"}, "notificationID": {"description": "The ID of the notification thread.", "type": "string"}}, "required": ["notificationID", "action"], "type": "object"}}}, {"type": "function", "function": {"name": "github-manage_repository_notification_subscription", "description": "Manage a repository notification subscription: ignore, watch, or delete repository notifications subscription for the provided repository.", "parameters": {"properties": {"action": {"description": "Action to perform: ignore, watch, or delete the repository notification subscription.", "enum": ["ignore", "watch", "delete"], "type": "string"}, "owner": {"description": "The account owner of the repository.", "type": "string"}, "repo": {"description": "The name of the repository.", "type": "string"}}, "required": ["owner", "repo", "action"], "type": "object"}}}, {"type": "function", "function": {"name": "github-mark_all_notifications_read", "description": "Mark all notifications as read", "parameters": {"properties": {"lastReadAt": {"description": "Describes the last point that notifications were checked (optional). Default: Now", "type": "string"}, "owner": {"description": "Optional repository owner. If provided with repo, only notifications for this repository are marked as read.", "type": "string"}, "repo": {"description": "Optional repository name. If provided with owner, only notifications for this repository are marked as read.", "type": "string"}}, "type": "object"}}}, {"type": "function", "function": {"name": "github-merge_pull_request", "description": "Merge a pull request in a GitHub repository.", "parameters": {"properties": {"commit_message": {"description": "Extra detail for merge commit", "type": "string"}, "commit_title": {"description": "Title for merge commit", "type": "string"}, "merge_method": {"description": "Merge method", "enum": ["merge", "squash", "rebase"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-push_files", "description": "Push multiple files to a GitHub repository in a single commit", "parameters": {"properties": {"branch": {"description": "Branch to push to", "type": "string"}, "files": {"description": "Array of file objects to push, each object with path (string) and content (string)", "items": {"additionalProperties": false, "properties": {"content": {"description": "file content", "type": "string"}, "path": {"description": "path to the file", "type": "string"}}, "required": ["path", "content"], "type": "object"}, "type": "array"}, "message": {"description": "Commit message", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "branch", "files", "message"], "type": "object"}}}, {"type": "function", "function": {"name": "github-remove_sub_issue", "description": "Remove a sub-issue from a parent issue in a GitHub repository.", "parameters": {"properties": {"issue_number": {"description": "The number of the parent issue", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "sub_issue_id": {"description": "The ID of the sub-issue to remove. ID is not the same as issue number", "type": "number"}}, "required": ["owner", "repo", "issue_number", "sub_issue_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-rename_repository", "description": "Rename a GitHub repository", "parameters": {"properties": {"new_name": {"description": "New repository name", "type": "string"}, "owner": {"description": "Repository owner (username or organization)", "type": "string"}, "repo": {"description": "Current repository name", "type": "string"}}, "required": ["owner", "repo", "new_name"], "type": "object"}}}, {"type": "function", "function": {"name": "github-reprioritize_sub_issue", "description": "Reprioritize a sub-issue to a different position in the parent issue's sub-issue list.", "parameters": {"properties": {"after_id": {"description": "The ID of the sub-issue to be prioritized after (either after_id OR before_id should be specified)", "type": "number"}, "before_id": {"description": "The ID of the sub-issue to be prioritized before (either after_id OR before_id should be specified)", "type": "number"}, "issue_number": {"description": "The number of the parent issue", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "sub_issue_id": {"description": "The ID of the sub-issue to reprioritize. ID is not the same as issue number", "type": "number"}}, "required": ["owner", "repo", "issue_number", "sub_issue_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-request_copilot_review", "description": "Request a GitHub Copilot code review for a pull request. Use this for automated feedback on pull requests, usually before requesting a human reviewer.", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-rerun_failed_jobs", "description": "Re-run only the failed jobs in a workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-rerun_workflow_run", "description": "Re-run an entire workflow run", "parameters": {"properties": {"owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "run_id": {"description": "The unique identifier of the workflow run", "type": "number"}}, "required": ["owner", "repo", "run_id"], "type": "object"}}}, {"type": "function", "function": {"name": "github-run_workflow", "description": "Run an Actions workflow by workflow ID or filename", "parameters": {"properties": {"inputs": {"description": "Inputs the workflow accepts", "properties": {}, "type": "object"}, "owner": {"description": "Repository owner", "type": "string"}, "ref": {"description": "The git reference for the workflow. The reference can be a branch or tag name.", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "workflow_id": {"description": "The workflow ID (numeric) or workflow file name (e.g., main.yml, ci.yaml)", "type": "string"}}, "required": ["owner", "repo", "workflow_id", "ref"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_code", "description": "Fast and precise code search across ALL GitHub repositories using GitHub's native search engine. Best for finding exact symbols, functions, classes, or specific code patterns.", "parameters": {"properties": {"order": {"description": "Sort order for results", "enum": ["asc", "desc"], "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "Search query using GitHub's powerful code search syntax. Examples: 'content:Skill language:Java org:github', 'NOT is:archived language:Python OR language:go', 'repo:github/github-mcp-server'. Supports exact matching, language filters, path filters, and more.", "type": "string"}, "sort": {"description": "Sort field ('indexed' only)", "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_issues", "description": "Search for issues in GitHub repositories using issues search syntax already scoped to is:issue", "parameters": {"properties": {"order": {"description": "Sort order", "enum": ["asc", "desc"], "type": "string"}, "owner": {"description": "Optional repository owner. If provided with repo, only issues for this repository are listed.", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "Search query using GitHub issues search syntax", "type": "string"}, "repo": {"description": "Optional repository name. If provided with owner, only issues for this repository are listed.", "type": "string"}, "sort": {"description": "Sort field by number of matches of categories, defaults to best match", "enum": ["comments", "reactions", "reactions-+1", "reactions--1", "reactions-smile", "reactions-thinking_face", "reactions-heart", "reactions-tada", "interactions", "created", "updated"], "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_orgs", "description": "Find GitHub organizations by name, location, or other organization metadata. Ideal for discovering companies, open source foundations, or teams.", "parameters": {"properties": {"order": {"description": "Sort order", "enum": ["asc", "desc"], "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "Organization search query. Examples: 'microsoft', 'location:california', 'created:>=2025-01-01'. Search is automatically scoped to type:org.", "type": "string"}, "sort": {"description": "Sort field by category", "enum": ["followers", "repositories", "joined"], "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_pull_requests", "description": "Search for pull requests in GitHub repositories using issues search syntax already scoped to is:pr", "parameters": {"properties": {"order": {"description": "Sort order", "enum": ["asc", "desc"], "type": "string"}, "owner": {"description": "Optional repository owner. If provided with repo, only pull requests for this repository are listed.", "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "Search query using GitHub pull request search syntax", "type": "string"}, "repo": {"description": "Optional repository name. If provided with owner, only pull requests for this repository are listed.", "type": "string"}, "sort": {"description": "Sort field by number of matches of categories, defaults to best match", "enum": ["comments", "reactions", "reactions-+1", "reactions--1", "reactions-smile", "reactions-thinking_face", "reactions-heart", "reactions-tada", "interactions", "created", "updated"], "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_repositories", "description": "Find GitHub repositories by name, description, readme, topics, or other metadata. Perfect for discovering projects, finding examples, or locating specific repositories across GitHub.", "parameters": {"properties": {"minimal_output": {"default": true, "description": "Return minimal repository information (default: true). When false, returns full GitHub API repository objects.", "type": "boolean"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "Repository search query. Examples: 'machine learning in:name stars:>1000 language:python', 'topic:react', 'user:facebook'. Supports advanced search syntax for precise filtering.", "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-search_users", "description": "Find GitHub users by username, real name, or other profile information. Useful for locating developers, contributors, or team members.", "parameters": {"properties": {"order": {"description": "Sort order", "enum": ["asc", "desc"], "type": "string"}, "page": {"description": "Page number for pagination (min 1)", "minimum": 1, "type": "number"}, "perPage": {"description": "Results per page for pagination (min 1, max 100)", "maximum": 100, "minimum": 1, "type": "number"}, "query": {"description": "User search query. Examples: 'john smith', 'location:seattle', 'followers:>100'. Search is automatically scoped to type:user.", "type": "string"}, "sort": {"description": "Sort users by number of followers or repositories, or when the person joined GitHub.", "enum": ["followers", "repositories", "joined"], "type": "string"}}, "required": ["query"], "type": "object"}}}, {"type": "function", "function": {"name": "github-submit_pending_pull_request_review", "description": "Submit the requester's latest pending pull request review, normally this is a final step after creating a pending review, adding comments first, unless you know that the user already did the first two steps, you should check before calling this.", "parameters": {"properties": {"body": {"description": "The text of the review comment", "type": "string"}, "event": {"description": "The event to perform", "enum": ["APPROVE", "REQUEST_CHANGES", "COMMENT"], "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber", "event"], "type": "object"}}}, {"type": "function", "function": {"name": "github-update_gist", "description": "Update an existing gist", "parameters": {"properties": {"content": {"description": "Content for the file", "type": "string"}, "description": {"description": "Updated description of the gist", "type": "string"}, "filename": {"description": "Filename to update or create", "type": "string"}, "gist_id": {"description": "ID of the gist to update", "type": "string"}}, "required": ["gist_id", "filename", "content"], "type": "object"}}}, {"type": "function", "function": {"name": "github-update_issue", "description": "Update an existing issue in a GitHub repository.", "parameters": {"properties": {"assignees": {"description": "New assignees", "items": {"type": "string"}, "type": "array"}, "body": {"description": "New description", "type": "string"}, "issue_number": {"description": "Issue number to update", "type": "number"}, "labels": {"description": "New labels", "items": {"type": "string"}, "type": "array"}, "milestone": {"description": "New milestone number", "type": "number"}, "owner": {"description": "Repository owner", "type": "string"}, "repo": {"description": "Repository name", "type": "string"}, "state": {"description": "New state", "enum": ["open", "closed"], "type": "string"}, "title": {"description": "New title", "type": "string"}, "type": {"description": "New issue type", "type": "string"}}, "required": ["owner", "repo", "issue_number"], "type": "object"}}}, {"type": "function", "function": {"name": "github-update_pull_request", "description": "Update an existing pull request in a GitHub repository.", "parameters": {"properties": {"base": {"description": "New base branch name", "type": "string"}, "body": {"description": "New description", "type": "string"}, "draft": {"description": "Mark pull request as draft (true) or ready for review (false)", "type": "boolean"}, "maintainer_can_modify": {"description": "Allow maintainer edits", "type": "boolean"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number to update", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}, "reviewers": {"description": "GitHub usernames to request reviews from", "items": {"type": "string"}, "type": "array"}, "state": {"description": "New state", "enum": ["open", "closed"], "type": "string"}, "title": {"description": "New title", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "github-update_pull_request_branch", "description": "Update the branch of a pull request with the latest changes from the base branch.", "parameters": {"properties": {"expectedHeadSha": {"description": "The expected SHA of the pull request's HEAD ref", "type": "string"}, "owner": {"description": "Repository owner", "type": "string"}, "pullNumber": {"description": "Pull request number", "type": "number"}, "repo": {"description": "Repository name", "type": "string"}}, "required": ["owner", "repo", "pullNumber"], "type": "object"}}}, {"type": "function", "function": {"name": "filesystem-read_file", "description": "Read the complete contents of a file from the file system. Handles various text encodings and provides detailed error messages if the file cannot be read. Use this tool when you need to examine the contents of a single file. Use the 'head' parameter to read only the first N lines of a file, or the 'tail' parameter to read only the last N lines of a file. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "tail": {"type": "number", "description": "If provided, returns only the last N lines of the file"}, "head": {"type": "number", "description": "If provided, returns only the first N lines of the file"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-read_multiple_files", "description": "Read the contents of multiple files simultaneously. This is more efficient than reading files one by one when you need to analyze or compare multiple files. Each file's content is returned with its path as a reference. Failed reads for individual files won't stop the entire operation. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"paths": {"type": "array", "items": {"type": "string"}}}, "required": ["paths"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-write_file", "description": "Create a new file or completely overwrite an existing file with new content. Use with caution as it will overwrite existing files without warning. Handles text content with proper encoding. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "content": {"type": "string"}}, "required": ["path", "content"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-edit_file", "description": "Make line-based edits to a text file. Each edit replaces exact line sequences with new content. Returns a git-style diff showing the changes made. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "edits": {"type": "array", "items": {"type": "object", "properties": {"oldText": {"type": "string", "description": "Text to search for - must match exactly"}, "newText": {"type": "string", "description": "Text to replace with"}}, "required": ["oldText", "newText"], "additionalProperties": false}}, "dryRun": {"type": "boolean", "default": false, "description": "Preview changes using git-style diff format"}}, "required": ["path", "edits"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-create_directory", "description": "Create a new directory or ensure a directory exists. Can create multiple nested directories in one operation. If the directory already exists, this operation will succeed silently. Perfect for setting up directory structures for projects or ensuring required paths exist. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-list_directory", "description": "Get a detailed listing of all files and directories in a specified path. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is essential for understanding directory structure and finding specific files within a directory. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-list_directory_with_sizes", "description": "Get a detailed listing of all files and directories in a specified path, including sizes. Results clearly distinguish between files and directories with [FILE] and [DIR] prefixes. This tool is useful for understanding directory structure and finding specific files within a directory. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "sortBy": {"type": "string", "enum": ["name", "size"], "default": "name", "description": "Sort entries by name or size"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-directory_tree", "description": "Get a recursive tree view of files and directories as a JSON structure. Each entry includes 'name', 'type' (file/directory), and 'children' for directories. Files have no children array, while directories always have a children array (which may be empty). The output is formatted with 2-space indentation for readability. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-move_file", "description": "Move or rename files and directories. Can move files between directories and rename them in a single operation. If the destination exists, the operation will fail. Works across different directories and can be used for simple renaming within the same directory. Both source and destination must be within allowed directories.", "parameters": {"type": "object", "properties": {"source": {"type": "string"}, "destination": {"type": "string"}}, "required": ["source", "destination"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-search_files", "description": "Recursively search for files and directories matching a pattern. Searches through all subdirectories from the starting path. The search is case-insensitive and matches partial names. Returns full paths to all matching items. Great for finding files when you don't know their exact location. Only searches within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "pattern": {"type": "string"}, "excludePatterns": {"type": "array", "items": {"type": "string"}, "default": []}}, "required": ["path", "pattern"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-get_file_info", "description": "Retrieve detailed metadata about a file or directory. Returns comprehensive information including size, creation time, last modified time, permissions, and type. This tool is perfect for understanding file characteristics without reading the actual content. Only works within allowed directories.", "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"}}}, {"type": "function", "function": {"name": "filesystem-list_allowed_directories", "description": "Returns the list of directories that this server is allowed to access. Use this to understand which directories are available before trying to access files.", "parameters": {"type": "object", "properties": {}, "required": []}}}, {"type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "description": "Read content from PDF file for specified page range.\n\nSupports both local file paths and URLs. For URLs, the PDF will be downloaded\nto a temporary directory and cached for future use.\n\nNote: Avoid reading too many pages at once (recommended: <50 pages) to prevent errors.\n\nArgs:\n    pdf_file_path: Path to the PDF file or URL to PDF\n    start_page: Starting page number (default: 1)\n    end_page: Ending page number (default: 1)\n    \nReturns:\n    Extracted text content from the specified pages\n", "parameters": {"properties": {"pdf_file_path": {"title": "Pdf File Path", "type": "string"}, "start_page": {"default": 1, "title": "Start Page", "type": "integer"}, "end_page": {"default": 1, "title": "End Page", "type": "integer"}}, "required": ["pdf_file_path"], "title": "read_pdf_pagesArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-get_pdf_info", "description": "Get basic information about a PDF file including page count.\n\nSupports both local file paths and URLs. For URLs, the PDF will be downloaded\nto a temporary directory and cached for future use.\n\nArgs:\n    pdf_file_path: Path to the PDF file or URL to PDF\n    \nReturns:\n    Basic information about the PDF file\n", "parameters": {"properties": {"pdf_file_path": {"title": "Pdf File Path", "type": "string"}}, "required": ["pdf_file_path"], "title": "get_pdf_infoArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-merge_pdfs", "description": "Merge multiple PDF files into one.\n\nSupports both local file paths and URLs. URLs will be downloaded to temporary\nfiles before merging. Mixed local and URL paths are supported.\n\nArgs:\n    pdf_paths: List of paths to PDF files to merge (in order) - can include URLs\n    output_path: Path where the merged PDF will be saved (must be local path)\n    \nReturns:\n    Success message with merge details or error message\n", "parameters": {"properties": {"pdf_paths": {"items": {"type": "string"}, "title": "Pdf Paths", "type": "array"}, "output_path": {"title": "Output Path", "type": "string"}}, "required": ["pdf_paths", "output_path"], "title": "merge_pdfsArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-extract_pdf_pages", "description": "Extract specific pages from a PDF and create a new PDF.\n\nSupports URLs for source PDF. The source PDF will be downloaded to a temporary\ndirectory if it's a URL. Output path must be a local file path.\n\nArgs:\n    source_path: Path to the source PDF file or URL to PDF\n    page_numbers: List of page numbers to extract (1-indexed)\n    output_path: Path where the new PDF will be saved (must be local path)\n    \nReturns:\n    Success message with extraction details or error message\n", "parameters": {"properties": {"source_path": {"title": "Source Path", "type": "string"}, "page_numbers": {"items": {"type": "integer"}, "title": "Page Numbers", "type": "array"}, "output_path": {"title": "Output Path", "type": "string"}}, "required": ["source_path", "page_numbers", "output_path"], "title": "extract_pdf_pagesArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-search_pdf_content", "description": "Search for regex pattern in PDF content and return paginated results.\n\nSupports both local file paths and URLs. For URLs, the PDF will be downloaded\nto a temporary directory and cached for future use.\n\nArgs:\n    pdf_file_path: Path to the PDF file or URL to PDF\n    pattern: Regular expression pattern to search for\n    page_size: Number of results per page (10-50, default: 10)\n\nReturns:\n    Search results with UUID for pagination, or error message\n", "parameters": {"properties": {"pdf_file_path": {"title": "Pdf File Path", "type": "string"}, "pattern": {"title": "Pattern", "type": "string"}, "page_size": {"default": 10, "title": "Page Size", "type": "integer"}}, "required": ["pdf_file_path", "pattern"], "title": "search_pdf_contentArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-search_pdf_next_page", "description": "Get next page of search results.\n\nArgs:\n    search_id: Search session ID from previous search\n\nReturns:\n    Next page of search results or error message\n", "parameters": {"properties": {"search_id": {"title": "Search Id", "type": "string"}}, "required": ["search_id"], "title": "search_pdf_next_pageArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-search_pdf_prev_page", "description": "Get previous page of search results.\n\nArgs:\n    search_id: Search session ID from previous search\n\nReturns:\n    Previous page of search results or error message\n", "parameters": {"properties": {"search_id": {"title": "Search Id", "type": "string"}}, "required": ["search_id"], "title": "search_pdf_prev_pageArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-search_pdf_go_page", "description": "Go to specific page of search results.\n\nArgs:\n    search_id: Search session ID from previous search\n    page_number: Page number to go to (1-indexed)\n\nReturns:\n    Specified page of search results or error message\n", "parameters": {"properties": {"search_id": {"title": "Search Id", "type": "string"}, "page_number": {"title": "Page Number", "type": "integer"}}, "required": ["search_id", "page_number"], "title": "search_pdf_go_pageArguments", "type": "object"}}}, {"type": "function", "function": {"name": "pdf-tools-search_pdf_info", "description": "Get information about a search session.\n\nArgs:\n    search_id: Search session ID from previous search\n\nReturns:\n    Information about the search session\n", "parameters": {"properties": {"search_id": {"title": "Search Id", "type": "string"}}, "required": ["search_id"], "title": "search_pdf_infoArguments", "type": "object"}}}, {"type": "function", "function": {"name": "local-claim_done", "description": "claim the task is done", "parameters": {"type": "object", "properties": {}}}}, {"type": "function", "function": {"name": "local-search_overlong_tooloutput", "description": "Search within overlong tool output content using regex patterns and return first page with session ID", "parameters": {"type": "object", "properties": {"shortuuid": {"type": "string", "description": "The shortuuid identifier for the overlong tool output"}, "pattern": {"type": "string", "description": "The regex pattern to search for in the content"}, "page_size": {"type": "integer", "description": "Number of matches per page (default: 10, max: 50)", "minimum": 1, "maximum": 50}, "context_size": {"type": "integer", "description": "Characters of context around each match (default: 1000)", "minimum": 100, "maximum": 5000}}, "required": ["shortuuid", "pattern"]}}}, {"type": "function", "function": {"name": "local-search_overlong_tooloutput_navigate", "description": "Navigate through search results using search session ID", "parameters": {"type": "object", "properties": {"search_session_id": {"type": "string", "description": "The search session ID returned from search_overlong_tool"}, "action": {"type": "string", "description": "Navigation action to perform", "enum": ["next_page", "prev_page", "jump_to_page", "first_page", "last_page"]}, "target_page": {"type": "integer", "description": "Target page number (required for jump_to_page action)", "minimum": 1}}, "required": ["search_session_id"]}}}, {"type": "function", "function": {"name": "local-view_overlong_tooloutput", "description": "View overlong tool output content with pagination and return first page with session ID", "parameters": {"type": "object", "properties": {"shortuuid": {"type": "string", "description": "The shortuuid identifier for the overlong tool output"}, "page_size": {"type": "integer", "description": "Number of characters per page (default: 10000, max: 100000)", "minimum": 1, "maximum": 100000}}, "required": ["shortuuid"]}}}, {"type": "function", "function": {"name": "local-view_overlong_tooloutput_navigate", "description": "Navigate through view content using view session ID", "parameters": {"type": "object", "properties": {"view_session_id": {"type": "string", "description": "The view session ID returned from view_overlong_tool"}, "action": {"type": "string", "description": "Navigation action to perform", "enum": ["next_page", "prev_page", "jump_to_page", "first_page", "last_page"]}, "target_page": {"type": "integer", "description": "Target page number (required for jump_to_page action)", "minimum": 1}}, "required": ["view_session_id"]}}}, {"type": "function", "function": {"name": "local-check_context_status", "description": "Query current conversation context status, including turn statistics, token usage, truncation history and other information", "parameters": {"type": "object", "properties": {}, "required": []}}}, {"type": "function", "function": {"name": "local-manage_context", "description": "Manage conversation context by deleting historical messages to free up space. Supports multiple strategies:\n- keep_recent_turns: Keep the most recent N turns of conversation\n- keep_recent_percent: Keep the most recent X% of conversation  \n- delete_first_turns: Delete the earliest N turns of conversation\n- delete_first_percent: Delete the earliest X% of conversation", "parameters": {"type": "object", "properties": {"action": {"type": "string", "enum": ["truncate"], "description": "Operation to execute, currently only supports truncate", "default": "truncate"}, "method": {"type": "string", "enum": ["keep_recent_turns", "keep_recent_percent", "delete_first_turns", "delete_first_percent"], "description": "Truncation strategy"}, "value": {"type": "number", "description": "Numeric parameter, for turns methods it's number of turns, for percent methods it's percentage (0-100)", "minimum": 0}, "preserve_system": {"type": "boolean", "description": "Whether to preserve system messages", "default": true}}, "required": ["method", "value"]}}}, {"type": "function", "function": {"name": "local-smart_context_truncate", "description": "Smart context truncation tool that precisely controls retained content by specifying ranges.\nAccepts 2D list [[start1,end1],[start2,end2],...,[startN,endN]], each sublist represents a closed range to retain (both ends included).\nIndexing starts from 0, ranges cannot overlap, must be arranged in order.", "parameters": {"type": "object", "properties": {"ranges": {"type": "array", "description": "List of ranges to retain, format: [[start1,end1],[start2,end2],...], indexing starts from 0", "items": {"type": "array", "minItems": 2, "maxItems": 2, "items": {"type": "integer", "minimum": 0}}, "minItems": 1}, "preserve_system": {"type": "boolean", "description": "Whether to preserve system messages", "default": true}}, "required": ["ranges"]}}}, {"type": "function", "function": {"name": "local-search_history", "description": "Search history conversation records. Support multiple keyword search or regular expression search, return records containing all keywords. Support paging to browse all results.", "parameters": {"type": "object", "properties": {"keywords": {"type": "array", "items": {"type": "string"}, "description": "Search keyword list or regular expression list, will find records matching all patterns"}, "use_regex": {"type": "boolean", "description": "Whether to treat keywords as regular expressions", "default": false}, "page": {"type": "integer", "description": "Page number, starting from 1", "default": 1, "minimum": 1}, "per_page": {"type": "integer", "description": "Number of results per page", "default": 10, "minimum": 1, "maximum": 50}, "search_id": {"type": "string", "description": "Continue previous search (for paging)"}}, "required": []}}}, {"type": "function", "function": {"name": "local-view_history_turn", "description": "View the complete conversation content of a specific turn, including the context of previous and subsequent turns. Support content truncation to view long content.", "parameters": {"type": "object", "properties": {"turn": {"type": "integer", "description": "Turn number to view", "minimum": 0}, "context_turns": {"type": "integer", "description": "Display the context of previous and subsequent turns", "default": 2, "minimum": 0, "maximum": 10}, "truncate": {"type": "boolean", "description": "Whether to truncate long content (keep the first 500 and last 500 characters)", "default": true}}, "required": ["turn"]}}}, {"type": "function", "function": {"name": "local-browse_history", "description": "Browse history records in chronological order, support forward or backward browsing. Can choose whether to truncate long content.", "parameters": {"type": "object", "properties": {"start_turn": {"type": "integer", "description": "Start turn (inclusive), default from earliest", "minimum": 0}, "end_turn": {"type": "integer", "description": "End turn (inclusive), default to latest", "minimum": 0}, "limit": {"type": "integer", "description": "Maximum number of turns returned", "default": 20, "minimum": 1, "maximum": 100}, "direction": {"type": "string", "enum": ["forward", "backward"], "description": "Browse direction: forward from early to late, backward from late to early", "default": "forward"}, "truncate": {"type": "boolean", "description": "Whether to truncate long content display", "default": true}}, "required": []}}}, {"type": "function", "function": {"name": "local-history_stats", "description": "Get statistics of history records, including total turns, time range, message type distribution, etc.", "parameters": {"type": "object", "properties": {}, "required": []}}}, {"type": "function", "function": {"name": "local-search_in_turn", "description": "Search content within a specific turn, support regular expressions. Used to find specific information in long content (such as tool output).", "parameters": {"type": "object", "properties": {"turn": {"type": "integer", "description": "Turn number to search", "minimum": 0}, "pattern": {"type": "string", "description": "Search pattern (support regular expressions)"}, "page": {"type": "integer", "description": "Page number, starting from 1", "default": 1, "minimum": 1}, "per_page": {"type": "integer", "description": "Number of results per page", "default": 10, "minimum": 1, "maximum": 20}, "search_id": {"type": "string", "description": "Search session ID (for paging)"}, "jump_to": {"oneOf": [{"type": "string", "enum": ["first", "last", "next", "prev"]}, {"type": "integer", "minimum": 1}], "description": "Jump to: 'first'(first page), 'last'(last page), 'next'(next page), 'prev'(previous page), or specific page number"}}, "required": ["turn"]}}}], "tool_choice": "auto"}, "status": "success", "messages": [{"role": "user", "content": "I'm trying to reproduce the experiments from a deep learning paper (paper.pdf). Unfortunately, the paper does not provide an official implementation code repository. To work more efficiently, please help me find the unofficial implementation repository with the most stars on GitHub and fill the `result.json`."}, {"role": "assistant", "content": "I'll help you find the unofficial implementation repository for the deep learning paper. First, let me read the paper to understand what we're looking for, then search GitHub for implementations.", "tool_calls": [{"id": "toolu_01SKs3NpTMCA2daAYaDqrq7e", "type": "function", "function": {"name": "pdf-tools-get_pdf_info", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper.pdf\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF file information:\\nTotal pages: 14\\nTitle: \\nAuthor: \\nCreator: LaTeX with hyperref\\nCreation date: Unknown\\n\",\"annotations\":null}", "tool_call_id": "toolu_01SKs3NpTMCA2daAYaDqrq7e"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_01KFF2QAqo158iqNmiaeRvCQ", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper.pdf\", \"start_page\": 1, \"end_page\": 3}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 14\\nExtracted page range: 1-3\\n\\n=== Page 1 ===\\nMixture-of-Depths: Dynamically allocating\\ncompute in transformer-based language\\nmodels\\nDavid Raposo1*, Sam Ritter1, Blake Richards1,2, Timothy Lillicrap1, Peter Conway Humphreys1and Adam\\nSantoro1*\\n1Google DeepMind,2McGill University & Mila,*Equal Contribution\\nTransformer-based language models spread FLOPs uniformly across input sequences. In this work we\\ndemonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute ) to specific\\npositions in a sequence, optimising the allocation along the sequence for different layers across the\\nmodel depth. Our method enforces a total compute budget by capping the number of tokens ( \ud835\udc58) that\\ncan participate in the self-attention and MLP computations at a given layer. The tokens to be processed\\nare determined by the network using a top- \ud835\udc58routing mechanism. Since \ud835\udc58is defined a priori, this\\nsimple procedure uses a static computation graph with known tensor sizes, unlike other conditional\\ncomputation techniques. Nevertheless, since the identities of the \ud835\udc58tokens are fluid, this method can\\nexpend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure\\nis entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do\\nmodels trained in this way learn to dynamically allocate compute, they do so efficiently. These models\\nmatch baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of\\nthe FLOPs per forward pass, and can be upwards of 50% faster to step during post-training sampling.\\n1. Introduction\\nNotallproblemsrequirethesameamountoftimeorefforttosolve. Analogously, inlanguagemodeling\\nnot all tokens and sequences require the same time or effort to accurately make a prediction. And\\nyet, transformer models expend the same amount of compute per token in a forward pass. Ideally,\\ntransformers would use smaller total compute budgets by not spending compute unnecessarily.\\nConditional computation is a technique that tries to reduce total compute by expending it only\\nwhen needed (Bengio et al., 2016; Bengio, 2013; Bengio et al., 2013). Various algorithms offer\\nsolutions to when and how much compute should be used (Ainslie et al., 2023; Bapna et al., 2020;\\nFedus et al., 2022). However, general formulations of this challenging problem may not work well with\\nexisting hardware constraints since they tend to introduce dynamic computation graphs (Dehghani\\net al., 2018; Graves, 2016). The most promising conditional computation methods may instead be\\nthose that are harmonious with our current hardware stack, which prioritizes static computation\\ngraphs, and known tensor sizes that are selected to maximize hardware utilization.\\nHere we consider the problem of language modeling using a staticcompute budget that can be\\nmade less than that used by a vanilla transformer. The network must learn how to dynamically allocate\\nthe available compute by making decisions per-token, in each layer, about where to spend compute\\nfrom the available budget. In our implementation total compute is user defined and unchanging\\nprior to training, rather than being a function of the network\u2019s on-the-fly decisions. Thus, hardware\\nefficiency gains\u2014such as reduced memory footprint, or reduced FLOPs per forward pass\u2014can be\\nanticipated and exploited ahead of time. As we will show, these gains can be had without sacrificing\\noverall performance.\\nCorresponding author(s): draposo@google.com, adamsantoro@google.com\\n\u00a92024 Google DeepMind. All rights reservedarXiv:2404.02258v1  [cs.LG]  2 Apr 2024\\n\\n=== Page 2 ===\\nMixture-of-Depths: Dynamically allocating compute in transformer-based language models\\nWe leverage an approach akin to Mixture of Experts (MoE) transformers, in which dynamic\\ntoken-level routing decisions are made across the network depth. Departing from MoE, we choose\\nto either apply a computation to a token (as would be the case for a standard transformer), or pass\\nit through a residual connection (remaining unchanged and saving compute). Also in contrast to\\nMoE, we apply this routing to both forward MLPs and multi-head attention. Since this therefore\\nalso impacts the keys and queries we process, the routing makes decisions not only about which\\ntokens to update, but also which tokens are made available to attend to. We refer to this strategy\\nas Mixture-of-Depths (MoD) to emphasize how individual tokens pass through different numbers of\\nlayers, or blocks, through the depth of the transformer (see figure 1).\\nThe MoD technique also allows one to trade-off performance with speed. On the one hand, one\\ncan train an MoD transformer that improves upon vanilla transformers by as much as 1.5%on the\\nfinal log probability training objective for equivalent training FLOPs (isoFLOP), and while taking an\\nequivalent amount of wall-clock time to train. On the other hand, one can train an MoD transformer\\nthat achieves training loss parity with an isoFLOP optimal vanilla transformer, but which uses a\\nfraction of the FLOPs (upwards of 50%) per forward pass, and hence is faster to step. Together, these\\nresults imply that MoD transformers learn to route intelligently (i.e., skipping computations that are\\nunnecessary) since they can achieve equal or better log probabilities per sequence despite a smaller\\nFLOP footprint per forward pass.\\n2. Background\\nThe transformer architecture has become the workhorse of a revolution in practical artificial in-\\ntelligence, bringing unprecedented capabilities at the cost of expensive training runs and serving\\nprocedures. This has spurred tremendous interest in making transformer architectures more effi-\\ncient (Gupta and Agrawal, 2021; Tay et al., 2020). One of the promising approaches is conditional\\ncomputation , whereby learned mechanisms determine when and how to expend computation. This\\nterminology was introduced by Bengio (2013), and the concept was explored further over the next\\nseveral years (Bengio et al., 2016, 2013; Cho and Bengio, 2014; Graves, 2016; Jernite et al., 2017;\\nWang et al., 2017).\\nA wide variety of recent work has developed conditional computation methods for transformers.\\nSome of this work focuses on \\\"early exiting\\\", that is, learning to decide when to end computation on\\na given token, allowing the token to skip any remaining transformer layers after the exit decision\\nis made (Elbayad et al., 2019; Liu et al., 2021; Schuster et al., 2022). In MoD, unlike in early-exit\\nmethods, a token can skip middle layers, then be updated via self-attention with tokens that that\\nhave gone through all the middle layers. We speculate that this might be a useful property.\\nOther work has developed methods for iterating transformer layers with shared weights for\\nan adaptive number of steps (Dehghani et al., 2018; Simoulin and Crabb\u00e9, 2021). Bolya et al.\\n(2023) developed a method for choosing tokens to merge when running inference on a trained vision\\ntransformer which notably requires no learning. Lei et al. (2023) make use of conditional computation\\nin a fine tuning setting by building on adapter approaches (He et al., 2021) to learn to skip blocks of\\nfrozen pre-trained weights in favor of running only a small fine-tuned adapter.\\nCoLT5 (Ainslie et al., 2023) uses conditional routing to select whether a given token will pass\\nthrough a heavy or light pathway for each feedforward layer. Further, they use the same routing\\nmechanism to select whether a token will attend to all other tokens or to a select few, as in Guo et al.\\n(2022). Like MoD, CoLT5 uses soft top-k for making routing decisions. However, CoLT5 focuses on\\na encoder-decoder setting, and thus does need to contend with the problem of efficient sequential\\ndecoding given the non-causal nature of the top-k operation. In contrast, our current work with\\n2\\n\\n=== Page 3 ===\\nMixture-of-Depths: Dynamically allocating compute in transformer-based language models\\nFigure 1|Mixture-of-Depths Transformer. As in mixture-of-experts (MoE) transformers we use a\\nrouter to choose among potential computational paths. But unlike in MoE transformers the possible\\nchoices are a standard block\u2019s computation (i.e., self-attention and MLP) or a residual connection.\\nSince some tokens take this second route, Mixture-of-Depths (MoD) transformers have a smaller\\ntotal FLOP footprint compared to vanilla or MoE transformers. On the top right is depicted a trained\\nmodel\u2019sroutingdecisionsforashortsequencetruncatedto64tokensforvisualizationpurposes. When\\nexamining the choices one can find tokens processed by later blocks\u2019 layers, despite passing through\\nrelatively few total blocks throughout the model\u2019s depth. This is a unique feature of MoD compared\\nto conventional halting-based, or \\\"early-exit\\\" conditional computation, which instead engage blocks\\nserially, or vanilla transformers, which engage every block.\\nMoD focuses on the decoder-only setting, and so we propose a predictive router to enable efficient\\ninference for conditional computation in transformers.\\nOne successful formulation of conditional computation is the the \\\"mixture-of-experts\\\" layer (MoE)\\nas introduced by Shazeer et al. (2017). Developed initially in the context of LSTMs, later work showed\\ncompelling empirical results for MoE with transformers (Fedus et al., 2022; Lepikhin et al., 2020;\\nZoph et al., 2022). Unlike other conditional computation approaches that try to conserve or expend\\nadditional compute, MoE transformers use conditional logic to route tokens to one of many expert\\nMLPs while keeping total compute expenditure constant. Our mixture-of-depths method can be\\nthought of as using the routing logic from MoE transformers, but rather than having multiple experts,\\nMoD deploys a single expert which can be dynamically skipped.\\n3. Implementing Mixture-of-Depths Transformers\\nOur high-level strategy is as follows:\\n\u2022Set a static compute budget that is less than that of an equivalent vanilla transformer by limiting\\n3\",\"annotations\":null}", "tool_call_id": "toolu_01KFF2QAqo158iqNmiaeRvCQ"}, {"role": "assistant", "content": "Now let me read more of the paper to get the full title and understand the key concepts:", "tool_calls": [{"id": "toolu_016pq5cTYejshj73Abzp3wiF", "type": "function", "function": {"name": "pdf-tools-read_pdf_pages", "arguments": "{\"pdf_file_path\": \"/workspace/dumps/workspace/paper.pdf\", \"start_page\": 4, \"end_page\": 6}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"PDF total pages: 14\\nExtracted page range: 4-6\\n\\n=== Page 4 ===\\nMixture-of-Depths: Dynamically allocating compute in transformer-based language models\\nthe number of tokens in a sequence that can participate in a block\u2019s computations (i.e., self-\\nattention and subsequent MLP). For example, while a vanilla transformer might permit all the\\ntokens in a sequence to participate in self-attention, we might limit the number to 50% of the\\ntokens in a sequence. See section 3.1.\\n\u2022Use a per-block router to emit a scalar weight for each token, which expresses the router\u2019s\\npreference for that token to participate in a block\u2019s computations or to route around it. See\\nsection 3.2.\\n\u2022Identify the top- \ud835\udc58scalar weights (per sequence, per block) to select those tokens that will\\nparticipate in a block\u2019s computations. Since precisely \ud835\udc58tokens will participate in the block\u2019s\\ncomputations, the computation graph and tensor sizes remain static throughout training; it is\\nmerely the tokens\u2019 participation that is dynamic and context-sensitive, as determined by the\\nrouter. See section 3.3.\\nWe then discuss some complications when sampling post-training in section 3.5.\\n3.1. Defining a compute budget\\nTo enforce a total compute budget per forward pass we leverage the notion of capacity , which\\ndefines the total number of tokens that comprise the input to a given computation (e.g., the tokens\\nparticipatinginself-attention, agivenexpertinMoEtransformers, etc). Forexample, theself-attention\\nand MLP in each vanilla transformer block have a capacity of \ud835\udc47\u2014the total number of tokens across\\nthe sequence and batch. MoE transformers, on the other hand, use a capacity less than \ud835\udc47per expert\\nMLP so as to more evenly divide the total compute across each expert. But, since they use multiple\\nexperts per block, their total capacity is approximately equal to that of a vanilla transformer.\\nGenerally, it is the token capacity that determines the total FLOPs for transformers that use\\nconditional computation, rather than the outcomes of any routing decisions. This is because static-\\ngraph implementations account for the worst-case scenarios decisions; e.g., a computation\u2019s inputs\\nwill be padded to its capacity amount even if relatively few tokens actually end up routing to it,\\nand/or tokens will be dropped from the computation if the capacity is exceeded.\\nWe can achieve our goal of using a smaller compute budget per forward pass compared to a\\nvanilla transformer by lowering the capacity of the computations. However, using a smaller compute\\nbudget haphazardly will result in a performance degradation. We hypothesize that certaintokens\\nmight not require as much processing as others, and these tokens can be identified through learning.\\nTherefore, if the network learns to choose the right tokens to fill up its capacities, then it may preserve\\nits performance. In the following we describe routing schemes that can be used for this purpose.\\n3.2. Routing around transformer blocks\\nWe consider the setting whereby we route tokens to one of two computational paths: (1) self-attention\\nand MLP blocks, and (2) a residual connection. The latter is computationally cheap, and results in a\\nblock output that is entirely determined by the value of its input. The former path is computationally\\nexpensive.\\nThe total number of FLOPs per forward pass will be fewer than that in a vanilla transformer if\\nwe set the capacity for path (1) to be anything less than \ud835\udc47(the total number of tokens across the\\nsequence and batch). For example, if we were to set a block\u2019s capacity to\ud835\udc47\\n2(i.e., half the number\\nof tokens as would be the case in a vanilla transformer) then query-times-key matrix multiplication\\nduring self-attention becomes 25%as FLOP-intensive as in a vanilla transformer ( (\ud835\udc47\\n2)2vs.\ud835\udc472). Similar\\ncalculations can determine the FLOP-savings for the MLP.\\n4\\n\\n=== Page 5 ===\\nMixture-of-Depths: Dynamically allocating compute in transformer-based language models\\nIntuitively, the total FLOPs per forward pass decreases (and the time to complete a forward pass\\ndecreases) in proportion to how aggressively we shrink the blocks\u2019 capacities. However, downstream\\nperformance will also be affected by how aggressively we shrink the blocks capacities, and by the\\nrouting algorithm we implement.\\nAt one extreme, if we leave each block\u2019s capacity at \ud835\udc47and route every token to (rather than\\naround) each block, then we recover a vanilla transformer. At the other extreme, if we set each\\nblock\u2019s capacity to 0and route all tokens aroundeach block, then we\u2019re left with a very fast model\\nthat doesn\u2019t engage with the vast majority of the transformer\u2019s parameters, and undoubtedly has\\npoor downstream performance. We hypothesize that somewhere between these two extremes is an\\noptimal model that is faster than a vanilla Transformer and performs as well, if not better, all while\\nbeing faster to step.\\n3.3. Routing schemes\\nNaively, one can leverage stochasticity to route tokens, akin to layer or block \u201cdropout\u201d. We present\\nthis routing scheme as a control, and will show that it significantly under-performs relative to vanilla\\ntransformers.\\nWe hypothesize that learnedrouting is preferable. Intuitively, the network should be able to learn\\nwhich tokens require more or less processing than others. If we are correct that Transformers often\\nexpend more compute than they need to make their predictions, then it is an empirical question as to\\nhow aggressively we can shrink each block\u2019s capacity, and hence, how many tokens we can afford to\\nroute around each block.\\nThere are two learned routing schemes we consider (see figure 2): token-choice and expert-choice.\\nIn token-choice routing, a router produces per-token probability distributions across computational\\npaths (e.g., across expert identities in MoE Transformers). Tokens are then shuttled to the path\\nthey prefer\u2014i.e., that with the highest probability\u2014and auxiliary losses ensure that all tokens don\u2019t\\nconverge to the same path. Token-choice routing can have load balancing problems since there isn\u2019t a\\nguarantee that tokens divide themselves appropriately between the possible paths. \u201cExpert choice\\nrouting\u201d flips this recipe on its head: rather than having tokens choose the path they prefer, each\\npath instead chooses the top- \ud835\udc58tokens based on the tokens\u2019 preferences. This ensures a perfect load\\nbalance since \ud835\udc58tokens are guaranteed to be shuttled to each path. However, it could result in over- or\\nunder-processing of some tokens, since some tokens may be among the top- \ud835\udc58for multiple paths, or\\nfor none of them.\\nWe decided to leverage expert-choice routing for a few reasons. First, it obviates the need for an\\nauxiliary balancing loss. Second, since the top- \ud835\udc58operation depends on the magnitude of the router\\nweights, this routing scheme allows for relative routing weights to help determine which tokens most\\nneed the block\u2019s computations; routers can try to ensurethat the most critical tokens are among the\\ntop-\ud835\udc58by setting their weight appropriately, which is not possible with token-choice routing schemes.\\nFor our specific use-case, wherein one computational path is essentially a null operation, it might\\nbe critical that important tokens are routed away from the null operation. Third, because we only\\nroute through two paths, a single top- \ud835\udc58operation can efficiently split the tokens into two mutually\\nexclusive sets, one for each computational path, preventing the over- or under-processing problem\\nmentioned above.\\n5\\n\\n=== Page 6 ===\\nMixture-of-Depths: Dynamically allocating compute in transformer-based language models\\nFigure 2|Routing schemes. Tokens are funnelled to the computational path of their choice when\\nusing token-choice routing (left). If a given path exceeds its capacity (e.g., more than two tokens in\\nthis example) then surplus tokens must be dropped (purple token). The exact token that is ultimately\\ndropped depends on the precise implementation in the underlying code. For example, priority is\\noften given to those tokens that come earlier in the sequence or batch order. With expert-choice\\nrouting (middle), precisely \ud835\udc58(in this case, two) tokens are chosen per path using a top- \ud835\udc58mechanism\\nacross the tokens\u2019 router weights. Here, tokens are dropped if they are not among the top- \ud835\udc58with\\nrespect to any given path (orange token), and some tokens may even be funnelled to multiple paths\\n(yellow token). In this work we deploy expert-choice routing (right). However, because we use just\\na single path, we leverage the implicit knowledge that tokens will be dropped if \ud835\udc58is less than the\\nsequence length so that we can route tokens away from the self-attention and MLP computations,\\nthus expending fewer FLOPs in a given forward pass of the model.\\n3.4. Routing implementation\\nAs a reminder of the high-level intuition, each token is processed by a router to produce a scalar\\nweight, and the top- \ud835\udc58weights are then used to choose the token identities that will route through a\\ntransformer\u2019s block, which comprises self-attention and the subsequent MLP.\\nSuppose we have the set of token embeddings in a sequence of length \ud835\udc46for a given layer \ud835\udc59; that\\nis\ud835\udc4b\ud835\udc59={\ud835\udc65\ud835\udc59\\n\ud835\udc56|\ud835\udc56is an integer, 1\u2264\ud835\udc56\u2264\ud835\udc46}. The router weight for a given token embedding is a scalar\\nproduced as a result of a linear projection, \ud835\udc5f\ud835\udc59\\n\ud835\udc56=\ud835\udc64\ud835\udc47\\n\ud835\udf03\ud835\udc65\ud835\udc59\\n\ud835\udc56.\\nOur goal is to use these router weights to determine the output of a block\u2019s computation of each\\ntoken. Suppose \ud835\udc43\ud835\udefd(\ud835\udc45\ud835\udc59)is the\ud835\udefd-th percentile of the set of router weights \ud835\udc45\ud835\udc59, where\ud835\udefd=1\u2212\ud835\udc36/\ud835\udc46and\ud835\udc36\\nis the user-defined capacity per batch element (an integer < \ud835\udc46that defines the number of tokens from\\na sequence that will be processed by a given function). A block\u2019s output for a given token is:\\n\ud835\udc65\ud835\udc59+1\\n\ud835\udc56=(\\n\ud835\udc5f\ud835\udc59\\n\ud835\udc56\ud835\udc53\ud835\udc56(\u02dc\ud835\udc4b\ud835\udc59)+\ud835\udc65\ud835\udc59\\n\ud835\udc56,if\ud835\udc5f\ud835\udc59\\n\ud835\udc56> \ud835\udc43\ud835\udefd(\ud835\udc45\ud835\udc59)\\n\ud835\udc65\ud835\udc59\\n\ud835\udc56, if\ud835\udc5f\ud835\udc59\\n\ud835\udc56< \ud835\udc43\ud835\udefd(\ud835\udc45\ud835\udc59)(1)\\nHere, \u02dc\ud835\udc4b\ud835\udc59is the set of tokens whose router values \ud835\udc5f\ud835\udc59\\n\ud835\udc56> \ud835\udc43\ud835\udefd(\ud835\udc45\ud835\udc59)(that is, the \u201ctop-k\u201d tokens), and \ud835\udc53\\ncomprises self-attention and the subsequent MLP. Note that the output for a given token \ud835\udc65\ud835\udc59+1\\n\ud835\udc56might\\ndepend on other tokens \ud835\udc65\ud835\udc59\\n\ud835\udc56\u2260\ud835\udc57because of the self-attention operation. The cardinality of \u02dc\ud835\udc4b\ud835\udc59is\ud835\udc36(or\ud835\udc58):\\nthe user-defined capacity. Therefore, the mixture-of-depths transformer accrues compute savings\\n6\",\"annotations\":null}", "tool_call_id": "toolu_016pq5cTYejshj73Abzp3wiF"}, {"role": "assistant", "content": "Perfect! Now I have a clear understanding of the paper. This is about \"Mixture-of-Depths\" (MoD) transformers by David Raposo et al. from Google DeepMind. Let me search GitHub for unofficial implementations of this paper.", "tool_calls": [{"id": "toolu_01RMUtMQsnJf8QaJYvT2jno6", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"mixture of depths transformer implementation\", \"perPage\": 20}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":6,\\\"incomplete_results\\\":false,\\\"items\\\":[{\\\"id\\\":785664688,\\\"name\\\":\\\"Mixture-of-depths\\\",\\\"full_name\\\":\\\"astramind-ai/Mixture-of-depths\\\",\\\"description\\\":\\\"Unofficial implementation for the paper \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":171,\\\"forks_count\\\":7,\\\"open_issues_count\\\":5,\\\"updated_at\\\":\\\"2025-09-19T02:56:57Z\\\",\\\"created_at\\\":\\\"2024-04-12T11:07:48Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":782269816,\\\"name\\\":\\\"Mixture-of-Depths\\\",\\\"full_name\\\":\\\"kyegomez/Mixture-of-Depths\\\",\\\"description\\\":\\\"Implementation of the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":106,\\\"forks_count\\\":7,\\\"open_issues_count\\\":7,\\\"updated_at\\\":\\\"2025-09-19T03:52:12Z\\\",\\\"created_at\\\":\\\"2024-04-05T00:51:20Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":782847289,\\\"name\\\":\\\"mixture-of-depths\\\",\\\"full_name\\\":\\\"sramshetty/mixture-of-depths\\\",\\\"description\\\":\\\"An unofficial implementation of \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/sramshetty/mixture-of-depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":36,\\\"forks_count\\\":3,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2025-09-05T01:19:59Z\\\",\\\"created_at\\\":\\\"2024-04-06T07:51:03Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":874565778,\\\"name\\\":\\\"Router-Tuning-Mixture-of-Depths\\\",\\\"full_name\\\":\\\"CASE-Lab-UMD/Router-Tuning-Mixture-of-Depths\\\",\\\"description\\\":\\\"The open-source Mixture of Depths code and the official implementation of the paper \\\\\\\"Router-Tuning: A Simple and Effective Approach for Enabling Dynamic Depth in Transformers. (EMNLP 2025)\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/CASE-Lab-UMD/Router-Tuning-Mixture-of-Depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":16,\\\"forks_count\\\":2,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2025-09-15T08:40:03Z\\\",\\\"created_at\\\":\\\"2024-10-18T04:11:52Z\\\",\\\"topics\\\":[\\\"deep-learning\\\",\\\"large-language-models\\\",\\\"machine-learning\\\",\\\"mixture-of-depths\\\",\\\"neural-network\\\",\\\"parameter-efficient-fine-tuning\\\"],\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":783121754,\\\"name\\\":\\\"MoE-LLM\\\",\\\"full_name\\\":\\\"eclouder/MoE-LLM\\\",\\\"description\\\":\\\"Implementation of the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/eclouder/MoE-LLM\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":2,\\\"forks_count\\\":0,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2024-04-22T08:48:24Z\\\",\\\"created_at\\\":\\\"2024-04-07T02:04:36Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":809894170,\\\"name\\\":\\\"MH-MoDE\\\",\\\"full_name\\\":\\\"dav3794/MH-MoDE\\\",\\\"description\\\":\\\"Implementation of Multi-Head Mixture-of-Depths-and-Experts Transformer for NLP course.\\\",\\\"html_url\\\":\\\"https://github.com/dav3794/MH-MoDE\\\",\\\"language\\\":\\\"Jupyter Notebook\\\",\\\"stargazers_count\\\":0,\\\"forks_count\\\":0,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2024-06-18T11:31:36Z\\\",\\\"created_at\\\":\\\"2024-06-03T16:48:16Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"}]}\",\"annotations\":null}", "tool_call_id": "toolu_01RMUtMQsnJf8QaJYvT2jno6"}, {"role": "assistant", "content": "Great! I found several implementations. Let me also search with different keywords to make sure I'm not missing any popular ones:", "tool_calls": [{"id": "toolu_01W2SKQXARmNHP9uBXf2bCmK", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"mixture-of-depths MoD transformer\", \"perPage\": 20}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":1,\\\"incomplete_results\\\":false,\\\"items\\\":[{\\\"id\\\":809894170,\\\"name\\\":\\\"MH-MoDE\\\",\\\"full_name\\\":\\\"dav3794/MH-MoDE\\\",\\\"description\\\":\\\"Implementation of Multi-Head Mixture-of-Depths-and-Experts Transformer for NLP course.\\\",\\\"html_url\\\":\\\"https://github.com/dav3794/MH-MoDE\\\",\\\"language\\\":\\\"Jupyter Notebook\\\",\\\"stargazers_count\\\":0,\\\"forks_count\\\":0,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2024-06-18T11:31:36Z\\\",\\\"created_at\\\":\\\"2024-06-03T16:48:16Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"}]}\",\"annotations\":null}", "tool_call_id": "toolu_01W2SKQXARmNHP9uBXf2bCmK"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_01LkNdg7EwFuBY2fvPxy7AtG", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"\\\"Mixture-of-Depths\\\" \\\"Dynamically allocating compute\\\"\", \"perPage\": 20}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":5,\\\"incomplete_results\\\":false,\\\"items\\\":[{\\\"id\\\":785664688,\\\"name\\\":\\\"Mixture-of-depths\\\",\\\"full_name\\\":\\\"astramind-ai/Mixture-of-depths\\\",\\\"description\\\":\\\"Unofficial implementation for the paper \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":171,\\\"forks_count\\\":7,\\\"open_issues_count\\\":5,\\\"updated_at\\\":\\\"2025-09-19T02:56:57Z\\\",\\\"created_at\\\":\\\"2024-04-12T11:07:48Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":782269816,\\\"name\\\":\\\"Mixture-of-Depths\\\",\\\"full_name\\\":\\\"kyegomez/Mixture-of-Depths\\\",\\\"description\\\":\\\"Implementation of the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":106,\\\"forks_count\\\":7,\\\"open_issues_count\\\":7,\\\"updated_at\\\":\\\"2025-09-19T03:52:12Z\\\",\\\"created_at\\\":\\\"2024-04-05T00:51:20Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":782847289,\\\"name\\\":\\\"mixture-of-depths\\\",\\\"full_name\\\":\\\"sramshetty/mixture-of-depths\\\",\\\"description\\\":\\\"An unofficial implementation of \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/sramshetty/mixture-of-depths\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":36,\\\"forks_count\\\":3,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2025-09-05T01:19:59Z\\\",\\\"created_at\\\":\\\"2024-04-06T07:51:03Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":784596511,\\\"name\\\":\\\"Mixture-of-Depths-Jax\\\",\\\"full_name\\\":\\\"dtunai/Mixture-of-Depths-Jax\\\",\\\"description\\\":\\\"Jax module for the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/dtunai/Mixture-of-Depths-Jax\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":3,\\\"forks_count\\\":0,\\\"open_issues_count\\\":13,\\\"updated_at\\\":\\\"2024-07-18T20:50:24Z\\\",\\\"created_at\\\":\\\"2024-04-10T06:56:02Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"},{\\\"id\\\":783121754,\\\"name\\\":\\\"MoE-LLM\\\",\\\"full_name\\\":\\\"eclouder/MoE-LLM\\\",\\\"description\\\":\\\"Implementation of the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"\\\",\\\"html_url\\\":\\\"https://github.com/eclouder/MoE-LLM\\\",\\\"language\\\":\\\"Python\\\",\\\"stargazers_count\\\":2,\\\"forks_count\\\":0,\\\"open_issues_count\\\":0,\\\"updated_at\\\":\\\"2024-04-22T08:48:24Z\\\",\\\"created_at\\\":\\\"2024-04-07T02:04:36Z\\\",\\\"private\\\":false,\\\"fork\\\":false,\\\"archived\\\":false,\\\"default_branch\\\":\\\"main\\\"}]}\",\"annotations\":null}", "tool_call_id": "toolu_01LkNdg7EwFuBY2fvPxy7AtG"}, {"role": "assistant", "content": "Let me also search for any repositories that might reference the paper authors:", "tool_calls": [{"id": "toolu_01Ua9jCQ7hjGdUYU7VXwLKNi", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"\\\"David Raposo\\\" \\\"Mixture-of-Depths\\\"\", \"perPage\": 10}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":0,\\\"incomplete_results\\\":false,\\\"items\\\":[]}\",\"annotations\":null}", "tool_call_id": "toolu_01Ua9jCQ7hjGdUYU7VXwLKNi"}, {"role": "assistant", "content": "Now let me check if there are any other variations or if I missed anything by searching for \"MoD transformer\":", "tool_calls": [{"id": "toolu_013KmWY3TuiCqVCnbiuSwojA", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"MoD transformer conditional compute\", \"perPage\": 20}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":0,\\\"incomplete_results\\\":false,\\\"items\\\":[]}\",\"annotations\":null}", "tool_call_id": "toolu_013KmWY3TuiCqVCnbiuSwojA"}, {"role": "assistant", "content": "Let me also check for repositories that might be implementing the paper with different naming:", "tool_calls": [{"id": "toolu_01HsxRuSrZEKiYRD9Mcne1jX", "type": "function", "function": {"name": "github-search_repositories", "arguments": "{\"query\": \"\\\"dynamic compute allocation\\\" transformer\", \"perPage\": 10}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"total_count\\\":0,\\\"incomplete_results\\\":false,\\\"items\\\":[]}\",\"annotations\":null}", "tool_call_id": "toolu_01HsxRuSrZEKiYRD9Mcne1jX"}, {"role": "assistant", "content": "Now let me get more details about the top repositories to make sure I identify the best one. Let me examine the top candidates:", "tool_calls": [{"id": "toolu_01UiRHUt1vyFTZoExb4w1g2a", "type": "function", "function": {"name": "github-get_file_contents", "arguments": "{\"owner\": \"astramind-ai\", \"repo\": \"Mixture-of-depths\", \"path\": \"/\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"[{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\".gitignore\\\",\\\"path\\\":\\\".gitignore\\\",\\\"size\\\":260,\\\"sha\\\":\\\"db6273ba8530b15d4224a3cb55e8462fefec64ce\\\",\\\"url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/contents/.gitignore?ref=aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths/blob/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/.gitignore\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/astramind-ai/Mixture-of-depths/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/.gitignore\\\"},{\\\"type\\\":\\\"dir\\\",\\\"name\\\":\\\"MoD\\\",\\\"path\\\":\\\"MoD\\\",\\\"sha\\\":\\\"42275bd76e3823e5ad1050c5566e0819fe9d7ecb\\\",\\\"url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/contents/MoD?ref=aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths/tree/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/MoD\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"README.md\\\",\\\"path\\\":\\\"README.md\\\",\\\"size\\\":2539,\\\"sha\\\":\\\"3b64b82fd62acd1dc75a368ccc2d87f640ad0b58\\\",\\\"url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/contents/README.md?ref=aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths/blob/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/README.md\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/astramind-ai/Mixture-of-depths/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/README.md\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"setup.py\\\",\\\"path\\\":\\\"setup.py\\\",\\\"size\\\":769,\\\"sha\\\":\\\"5f2a08831a8b8684c321081fee35b98f66adc9c1\\\",\\\"url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/contents/setup.py?ref=aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths/blob/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/setup.py\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/astramind-ai/Mixture-of-depths/aff9e74fc9c5a30d2c59dc36767f1f0fd86255e8/setup.py\\\"}]\",\"annotations\":null}", "tool_call_id": "toolu_01UiRHUt1vyFTZoExb4w1g2a"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_01WzpzhhizKMvszJk1WR2S4y", "type": "function", "function": {"name": "github-get_file_contents", "arguments": "{\"owner\": \"kyegomez\", \"repo\": \"Mixture-of-Depths\", \"path\": \"/\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"[{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\".DS_Store\\\",\\\"path\\\":\\\".DS_Store\\\",\\\"size\\\":6148,\\\"sha\\\":\\\"5008ddfcf53c02e82d7eee2e57c38e5672ef89f6\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/.DS_Store?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/.DS_Store\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/.DS_Store\\\"},{\\\"type\\\":\\\"dir\\\",\\\"name\\\":\\\".github\\\",\\\"path\\\":\\\".github\\\",\\\"sha\\\":\\\"2ef6e78ea3e51ddafb2e577882a429a5c002bd90\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/.github?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/tree/597febe17e8942ec5c999dff5de680208fa55659/.github\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\".gitignore\\\",\\\"path\\\":\\\".gitignore\\\",\\\"size\\\":3108,\\\"sha\\\":\\\"36b36efb57965d11e32006f54bcaff44832fd65b\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/.gitignore?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/.gitignore\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/.gitignore\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\".pre-commit-config.yaml\\\",\\\"path\\\":\\\".pre-commit-config.yaml\\\",\\\"size\\\":466,\\\"sha\\\":\\\"ae0a4fc0c2dd9408228bb959699e10b94dc39c1b\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/.pre-commit-config.yaml?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/.pre-commit-config.yaml\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/.pre-commit-config.yaml\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\".readthedocs.yml\\\",\\\"path\\\":\\\".readthedocs.yml\\\",\\\"size\\\":159,\\\"sha\\\":\\\"fbdc74ec77285c26f01ba309c565c0018c36b1e7\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/.readthedocs.yml?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/.readthedocs.yml\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/.readthedocs.yml\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"LICENSE\\\",\\\"path\\\":\\\"LICENSE\\\",\\\"size\\\":1074,\\\"sha\\\":\\\"ca69c7eb4955d82bcc187d8b510746d618eb0471\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/LICENSE?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/LICENSE\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/LICENSE\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"README.md\\\",\\\"path\\\":\\\"README.md\\\",\\\"size\\\":808,\\\"sha\\\":\\\"2ddff931477c167010a58be340cb85f65acebafa\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/README.md?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/README.md\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/README.md\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"agorabanner.png\\\",\\\"path\\\":\\\"agorabanner.png\\\",\\\"size\\\":198637,\\\"sha\\\":\\\"030ad15560bb5b6154592b392fd594dceeccd4e7\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/agorabanner.png?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/agorabanner.png\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/agorabanner.png\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"example.py\\\",\\\"path\\\":\\\"example.py\\\",\\\"size\\\":269,\\\"sha\\\":\\\"84c0909bea1ba53d4f7a44a8e2382f7b8b1d4c49\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/example.py?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/example.py\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/example.py\\\"},{\\\"type\\\":\\\"dir\\\",\\\"name\\\":\\\"mixture_of_depths\\\",\\\"path\\\":\\\"mixture_of_depths\\\",\\\"sha\\\":\\\"7e8ac710a6b66fd26db01717d11ddfcebfae0bd4\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/mixture_of_depths?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/tree/597febe17e8942ec5c999dff5de680208fa55659/mixture_of_depths\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"pyproject.toml\\\",\\\"path\\\":\\\"pyproject.toml\\\",\\\"size\\\":1406,\\\"sha\\\":\\\"fe792f05bf7b93739d9b4a6d67d9356a5ab64a69\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/pyproject.toml?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/pyproject.toml\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/pyproject.toml\\\"},{\\\"type\\\":\\\"file\\\",\\\"name\\\":\\\"requirements.txt\\\",\\\"path\\\":\\\"requirements.txt\\\",\\\"size\\\":45,\\\"sha\\\":\\\"a4f54ed2318c83ed474c011cf7306272bad6c8b0\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/requirements.txt?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/597febe17e8942ec5c999dff5de680208fa55659/requirements.txt\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/597febe17e8942ec5c999dff5de680208fa55659/requirements.txt\\\"},{\\\"type\\\":\\\"dir\\\",\\\"name\\\":\\\"scripts\\\",\\\"path\\\":\\\"scripts\\\",\\\"sha\\\":\\\"ce651d419f3a1eef38ad90ae9f4d1981b9a6edd6\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/scripts?ref=597febe17e8942ec5c999dff5de680208fa55659\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/tree/597febe17e8942ec5c999dff5de680208fa55659/scripts\\\"}]\",\"annotations\":null}", "tool_call_id": "toolu_01WzpzhhizKMvszJk1WR2S4y"}, {"role": "assistant", "content": "Let me read the README files to understand the quality and completeness of these implementations:", "tool_calls": [{"id": "toolu_012JtwTEoeDMieydR4K1rpfh", "type": "function", "function": {"name": "github-get_file_contents", "arguments": "{\"owner\": \"astramind-ai\", \"repo\": \"Mixture-of-depths\", \"path\": \"README.md\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"content\\\":\\\"# Unofficial implementation for the paper \\\\\\\"Mixture-of-Depths\\\\\\\"\\\\n\\\\n\\\\n## Introduction\\\\nThis is an unofficial implementation for the paper [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/abs/2404.02258)\\\\n\\\\n## Currently supported models\\\\n\\\\n| Model  | Supported? |\\\\n| ------------- | ------------- |\\\\n| Mistral  |  \u2705 |\\\\n| Mixtral  |  \u2705 |\\\\n| LLama  |  \u2705 |\\\\n| LLama2  |  \u2705 |\\\\n| LLama3  |  \u2705 |\\\\n| Gemma  |  \u2705 |\\\\n| BLOOMZ  |  \u2705 |\\\\n| BLOOM  |  \u2705 |\\\\n| DeepSeek  |  \u2705 |\\\\n| Phi (1.5 \\\\u0026 2)  |  \u2705 |\\\\n| Qwen2  |  \u2705 |\\\\n| StarCoder2  |  \u2705 |\\\\n| Qwen2-MoE  |  \u2753 |\\\\n| Solar  |  \u2753 |\\\\n| Baichuan  |  \u274c |\\\\n| ChatGLM3  |  \u274c |\\\\n| InternLM  |  \u274c |\\\\n| Olmo  |  \u274c |\\\\n| XVERSE  |  \u274c |\\\\n| Yi  |  \u274c |\\\\n| Yuan  |  \u274c |\\\\n\\\\n## \ud83d\udcbe Installation\\\\n```bash\\\\npip install mixture-of-depth\\\\n```\\\\nBoth **Linux**, **Windows** and **MacOS** are supported.\\\\n## \ud83c\udfc1 Quick Start\\\\n\\\\n### High-level API (tranformers-compatible)\\\\n```python\\\\nfrom transformers import AutoModelForCausalLM\\\\nfrom MoD import apply_mod_to_hf\\\\n\\\\n# Initialize your model from an available hf model\\\\nmodel= AutoModelForCausalLM.from_pretrained(\\\\\\\"some-repo/some-model\\\\\\\")\\\\n# Convert the model to include the mixture of depths layers\\\\nmodel = apply_mod_to_hf(model)\\\\n# train the model\\\\n# ...\\\\n# save the model\\\\nmodel.save_pretrained('some_local_directory')\\\\n```\\\\n### Loading the converted Model\\\\nTo utilize the converted model, you will need to load the model from the AutoClass. Below is an example demonstrating how to load the model from a local directory:\\\\n```python\\\\nfrom MoD import AutoMoDModelForCausalLM\\\\n\\\\n# Replace 'path_to_your_model' with the actual path to your model's directory\\\\nmodel = AutoMoDModelForCausalLM.from_pretrained('path_to_your_model')\\\\n```\\\\n### Using generate()\\\\nBefore calling the hf generate() method please explicitly use eval() on the model\\\\n\\\\n## \ud83e\udef1\ud83c\udffc\u200d\ud83e\udef2\ud83c\udffd Contributing\\\\nWe welcome contributions from the community, whether it's adding new features, improving documentation, or reporting bugs. Please refer to our contribution guidelines before making a pull request.\\\\n\\\\n## \ud83d\udcdc License\\\\nThis repo is open-sourced under the Apache-2.0 license.\\\\n\\\\n## Citation\\\\nIf you use our code in your research, please cite it using the following Bibtex entry:\\\\n\\\\n```bibtex\\\\n@article{MoD2024,\\\\n  title={Unofficial implementation for the paper \\\\\\\"Mixture-of-Depths\\\\\\\"},\\\\n  author={AstraMind AI},\\\\n  journal={https://github.com/astramind-ai/Mixture-of-depths},\\\\n  year={2024}\\\\n}\\\\n```\\\\n## Support\\\\nFor questions, issues, or support, please open an issue on our GitHub repository.\\\\n\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/astramind-ai/Mixture-of-depths/main/README.md\\\",\\\"encoding\\\":\\\"text\\\",\\\"git_url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/git/blobs/3b64b82fd62acd1dc75a368ccc2d87f640ad0b58\\\",\\\"html_url\\\":\\\"https://github.com/astramind-ai/Mixture-of-depths/blob/main/README.md\\\",\\\"name\\\":\\\"README.md\\\",\\\"path\\\":\\\"README.md\\\",\\\"sha\\\":\\\"3b64b82fd62acd1dc75a368ccc2d87f640ad0b58\\\",\\\"size\\\":2539,\\\"type\\\":\\\"file\\\",\\\"url\\\":\\\"https://api.github.com/repos/astramind-ai/Mixture-of-depths/contents/README.md?ref=main\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_012JtwTEoeDMieydR4K1rpfh"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_019sQz7qapJK7Bdzp4hnwnAx", "type": "function", "function": {"name": "github-get_file_contents", "arguments": "{\"owner\": \"kyegomez\", \"repo\": \"Mixture-of-Depths\", \"path\": \"README.md\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"content\\\":\\\"[![Multi-Modality](agorabanner.png)](https://discord.gg/qUtxnK2NMf)\\\\n\\\\n## Mixture of Depths Scaling\\\\nImplementation of the paper: \\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\". From the paper: \\\\\\\"These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50% faster to step during post-training sampling.\\\\\\\"\\\\n\\\\n\\\\n## install \\\\n`pip3 install mixture-of-depths`\\\\n\\\\n## usage\\\\n```python\\\\nimport torch\\\\nfrom mixture_of_depths.main import MoD\\\\n\\\\nx = torch.randn(1, 1000, 512)\\\\n# mask = torch.ones(1)\\\\n\\\\n# Model\\\\nmodel = MoD(\\\\n    seq_len=1000,\\\\n    dim=512,\\\\n    capacity_factor=0.12,\\\\n    vocab_size=10000,\\\\n    transformer_depth=8,\\\\n)\\\\n\\\\n# Model\\\\nout = model(x)\\\\nprint(out)\\\\n```\\\\n\\\\n# License\\\\nMIT\\\\n\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/kyegomez/Mixture-of-Depths/main/README.md\\\",\\\"encoding\\\":\\\"text\\\",\\\"git_url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/git/blobs/2ddff931477c167010a58be340cb85f65acebafa\\\",\\\"html_url\\\":\\\"https://github.com/kyegomez/Mixture-of-Depths/blob/main/README.md\\\",\\\"name\\\":\\\"README.md\\\",\\\"path\\\":\\\"README.md\\\",\\\"sha\\\":\\\"2ddff931477c167010a58be340cb85f65acebafa\\\",\\\"size\\\":808,\\\"type\\\":\\\"file\\\",\\\"url\\\":\\\"https://api.github.com/repos/kyegomez/Mixture-of-Depths/contents/README.md?ref=main\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_019sQz7qapJK7Bdzp4hnwnAx"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_01E5stEAdiQdp1HEwyoBEXyf", "type": "function", "function": {"name": "github-get_file_contents", "arguments": "{\"owner\": \"sramshetty\", \"repo\": \"mixture-of-depths\", \"path\": \"README.md\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\\"content\\\":\\\"# Mixture of Depths\\\\nAn unofficial implementation of [\\\\\\\"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\\\\\\\"](https://arxiv.org/abs/2404.02258)\\\\n\\\\n\\\\n## Setup\\\\n- First follow instructions for setting up your environment for Llama 2 [here](https://github.com/meta-llama/llama).\\\\n- Then:\\\\n```bash\\\\npip install einops\\\\n```\\\\n\\\\n\\\\n## Details\\\\n- Implementing MoD in Llama 2\\\\n- Follow paper's configuration with some assumptions.\\\\n    - Route every other layer\\\\n    - Training configurations for both causal inference methods proposed\\\\n- Notes on auxiliary router for causal inference:\\\\n    - Currently, we train it separately after MoD Llama is trained.\\\\n    - Simple task as we achieve high token prediction accuracy quickly, which is further simplified by using a simple dataset.\\\\n\\\\n- `MoD_training.ipynb` demonstrates training and was used for the results below.\\\\n- `MoD_sampling.ipynb` demonstrates generation with each method.\\\\n\\\\n## Results\\\\n- 50 million parameter model\\\\n    - C4\\\\n        - Baseline after 1 epoch:\\\\n            - Loss: 3.73\\\\n            - Samples/sec: 6.79\\\\n        - MoD w/ Auxiliary Loss after 1 epoch:\\\\n            - Loss: 3.81\\\\n            - Samples/sec: 8.15\\\\n        - MoD w/ Auxiliary Router after 1 epoch:\\\\n            - Loss: 4.19\\\\n            - Samples/sec: 7.64\\\\n    - Tiny Stories\\\\n        - Baseline after 5 epochs:\\\\n            - Loss: 2.46\\\\n            - Samples/sec: 11.22\\\\n        - MoD w/ Auxiliary Loss after 5 epochs:\\\\n            - Loss: 2.55\\\\n            - Samples/sec: 11.33\\\\n        - MoD w/ Auxiliary Router after 5 epochs:\\\\n            - Loss: 2.48\\\\n            - Auxilairy Router Causal Loss: 0.15 \\\\n            - Samples/sec: 11.54\\\\n\\\\n## TODO\\\\n- [x] Validate\\\\n- [x] Sampling methods\\\\n    - [x] Auxiliary loss\\\\n    - [x] \\\\\\\"Second\\\\\\\" router\\\\n\\\\n\\\\n## Citations\\\\n```bibtex\\\\n@misc{raposo2024mixtureofdepths,\\\\n    title={Mixture-of-Depths: Dynamically allocating compute in transformer-based language models}, \\\\n    author={David Raposo and Sam Ritter and Blake Richards and Timothy Lillicrap and Peter Conway Humphreys and Adam Santoro},\\\\n    year={2024},\\\\n    eprint={2404.02258},\\\\n    archivePrefix={arXiv},\\\\n    primaryClass={cs.LG}\\\\n}\\\\n```\\\\n\\\",\\\"download_url\\\":\\\"https://raw.githubusercontent.com/sramshetty/mixture-of-depths/main/README.md\\\",\\\"encoding\\\":\\\"text\\\",\\\"git_url\\\":\\\"https://api.github.com/repos/sramshetty/mixture-of-depths/git/blobs/a651911f3a4287a1b84c1627805645f5d92a7012\\\",\\\"html_url\\\":\\\"https://github.com/sramshetty/mixture-of-depths/blob/main/README.md\\\",\\\"name\\\":\\\"README.md\\\",\\\"path\\\":\\\"README.md\\\",\\\"sha\\\":\\\"a651911f3a4287a1b84c1627805645f5d92a7012\\\",\\\"size\\\":2147,\\\"type\\\":\\\"file\\\",\\\"url\\\":\\\"https://api.github.com/repos/sramshetty/mixture-of-depths/contents/README.md?ref=main\\\"}\",\"annotations\":null}", "tool_call_id": "toolu_01E5stEAdiQdp1HEwyoBEXyf"}, {"role": "assistant", "content": "Now let me check if there's a result.json file in the workspace to understand the expected format:", "tool_calls": [{"id": "toolu_01RC8jNApQZ9kHe3PhsXcXiZ", "type": "function", "function": {"name": "filesystem-list_directory", "arguments": "{\"path\": \"/workspace/dumps/workspace\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"[DIR] .pdf_tools_tempfiles\\n[FILE] paper.pdf\\n[FILE] result.json\",\"annotations\":null}", "tool_call_id": "toolu_01RC8jNApQZ9kHe3PhsXcXiZ"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_013e4Uz9sk1xJwmzCy6MJPfr", "type": "function", "function": {"name": "filesystem-read_file", "arguments": "{\"path\": \"/workspace/dumps/workspace/result.json\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"{\\n    \\\"URL\\\": \\\"\\\"\\n}\",\"annotations\":null}", "tool_call_id": "toolu_013e4Uz9sk1xJwmzCy6MJPfr"}, {"role": "assistant", "content": "Perfect! Now I have all the information I need. Based on my analysis of the GitHub search results, I can identify the repository with the most stars that implements the \"Mixture-of-Depths\" paper.\n\nFrom the search results, I found several unofficial implementations:\n\n1. **astramind-ai/Mixture-of-depths** - 171 stars (highest)\n2. **kyegomez/Mixture-of-Depths** - 106 stars  \n3. **sramshetty/mixture-of-depths** - 36 stars\n4. **CASE-Lab-UMD/Router-Tuning-Mixture-of-Depths** - 16 stars\n5. **dtunai/Mixture-of-Depths-Jax** - 3 stars\n6. **eclouder/MoE-LLM** - 2 stars\n\nThe repository with the most stars is **astramind-ai/Mixture-of-depths** with 171 stars. This implementation also appears to be quite comprehensive, supporting multiple model architectures (Mistral, Mixtral, LLama, LLama2, LLama3, Gemma, BLOOMZ, BLOOM, DeepSeek, Phi, Qwen2, StarCoder2) and provides a transformers-compatible high-level API.\n\nLet me update the result.json file:", "tool_calls": [{"id": "toolu_01KrWXL1Bjih3TTvM3UVT5yb", "type": "function", "function": {"name": "filesystem-write_file", "arguments": "{\"path\": \"/workspace/dumps/workspace/result.json\", \"content\": \"{\\n    \\\"URL\\\": \\\"https://github.com/astramind-ai/Mixture-of-depths\\\"\\n}\"}"}}]}, {"role": "tool", "content": "{\"type\":\"text\",\"text\":\"Successfully wrote to /workspace/dumps/workspace/result.json\",\"annotations\":null}", "tool_call_id": "toolu_01KrWXL1Bjih3TTvM3UVT5yb"}, {"role": "assistant", "content": null, "tool_calls": [{"id": "toolu_01AhqYn72jxzQkCbAXz2DzCV", "type": "function", "function": {"name": "local-claim_done", "arguments": ""}}]}, {"role": "tool", "content": "you have claimed the task is done!", "tool_call_id": "toolu_01AhqYn72jxzQkCbAXz2DzCV"}, {"role": "assistant", "content": "I have successfully completed the task! Here's what I found:\n\n**Paper Analysis:**\n- The paper is \"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\" by David Raposo et al. from Google DeepMind\n- It introduces a method to dynamically allocate compute in transformers by using a top-k routing mechanism to select which tokens participate in self-attention and MLP computations at each layer\n\n**GitHub Search Results:**\nI searched GitHub comprehensively and found several unofficial implementations. The repository with the most stars is:\n\n**astramind-ai/Mixture-of-depths** with **171 stars**\n\nThis implementation stands out because it:\n- Has the highest star count (171 stars)\n- Supports multiple popular model architectures (Mistral, Mixtral, LLama variants, Gemma, BLOOMZ, BLOOM, DeepSeek, Phi, Qwen2, StarCoder2)\n- Provides a transformers-compatible high-level API\n- Is actively maintained (last updated September 2025)\n- Has proper documentation and installation instructions\n\nI have updated the `result.json` file with the URL of this repository: `https://github.com/astramind-ai/Mixture-of-depths`"}], "key_stats": {"interaction_turns": 1, "tool_calls": 18, "agent_llm_requests": 19, "total_tokens": 640016, "input_tokens": 637583, "output_tokens": 2433, "total_turns": 20, "total_messages": 49, "truncations": 0, "user_input_turns": 1, "assistant_turns": 19}, "agent_cost": {"total_cost": 1.9492, "total_input_tokens": 637583, "total_output_tokens": 2433, "total_requests": 19}, "user_cost": {"total_cost": 0.0, "total_input_tokens": 0, "total_output_tokens": 0, "total_requests": 0}, "resumed": false, "session_id": "task_finalpool-git-repo_session", "history_file": "/workspace/dumps/conversation_history/task_finalpool-git-repo_session_history.jsonl", "pass": true}