{
    "pass": true,
    "messages": [
        {
            "role": "user",
            "content": "I'm looking for a paper on arxiv related to agentic reasoning. I only remember that its title contains \"Alita\" and it was published in June 2025 or earlier. Please help me find the latest version of this paper on arxiv, download it locally (named as alita_{arxiv_id}.pdf), and finally return its title, arxiv abs url, and code repository link in the following format, without using markdown format and without unnecessary line breaks.\n\ntitle: {title}\narxiv_abs_url: {arxiv_abs_url}\ncode_url: {code_url}"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_axFvI83qXpB981Puk56duS7g",
                    "type": "function",
                    "function": {
                        "name": "arxiv_local-search_papers",
                        "arguments": "{\"query\":\"Alita agent reasoning\", \"max_results\": 10, \"date_from\": \"2007-01-01\", \"date_to\": \"2025-06-30\", \"categories\": [\"cs.AI\", \"cs.CL\", \"cs.LG\"]}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 0,\\n  \\\"papers\\\": []\\n}\",\"annotations\":null}",
            "tool_call_id": "call_axFvI83qXpB981Puk56duS7g"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_SVDSfgneBU3g2o54tizQZNyt",
                    "type": "function",
                    "function": {
                        "name": "scholarly-search-arxiv",
                        "arguments": "{\"keyword\":\"Alita agentic reasoning\"}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"Search articles for Alita agentic reasoning:\\nTitle: Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\\nAuthors: Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, Xing Zhou, Dongrui Liu, Ling Yang, Yue Wu, Kaixuan Huang, Shilong Liu, Hongru Wang, Mengdi Wang\\nPublished: 2025-05-26\\nUpdated: 2025-05-26\\nPrimary Category: cs.AI\\nAll Categories: cs.AI\\nDOI: N/A\\nJournal Reference: N/A\\nComment: 9 pages, 3 figures\\nEntry ID: http://arxiv.org/abs/2505.20286v1\\nPDF URL: http://arxiv.org/pdf/2505.20286v1\\nAll Links: http://arxiv.org/abs/2505.20286v1||http://arxiv.org/pdf/2505.20286v1\\nSummary: Recent advances in large language models (LLMs) have enabled agents to\\nautonomously perform complex, open-ended tasks. However, many existing\\nframeworks depend heavily on manually predefined tools and workflows, which\\nhinder their adaptability, scalability, and generalization across domains. In\\nthis work, we introduce Alita--a generalist agent designed with the principle\\nof \\\"Simplicity is the ultimate sophistication,\\\" enabling scalable agentic\\nreasoning through minimal predefinition and maximal self-evolution. For minimal\\npredefinition, Alita is equipped with only one component for direct\\nproblem-solving, making it much simpler and neater than previous approaches\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\\ndesign enhances its potential to generalize to challenging questions, without\\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\\nAlita by providing a suite of general-purpose components to autonomously\\nconstruct, refine, and reuse external capabilities by generating task-related\\nmodel context protocols (MCPs) from open source, which contributes to scalable\\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\\nMathvista and PathVQA, outperforming many agent systems with far greater\\ncomplexity. More details will be updated at\\n$\\\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.\\n\\n\\nTitle: Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models\\nAuthors: Danqing Wang, Zhuorui Ye, Fei Fang, Lei Li\\nPublished: 2024-10-25\\nUpdated: 2024-10-25\\nPrimary Category: cs.AI\\nAll Categories: cs.AI, cs.CL\\nDOI: N/A\\nJournal Reference: N/A\\nComment: Working in progress\\nEntry ID: http://arxiv.org/abs/2410.20007v1\\nPDF URL: http://arxiv.org/pdf/2410.20007v1\\nAll Links: http://arxiv.org/abs/2410.20007v1||http://arxiv.org/pdf/2410.20007v1\\nSummary: Enhancing the reasoning capabilities of large language models (LLMs) is\\ncrucial for enabling them to tackle complex, multi-step problems. Multi-agent\\nframeworks have shown great potential in enhancing LLMs' reasoning\\ncapabilities. However, the lack of effective cooperation between LLM agents\\nhinders their performance, especially for multi-step reasoning tasks. This\\npaper proposes a novel cooperative multi-agent reasoning framework (CoPlanner)\\nby separating reasoning steps and assigning distinct duties to different\\nagents. CoPlanner consists of two LLM agents: a planning agent and a reasoning\\nagent. The planning agent provides high-level strategic hints, while the\\nreasoning agent follows these hints and infers answers. By training the\\nplanning agent's policy through the interactive reasoning process via Proximal\\nPolicy Optimization (PPO), the LLaMA-3-8B-based CoPlanner outperforms the\\nprevious best method by 9.94\\\\% on LogiQA and 3.09\\\\% on BBH. Our results\\ndemonstrate that the guidance from the planning agent and the effective\\ncooperation between the agents contribute to the superior performance of\\nCoPlanner in tackling multi-step reasoning problems.\\n\\n\\nTitle: GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments\\nAuthors: Hanlin Zhu, Tianyu Guo, Song Mei, Stuart Russell, Nikhil Ghosh, Alberto Bietti, Jiantao Jiao\\nPublished: 2025-09-26\\nUpdated: 2025-10-02\\nPrimary Category: cs.AI\\nAll Categories: cs.AI, cs.LG\\nDOI: N/A\\nJournal Reference: N/A\\nComment: 39 pages, 8 figures\\nEntry ID: http://arxiv.org/abs/2509.21998v2\\nPDF URL: http://arxiv.org/pdf/2509.21998v2\\nAll Links: http://arxiv.org/abs/2509.21998v2||http://arxiv.org/pdf/2509.21998v2\\nSummary: As LLMs are increasingly deployed as agents, agentic reasoning - the ability\\nto combine tool use, especially search, and reasoning - becomes a critical\\nskill. However, it is hard to disentangle agentic reasoning when evaluated in\\ncomplex environments and tasks. Current agent benchmarks often mix agentic\\nreasoning with challenging math reasoning, expert-level knowledge, and other\\nadvanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent,\\nwhere an LLM agent is required to solve grade-school-level reasoning problems,\\nbut is only presented with the question in the prompt without the premises that\\ncontain the necessary information to solve the task, and needs to proactively\\ncollect that information using tools. Although the original tasks are\\ngrade-school math problems, we observe that even frontier models like GPT-5\\nonly achieve 67% accuracy. To understand and analyze the agentic reasoning\\npatterns, we propose the concept of agentic reasoning graph: cluster the\\nenvironment's document embeddings into nodes, and map each tool call to its\\nnearest node to build a reasoning path. Surprisingly, we identify that the\\nability to revisit a previously visited node, widely taken as a crucial pattern\\nin static reasoning, is often missing for agentic reasoning for many models.\\nBased on the insight, we propose a tool-augmented test-time scaling method to\\nimprove LLM's agentic reasoning performance by adding tools to encourage models\\nto revisit. We expect our benchmark and the agentic reasoning framework to aid\\nfuture studies of understanding and pushing the boundaries of agentic\\nreasoning.\\n\\n\\nTitle: Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools\\nAuthors: Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin\\nPublished: 2025-02-07\\nUpdated: 2025-07-14\\nPrimary Category: cs.AI\\nAll Categories: cs.AI, cs.CL\\nDOI: N/A\\nJournal Reference: N/A\\nComment: ACL 2025\\nEntry ID: http://arxiv.org/abs/2502.04644v2\\nPDF URL: http://arxiv.org/pdf/2502.04644v2\\nAll Links: http://arxiv.org/abs/2502.04644v2||http://arxiv.org/pdf/2502.04644v2\\nSummary: We introduce Agentic Reasoning, a framework that enhances large language\\nmodel (LLM) reasoning by integrating external tool-using agents. Agentic\\nReasoning dynamically leverages web search, code execution, and structured\\nmemory to address complex problems requiring deep research. A key innovation in\\nour framework is the Mind-Map agent, which constructs a structured knowledge\\ngraph to store reasoning context and track logical relationships, ensuring\\ncoherence in long reasoning chains with extensive tool usage. Additionally, we\\nconduct a comprehensive exploration of the Web-Search agent, leading to a\\nhighly effective search mechanism that surpasses all prior approaches. When\\ndeployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA)\\namong public models and delivers performance comparable to OpenAI Deep\\nResearch, the leading proprietary model in this domain. Extensive ablation\\nstudies validate the optimal selection of agentic tools and confirm the\\neffectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning.\\nThe code is at: https://github.com/theworldofagents/Agentic-Reasoning\\n\\n\\nTitle: Reasoning-Aware Prompt Orchestration: A Foundation Model for Multi-Agent Language Model Coordination\\nAuthors: Hassen Dhrif\\nPublished: 2025-09-30\\nUpdated: 2025-09-30\\nPrimary Category: cs.MA\\nAll Categories: cs.MA, cs.AI\\nDOI: N/A\\nJournal Reference: N/A\\nComment: N/A\\nEntry ID: http://arxiv.org/abs/2510.00326v1\\nPDF URL: http://arxiv.org/pdf/2510.00326v1\\nAll Links: http://arxiv.org/abs/2510.00326v1||http://arxiv.org/pdf/2510.00326v1\\nSummary: The emergence of large language models has enabled sophisticated multi-agent\\nsystems, yet coordinating their reasoning capabilities through prompt\\nengineering remains challenging. We present a theoretically-grounded framework\\nfor dynamic prompt orchestration that enhances reasoning across multiple\\nspecialized agents. This framework addresses three core challenges: logical\\nconsistency preservation during agent transitions, reasoning-aware prompt\\nadaptation, and scalable coordination of distributed inference.\\n  Our approach formalizes agent states using prompt templates, reasoning\\ncontext vectors, and capability matrices. We prove system convergence to stable\\ncoordination patterns when step sizes satisfy $\\\\alpha < \\\\frac{1}{2L}$ where $L$\\nis the Lipschitz constant of the state transition function. We implement this\\nthrough a distributed architecture that dynamically routes reasoning tasks\\nwhile maintaining semantic coherence.\\n  Experimental results on 1,000 synthetic multi-agent conversations demonstrate\\na 42% reduction in reasoning latency, a 23% improvement in logical consistency\\nmeasured by ROUGE-L score, and an 89% success rate for task completion without\\ncontext loss across agent transitions. Ablation studies identify the consensus\\nmechanism as the primary performance driver, while revealing limitations:\\nperformance degrades beyond 10 agent transitions, and the system requires\\n76.5GB memory for 1,000 concurrent agents. These findings establish a new\\nparadigm for scalable reasoning in multi-agent systems, providing theoretical\\nfoundations for understanding reasoning emergence across coordinated language\\nmodels.\\n\\n\\nTitle: Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent\\nAuthors: Fatemeh Haji, Mazal Bethany, Maryam Tabar, Jason Chiang, Anthony Rios, Peyman Najafirad\\nPublished: 2024-09-17\\nUpdated: 2024-11-05\\nPrimary Category: cs.AI\\nAll Categories: cs.AI\\nDOI: N/A\\nJournal Reference: N/A\\nComment: N/A\\nEntry ID: http://arxiv.org/abs/2409.11527v2\\nPDF URL: http://arxiv.org/pdf/2409.11527v2\\nAll Links: http://arxiv.org/abs/2409.11527v2||http://arxiv.org/pdf/2409.11527v2\\nSummary: Multi-agent strategies have emerged as a promising approach to enhance the\\nreasoning abilities of Large Language Models (LLMs) by assigning specialized\\nroles in the problem-solving process. Concurrently, Tree of Thoughts (ToT)\\nmethods have shown potential in improving reasoning for complex\\nquestion-answering tasks by exploring diverse reasoning paths. A critical\\nlimitation in multi-agent reasoning is the 'Reasoner' agent's shallow\\nexploration of reasoning paths. While ToT strategies could help mitigate this\\nproblem, they may generate flawed reasoning branches, which could harm the\\ntrustworthiness of the final answer. To leverage the strengths of both\\nmulti-agent reasoning and ToT strategies, we introduce a novel approach\\ncombining ToT-based Reasoner agents with a Thought Validator agent. Multiple\\nReasoner agents operate in parallel, employing ToT to explore diverse reasoning\\npaths. The Thought Validator then scrutinizes these paths, considering a\\nReasoner's conclusion only if its reasoning is valid. This method enables a\\nmore robust voting strategy by discarding faulty reasoning paths, enhancing the\\nsystem's ability to tackle tasks requiring systematic and trustworthy\\nreasoning. Our method demonstrates superior performance compared to existing\\ntechniques when evaluated on the GSM8K dataset, outperforming the standard ToT\\nstrategy by an average 5.6% across four LLMs. The code and related content can\\nbe found in: https://github.com/SecureAIAutonomyLab/MA-ToT\\n\\n\\nTitle: When Do Introspection Axioms Matter for Multi-Agent Epistemic Reasoning?\\nAuthors: Yifeng Ding, Wesley H. Holliday, Cedegao Zhang\\nPublished: 2019-07-22\\nUpdated: 2019-07-22\\nPrimary Category: cs.LO\\nAll Categories: cs.LO, cs.MA\\nDOI: 10.4204/EPTCS.297.9\\nJournal Reference: EPTCS 297, 2019, pp. 121-139\\nComment: In Proceedings TARK 2019, arXiv:1907.08335\\nEntry ID: http://arxiv.org/abs/1907.09101v1\\nPDF URL: http://arxiv.org/pdf/1907.09101v1\\nAll Links: http://dx.doi.org/10.4204/EPTCS.297.9||http://arxiv.org/abs/1907.09101v1||http://arxiv.org/pdf/1907.09101v1\\nSummary: The early literature on epistemic logic in philosophy focused on reasoning\\nabout the knowledge or belief of a single agent, especially on controversies\\nabout \\\"introspection axioms\\\" such as the 4 and 5 axioms. By contrast, the later\\nliterature on epistemic logic in computer science and game theory has focused\\non multi-agent epistemic reasoning, with the single-agent 4 and 5 axioms\\nlargely taken for granted. In the relevant multi-agent scenarios, it is often\\nimportant to reason about what agent A believes about what agent B believes\\nabout what agent A believes; but it is rarely important to reason just about\\nwhat agent A believes about what agent A believes. This raises the question of\\nthe extent to which single-agent introspection axioms actually matter for\\nmulti-agent epistemic reasoning. In this paper, we formalize and answer this\\nquestion. To formalize the question, we first define a set of multi-agent\\nformulas that we call agent-alternating formulas, including formulas like Box_a\\nBox_b Box_a p but not formulas like Box_a Box_a p. We then prove, for the case\\nof belief, that if one starts with multi-agent K or KD, then adding both the 4\\nand 5 axioms (or adding the B axiom) does not allow the derivation of any new\\nagent-alternating formulas -- in this sense, introspection axioms do not\\nmatter. By contrast, we show that such conservativity results fail for\\nknowledge and multi-agent KT, though they hold with respect to a smaller class\\nof agent-nonrepeating formulas.\\n\\n\\nTitle: Augmenting Agent Platforms to Facilitate Conversation Reasoning\\nAuthors: David Lillis, Rem W. Collier`\\nPublished: 2015-08-11\\nUpdated: 2015-08-11\\nPrimary Category: cs.MA\\nAll Categories: cs.MA\\nDOI: 10.1007/978-3-642-22723-3_4\\nJournal Reference: In Languages, Methodologies, and Development Tools for Multi-Agent\\n  Systems - Third International Workshop, LADS 2010, Revised Selected Papers,\\n  Lecture Notes in Computer Science vol. 6822, pp. 56--75. Springer Berlin\\n  Heidelberg, 2011\\nComment: N/A\\nEntry ID: http://arxiv.org/abs/1508.02685v1\\nPDF URL: http://arxiv.org/pdf/1508.02685v1\\nAll Links: http://dx.doi.org/10.1007/978-3-642-22723-3_4||http://arxiv.org/abs/1508.02685v1||http://arxiv.org/pdf/1508.02685v1\\nSummary: Within Multi Agent Systems, communication by means of Agent Communication\\nLanguages (ACLs) has a key role to play in the co-operation, co-ordination and\\nknowledge-sharing between agents. Despite this, complex reasoning about agent\\nmessaging, and specifically about conversations between agents, tends not to\\nhave widespread support amongst general-purpose agent programming languages.\\n  ACRE (Agent Communication Reasoning Engine) aims to complement the existing\\nlogical reasoning capabilities of agent programming languages with the\\ncapability of reasoning about complex interaction protocols in order to\\nfacilitate conversations between agents. This paper outlines the aims of the\\nACRE project and gives details of the functioning of a prototype implementation\\nwithin the Agent Factory multi agent framework.\\n\\n\\nTitle: Guided Reasoning: A Non-Technical Introduction\\nAuthors: Gregor Betz\\nPublished: 2024-08-29\\nUpdated: 2024-08-29\\nPrimary Category: cs.AI\\nAll Categories: cs.AI, cs.HC\\nDOI: N/A\\nJournal Reference: N/A\\nComment: N/A\\nEntry ID: http://arxiv.org/abs/2408.16331v1\\nPDF URL: http://arxiv.org/pdf/2408.16331v1\\nAll Links: http://arxiv.org/abs/2408.16331v1||http://arxiv.org/pdf/2408.16331v1\\nSummary: We introduce the concept and a default implementation of Guided Reasoning. A\\nmulti-agent system is a Guided Reasoning system iff one agent (the guide)\\nprimarily interacts with other agents in order to improve reasoning quality. We\\ndescribe Logikon's default implementation of Guided Reasoning in non-technical\\nterms. This is a living document we'll gradually enrich with more detailed\\ninformation and examples.\\n  Code: https://github.com/logikon-ai/logikon\\n\\n\\nTitle: The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners\\nAuthors: Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis\\nPublished: 2025-05-14\\nUpdated: 2025-08-26\\nPrimary Category: cs.AI\\nAll Categories: cs.AI, cs.MA\\nDOI: N/A\\nJournal Reference: N/A\\nComment: N/A\\nEntry ID: http://arxiv.org/abs/2505.09396v2\\nPDF URL: http://arxiv.org/pdf/2505.09396v2\\nAll Links: http://arxiv.org/abs/2505.09396v2||http://arxiv.org/pdf/2505.09396v2\\nSummary: The rapid rise of large language models (LLMs) has shifted artificial\\nintelligence (AI) research toward agentic systems, motivating the use of weaker\\nand more flexible notions of agency. However, this shift raises key questions\\nabout the extent to which LLM-based agents replicate human strategic reasoning,\\nparticularly in game-theoretic settings. In this context, we examine the role\\nof agentic sophistication in shaping artificial reasoners' performance by\\nevaluating three agent designs: a simple game-theoretic model, an unstructured\\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\\nUsing guessing games as a testbed, we benchmarked these agents against human\\nparticipants across general reasoning patterns and individual role-based\\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\\nagents' ability to generalise beyond training distributions. Our analysis,\\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\\nhuman strategic behaviour. Still, the relationship between agentic design\\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\\non underlying LLM capabilities and suggesting limits to simple architectural\\naugmentation.\",\"annotations\":null}",
            "tool_call_id": "call_SVDSfgneBU3g2o54tizQZNyt"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_I83FRUHuzpjvJPJrgrqrXB6Q",
                    "type": "function",
                    "function": {
                        "name": "filesystem-list_allowed_directories",
                        "arguments": "{}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"Allowed directories:\\n/workspace/dumps/workspace\",\"annotations\":null}",
            "tool_call_id": "call_I83FRUHuzpjvJPJrgrqrXB6Q"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_i52ChApKZrEExR2Z3viTJDPq",
                    "type": "function",
                    "function": {
                        "name": "arxiv_local-download_paper",
                        "arguments": "{\"paper_id\":\"2505.20286\",\"check_status\":false}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"converting\\\", \\\"message\\\": \\\"Paper downloaded, conversion started\\\", \\\"started_at\\\": \\\"2025-10-16T22:25:59.069008\\\"}\",\"annotations\":null}",
            "tool_call_id": "call_i52ChApKZrEExR2Z3viTJDPq"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_CkU9eC72Sh1hMtnAhd9TBMfS",
                    "type": "function",
                    "function": {
                        "name": "arxiv_local-list_papers",
                        "arguments": "{}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_papers\\\": 1,\\n  \\\"papers\\\": [\\n    {\\n      \\\"title\\\": \\\"Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\\\",\\n      \\\"summary\\\": \\\"Recent advances in large language models (LLMs) have enabled agents to\\\\nautonomously perform complex, open-ended tasks. However, many existing\\\\nframeworks depend heavily on manually predefined tools and workflows, which\\\\nhinder their adaptability, scalability, and generalization across domains. In\\\\nthis work, we introduce Alita--a generalist agent designed with the principle\\\\nof \\\\\\\"Simplicity is the ultimate sophistication,\\\\\\\" enabling scalable agentic\\\\nreasoning through minimal predefinition and maximal self-evolution. For minimal\\\\npredefinition, Alita is equipped with only one component for direct\\\\nproblem-solving, making it much simpler and neater than previous approaches\\\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\\\\ndesign enhances its potential to generalize to challenging questions, without\\\\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\\\\nAlita by providing a suite of general-purpose components to autonomously\\\\nconstruct, refine, and reuse external capabilities by generating task-related\\\\nmodel context protocols (MCPs) from open source, which contributes to scalable\\\\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\\\\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\\\\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\\\\nMathvista and PathVQA, outperforming many agent systems with far greater\\\\ncomplexity. More details will be updated at\\\\n$\\\\\\\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.\\\",\\n      \\\"authors\\\": [\\n        \\\"Jiahao Qiu\\\",\\n        \\\"Xuan Qi\\\",\\n        \\\"Tongcheng Zhang\\\",\\n        \\\"Xinzhe Juan\\\",\\n        \\\"Jiacheng Guo\\\",\\n        \\\"Yifu Lu\\\",\\n        \\\"Yimin Wang\\\",\\n        \\\"Zixin Yao\\\",\\n        \\\"Qihan Ren\\\",\\n        \\\"Xun Jiang\\\",\\n        \\\"Xing Zhou\\\",\\n        \\\"Dongrui Liu\\\",\\n        \\\"Ling Yang\\\",\\n        \\\"Yue Wu\\\",\\n        \\\"Kaixuan Huang\\\",\\n        \\\"Shilong Liu\\\",\\n        \\\"Hongru Wang\\\",\\n        \\\"Mengdi Wang\\\"\\n      ],\\n      \\\"links\\\": [\\n        \\\"http://arxiv.org/abs/2505.20286v1\\\",\\n        \\\"http://arxiv.org/pdf/2505.20286v1\\\"\\n      ],\\n      \\\"pdf_url\\\": \\\"http://arxiv.org/pdf/2505.20286v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}",
            "tool_call_id": "call_CkU9eC72Sh1hMtnAhd9TBMfS"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_Z76qD7GLLSbHTBxdKi4DWiaw",
                    "type": "function",
                    "function": {
                        "name": "arxiv_local-search_papers",
                        "arguments": "{\"query\":\"Alita\", \"max_results\": 10, \"date_from\": \"2007-01-01\", \"date_to\": \"2025-12-31\", \"categories\": [\"cs.AI\", \"cs.CL\", \"cs.LG\"]}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"{\\n  \\\"total_results\\\": 1,\\n  \\\"papers\\\": [\\n    {\\n      \\\"id\\\": \\\"2505.20286v1\\\",\\n      \\\"title\\\": \\\"Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\\\",\\n      \\\"authors\\\": [\\n        \\\"Jiahao Qiu\\\",\\n        \\\"Xuan Qi\\\",\\n        \\\"Tongcheng Zhang\\\",\\n        \\\"Xinzhe Juan\\\",\\n        \\\"Jiacheng Guo\\\",\\n        \\\"Yifu Lu\\\",\\n        \\\"Yimin Wang\\\",\\n        \\\"Zixin Yao\\\",\\n        \\\"Qihan Ren\\\",\\n        \\\"Xun Jiang\\\",\\n        \\\"Xing Zhou\\\",\\n        \\\"Dongrui Liu\\\",\\n        \\\"Ling Yang\\\",\\n        \\\"Yue Wu\\\",\\n        \\\"Kaixuan Huang\\\",\\n        \\\"Shilong Liu\\\",\\n        \\\"Hongru Wang\\\",\\n        \\\"Mengdi Wang\\\"\\n      ],\\n      \\\"abstract\\\": \\\"Recent advances in large language models (LLMs) have enabled agents to\\\\nautonomously perform complex, open-ended tasks. However, many existing\\\\nframeworks depend heavily on manually predefined tools and workflows, which\\\\nhinder their adaptability, scalability, and generalization across domains. In\\\\nthis work, we introduce Alita--a generalist agent designed with the principle\\\\nof \\\\\\\"Simplicity is the ultimate sophistication,\\\\\\\" enabling scalable agentic\\\\nreasoning through minimal predefinition and maximal self-evolution. For minimal\\\\npredefinition, Alita is equipped with only one component for direct\\\\nproblem-solving, making it much simpler and neater than previous approaches\\\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean\\\\ndesign enhances its potential to generalize to challenging questions, without\\\\nbeing limited by tools. For Maximal self-evolution, we enable the creativity of\\\\nAlita by providing a suite of general-purpose components to autonomously\\\\nconstruct, refine, and reuse external capabilities by generating task-related\\\\nmodel context protocols (MCPs) from open source, which contributes to scalable\\\\nagentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3\\\\naccuracy, which is top-ranking among general-purpose agents, on the GAIA\\\\nbenchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on\\\\nMathvista and PathVQA, outperforming many agent systems with far greater\\\\ncomplexity. More details will be updated at\\\\n$\\\\\\\\href{https://github.com/CharlesQ9/Alita}{https://github.com/CharlesQ9/Alita}$.\\\",\\n      \\\"categories\\\": [\\n        \\\"cs.AI\\\"\\n      ],\\n      \\\"published\\\": \\\"2025-05-26T17:58:53+00:00\\\",\\n      \\\"url\\\": \\\"http://arxiv.org/pdf/2505.20286v1\\\",\\n      \\\"resource_uri\\\": \\\"arxiv://2505.20286v1\\\"\\n    }\\n  ]\\n}\",\"annotations\":null}",
            "tool_call_id": "call_Z76qD7GLLSbHTBxdKi4DWiaw"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_KPyifSumOaKW8hDiuMvwIJpC",
                    "type": "function",
                    "function": {
                        "name": "arxiv_local-download_paper",
                        "arguments": "{\"paper_id\":\"2505.20286\",\"check_status\":true}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"{\\\"status\\\": \\\"success\\\", \\\"started_at\\\": \\\"2025-10-16T22:25:59.069008\\\", \\\"completed_at\\\": \\\"2025-10-16T22:26:01.520556\\\", \\\"error\\\": null, \\\"message\\\": \\\"Paper conversion success\\\"}\",\"annotations\":null}",
            "tool_call_id": "call_KPyifSumOaKW8hDiuMvwIJpC"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_IH1LmilzlkHhthUP3p8NRR8r",
                    "type": "function",
                    "function": {
                        "name": "filesystem-list_directory",
                        "arguments": "{\"path\":\"/workspace/dumps/workspace\"}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"[DIR] arxiv_local_storage\",\"annotations\":null}",
            "tool_call_id": "call_IH1LmilzlkHhthUP3p8NRR8r"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_qlGVaorJNbtsj2Hr8oN24YUd",
                    "type": "function",
                    "function": {
                        "name": "filesystem-directory_tree",
                        "arguments": "{\"path\":\"/workspace/dumps/workspace/arxiv_local_storage\"}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"[\\n  {\\n    \\\"name\\\": \\\"2505.20286.md\\\",\\n    \\\"type\\\": \\\"file\\\"\\n  },\\n  {\\n    \\\"name\\\": \\\"2505.20286.pdf\\\",\\n    \\\"type\\\": \\\"file\\\"\\n  }\\n]\",\"annotations\":null}",
            "tool_call_id": "call_qlGVaorJNbtsj2Hr8oN24YUd"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_zjvPel2XhEWFc4sRi04XVTcm",
                    "type": "function",
                    "function": {
                        "name": "filesystem-move_file",
                        "arguments": "{\"source\":\"/workspace/dumps/workspace/arxiv_local_storage/2505.20286.pdf\",\"destination\":\"/workspace/dumps/workspace/arxiv_local_storage/alita_2505.20286.pdf\"}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"Successfully moved /workspace/dumps/workspace/arxiv_local_storage/2505.20286.pdf to /workspace/dumps/workspace/arxiv_local_storage/alita_2505.20286.pdf\",\"annotations\":null}",
            "tool_call_id": "call_zjvPel2XhEWFc4sRi04XVTcm"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_noxOPOBDvjjbkPZWJBZQGvXU",
                    "type": "function",
                    "function": {
                        "name": "filesystem-read_file",
                        "arguments": "{\"path\":\"/workspace/dumps/workspace/arxiv_local_storage/2505.20286.md\",\"tail\":0,\"head\":0}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "content": "{\"type\":\"text\",\"text\":\"## A LITA : G ENERALIST A GENT E NABLING S CALABLE A GENTIC R EASONING WITH M INIMAL P REDEFINITION AND M AXIMAL S ELF -E VOLUTION\\n\\nJiahao Qiu *[\u2217]* [1], Xuan Qi *[\u2217]* [2], Tongcheng Zhang *[\u2217]* [3], Xinzhe Juan [3] *[,]* [4], Jiacheng Guo [1], Yifu Lu [1], Yimin Wang [3] *[,]* [4], Zixin Yao [1],\\nQihan Ren [3], Xun Jiang [5], Xing Zhou [5], Dongrui Liu [3], Ling Yang [1], Yue Wu [1], Kaixuan Huang [1], Shilong Liu [1],\\nHongru Wang [6], Mengdi Wang [1]\\n\\n1 AI Lab, Princeton University 2 IIIS, Tsinghua University 3 Shanghai Jiao Tong University\\n4 University of Michigan 5 Tianqiao and Chrissy Chen Institute 6 The Chinese University of Hong Kong\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|Col1|47.|57.<br>6%|7%|6|Col6|74.3<br>.1%<br>%|%<br>76.9|%|86.5|88.7<br>%<br>89|%<br>.5%|\\n|---|---|---|---|---|---|---|---|---|---|---|---|\\n||47.|57.<br>6%|7%|6|70|.1|.1|.1|.1|.1|.1|\\n||47.|57.<br>6%|7%|6|9.1|9.1|9.1|9.1|9.1|9.1|9.1|\\n|||||67.4|%|73.3%|||87.|3%||\\n\\n\\nFigure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\\n\\n**A** **BSTRACT**\\n\\nRecent advances in large language models (LLMs) have enabled agents to autonomously perform\\ncomplex, open-ended tasks. However, many existing frameworks depend heavily on manually\\npredefined tools and workflows, which hinder their adaptability, scalability, and generalization\\nacross domains. In this work, we introduce **Alita** \u2014a generalist agent designed with the principle\\nof *\\\"Simplicity is the ultimate sophistication,\\\"* enabling scalable agentic reasoning through *minimal*\\n*predefinition* and *maximal self-evolution* . For minimal predefinition, Alita is equipped with only one\\ncomponent for direct problem-solving, making it much simpler and neater than previous approaches\\nthat relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances\\nits potential to generalize to challenging questions, without being limited by tools. For *Maximal*\\n*self-evolution*, we enable the creativity of Alita by providing a suite of general-purpose components\\nto autonomously construct, refine, and reuse external capabilities by generating task-related model\\ncontext protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably,\\nAlita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among generalpurpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively,\\non Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More\\n[details will be updated at https://github.com/CharlesQ9/Alita.](https://github.com/CharlesQ9/Alita)\\n\\n*\u2217* These authors contributed equally to this work.\\n\\n**1** **Introduction**\\n\\n*\\\"Simplicity is the ultimate sophistication.\\\"* \u2014 Leonardo da Vinci\\n\\nLarge language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of\\nindependently planning and executing complex tasks on behalf of users with limited human oversight [ 2 ]. These\\ncapabilities have enabled a wide range of applications, ranging from travel planning [ 3 ], computer use [ 4, 5, 6 ],\\nto the multi-step research tasks [ 7 ]. To support such diverse and demanding tasks, a new class of systems called\\ngeneralist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified\\narchitecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [ 1 ] and Manus.\\n\\nHowever, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously\\ndesigned workflows, considerable pre-defined tools, and hardcoded components [ 8, 9 ]. This reliance introduces several\\ncritical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of\\nreal-world tasks an agent might encounter ( *imcomplete coverage* ); ii) Many complex tasks require agents to creatively\\ncompose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components\\nconstrain this compositional flexibility and inhibit the development of adaptive behaviors ( *limited creativity and*\\n*flexibility* ); iii) It is not always the case that the interface or environment of different tools are compatible with the agent\\n( *mismatch* ). For example, many useful tools are not written in Python, which makes it difficult, though not entirely\\nimpossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python.\\nTogether, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\\n\\nIn contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two\\nprinciples: i) *Minimal Predefinition* : Equip the agent with only a minimal set of core capabilities, avoiding manually\\nengineered components for specific tasks or modalities; ii) *Maximal Self-Evolution* : Empower the agent to autonomously\\ncreate, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built\\nwith a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed\\ncapability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) [1] which is an open\\nprotocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate,\\nadapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from\\nmanually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple\\nyet profoundly capable.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|Col1|Col2|\\n|---|---|\\n||MCP Creation|\\n\\n\\n\\n\\n|Col1|Col2|\\n|---|---|\\n|Self Evolving||\\n|||\\n\\n\\n\\nFigure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on\\nlarge-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\\n\\nWe conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially\\non the most popular GAIA [ 10 ]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent\\nbehavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions\\ncan be summarized as follows.\\n\\n    - We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging\\nconventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent\\nframework.\\n\\n1 `https://www.anthropic.com/news/model-context-protocol`\\n\\n2\\n\\n    - We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\\n\\n    - We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific\\ntasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark.\\nWe achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI\u2019s Deep Research with 67.36% pass@1\\nand ranking top among all general-purpose agents.\\n\\n**2** **Related Works**\\n\\n**2.1** **Generalist Agent**\\n\\nThe concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety\\nof complex tasks in a real-world environment. OWL [ 8 ] introduces a method that decomposes complex tasks into\\nsubtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [ 11 ] proposes a multiagent collaborative development framework, where each agent possesses an independent system structure, enabling\\nautonomous learning and the storage of a comprehensive world model to build an independent understanding of the\\nenvironment. OpenAI Deep Research [2] employs reinforcement learning for training on real-world tasks, aiming to\\nprovide precise and reliable research reports for knowledge-intensive tasks. A-World [ 12 ] offers a highly configurable,\\nmodular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI\\nagents. The Magentic-One [ 13 ] framework merges the Magentic and Autogen systems, distinguishing between the\\nmicro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and\\nmore efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined\\ntools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\\n\\n**2.2** **Auto Generating Agent**\\n\\nAuto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools,\\nagents, or workflows tailored to specific tasks. AutoAgents [ 14 ], for instance, generate multiple agents, each playing a\\ndistinct role, to handle the corresponding subtasks. OpenHands [ 15 ] offers an event-driven architecture that allows\\nagents to interact with the environment like human developers, thereby enabling the creation of custom workflows.\\nAFlow [ 16 ] redefines workflow optimization as a search problem, where each workflow consists of several nodes\\ninvoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [ 17 ], as\\nan autonomous agent operating system, permits agents to manage system-level operations and file data autonomously.\\nIn Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the\\ncompletion of specific tasks, while also providing resources for future executions.\\n\\n**2.3** **Tool Creation**\\n\\nTool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external\\nsupport. CRAFT [ 18 ] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved\\nand used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated,\\nextended, and periodically pruned to optimize program generation. CREATOR [ 20 ] decouples the abstraction of tool\\ncreation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [ 17 ]\\nenables agents to autonomously create new tools based on task requirements, incorporating information gathered\\nthrough web searches and integrating these tools into their workflow. OpenHands [ 15 ] allows agents to create code\\nscripts in a human-like manner during interaction with the environment to assist in task completion. In comparison,\\nAlita enables MCP creation, which provides additional benefits, including better reusability and easy environment\\nmanagement over tool creation.\\n\\n**2.4** **MCP**\\n\\nThe Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI\\nsystems and external data sources and services. RAG-MCP [ 21 ] enhances the efficiency and accuracy of agents by\\nretrieving the most relevant tools from a large collection, based on the task description, within the database composed\\nof MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use,\\nfacilitating reuse by itself and other agents.\\n\\n2 https://openai.com/index/introducing-deep-research/\\n\\n3\\n\\n**3** **Methods**\\n\\nWe propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal\\nself-evolution to tackle diverse and complex tasks. Figure **3** illustrates the framework of Alita. In contrast to generalist\\nagents that typically depend on extensive manually-designed tools and workflows [ 8, 9 ], the manager agent in Alita\\nsolely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan\\ntask-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries\\nand other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and\\nconfigures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if\\nany issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct,\\nimproving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future\\nreuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a\\nself-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFigure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct\\nloop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system\\ndynamically performs open-source searching, script generation, and virtual environment execution to construct taskrelated functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this\\nprocess, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously\\nintegrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying\\non a huge hand-crafted, elaborate tools and workflows.\\n\\n**3.1** **Execution Pipeline**\\n\\nEach task commences with the construction of an augmented prompt that incorporates the original query. The manager\\nagent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the\\nagent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute\\nthem within isolated environments (Sec. 3.4.4).\\n\\nUpon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP\\nand stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are\\nsystematically logged to facilitate comprehensive analysis.\\n\\n**3.2** **Manager Agent**\\n\\nThe Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the\\nmanager agent initially calls the `MCP Brainstorming` to determine whether additional tools are needed and which\\nspecific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web\\nagent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the\\ninformation retrieved by the web agent to generate the required new tools along with their corresponding environment\\nconfiguration instructions. After collecting all intermediate results, the manager performs final aggregation and response\\nformulation.\\n\\n4\\n\\n**Tool Usage** . In contrast to traditional systems that rely on extensive predefined toolkits, the manager agent embraces Alita\u2019s minimal philosophy by employing concise but powerful toolkits, including `MCP Brainstorming`,\\n`ScriptGeneratingTool` and `CodeRunningTool` . Specifically, `MCP Brainstorming` detects functional gaps, identifies necessary supplementary tools and outlines tool specifications; `ScriptGeneratingTool` obtains tool specification\\noutlines and then generates appropriate tools tailored to the task requirements; `CodeRunningTool` executes generated\\ncode in isolated environments and caches the output for potential MCP servers generation. These tools are intelligently\\ninvoked in response to the task\u2019s evolving demands, ensuring adaptive and efficient problem-solving.\\n\\n**3.3** **Web Agent**\\n\\nThe web agent retrieves relevant information from external sources when internal knowledge is insufficient. It is\\nparticularly effective for tasks requiring the retrieval of domain-specific code or documentation. With a lightweight,\\ntext-based web interface and modular navigation tools, the web agent traverses multiple websites, extract relevant\\nsegments, and return reasonable URLs or raw content.\\n\\n**Tool Usage** . The agent utilizes `SimpleTextBrowser` as its web interface and page-level control tools: `VisitTool`,\\n`PageUpTool`, and `PageDownTool` to navigate webpages. For query-based lookups, it applies `GoogleSearchTool` for\\nopen web search and `GithubSearchTool` to identify reusable open-source tools. This design supports real-time code\\nretrieval and context-aware tool planning.\\n\\n**3.4** **MCP Creation Component**\\n\\nTo enable the creativity of the agent, we design three tools collaboratively contributing to the MCP creation process.\\n\\n**3.4.1** **MCP Brainstorming**\\n\\nSince LLMs often exhibit overconfidence in their capabilities [ 22 ], we introduce `MCP Brainstorming` to conduct\\npreliminary capability assessment by providing both the task and the description of current framework. We designed specialized prompts to facilitate accurate self-assessment of the agent\u2019s capabilities. Moreover, when `MCP Brainstorming`\\nidentifies insufficient capabilities of the framework to complete the task, it provides references for tool generation to\\nbridge the capability gap. This provides prior guidance for subsequent tool selection and task planning required to\\naccomplish given objectives.\\n\\n**3.4.2** **ScriptGeneratingTool**\\n\\nThe `ScriptGeneratingTool` is a code-building utility designed for constructing external tools. It receives explicit\\nsubtask descriptions and suggestions for code construction from the manager agent, and potentially useful GitHub links\\nobtained via the web agent, which can provide information such as `README.md` files or code snippets from GitHub to\\nguide the script generation process. Furthermore, `ScriptGeneratingTool` generates the environment script to create\\nthe required environment for the code running and the cleaning script to clean up redundant files and environments\\ngenerated after script execution. Therefore, `ScriptGeneratingTool` ensures that the generated scripts are valid,\\nself-contained, and executable, making them suitable for deployment in the given task, and reusable in the future.\\n\\n**3.4.3** **CodeRunningTool**\\n\\nThe `CodeRunningTool` validates the functionality of the generated script by executing it within an isolated environment.\\nIf the execution produces the expected results, the tool is registered in the system as a reusable MCP. This process also\\nsupports iterative refinement, allowing for error inspection and subsequent code regeneration to improve the script\u2019s\\nperformance.\\n\\n**3.4.4** **Environment Management**\\n\\nUpon retrieving or generating a candidate tool, the system activates the environment planner module. This module\\nparses the relevant repository or script metadata such as `README.md`, `requirements.txt`, and shell scripts using\\nthe `TextInspectorTool` . It extracts and validates the dependencies and setup instructions to construct an isolated\\nexecution profile. Subsequently, a new Conda environment is created with a unique name (typically derived from the\\ntask ID or a hash of the repository path), and dependencies are installed using `conda install` or `pip install` .\\n\\nAll runtime environments are initialized locally in parallel, obviating the need for administrative privileges or containerization technologies. This approach ensures high compatibility across various tasks while preserving the portability\\n\\n5\\n\\nof the system. During execution, the environment is explicitly activated prior to invoking the code interpreter, thus\\nensuring both isolation and reproducibility.\\n\\nIn the event of a failure during environment initialization\u2014due to issues such as missing packages, syntax errors in setup\\nscripts, or unavailable dependencies\u2014Alita activates an automated recovery procedure. This procedure attempts various\\nfallback strategies, including relaxing version constraints or identifying the minimal set of dependencies required for\\nfunctionality. If these recovery attempts are unsuccessful, the tool is discarded, and the failure is logged for offline\\nanalysis and future investigation. This enables Alita to self-correct its designed tools, thereby generating more accurate\\nand robust solutions.\\n\\n**4** **Experiments**\\n\\n**4.1** **Experiment Setting**\\n\\n**4.1.1** **Benchmarks**\\n\\nTo evaluate the general task-handling capabilities of Alita, we conducted extensive testing across multiple agent\\nbenchmarks.\\n\\n**GAIA [** **10** **]:** GAIA is a benchmark designed to assess the capabilities of general-purpose AI assistants. It consists of\\n466 real-world scenario-based questions covering daily tasks, scientific reasoning, web browsing, and tool usage. While\\nthese tasks are conceptually simple for humans, they are challenging for most advanced AI systems.\\n\\n**Mathvista [** **23** **]:** MathVista is a comprehensive benchmark designed to evaluate the mathematical reasoning capabilities\\nof foundation models within visual contexts. It can effectively evaluate the model\u2019s capabilities in visual comprehension,\\nmathematical reasoning, programming, and other related skills. Due to limitations in resources, we randomly selected\\n100 samples from the dataset.\\n\\n**Pathvqa [** **24** **]:** PathVQA is a medical visual question answering dataset. It can effectively assess the agent\u2019s capabilities\\nacross multiple dimensions, including visual understanding, spatial Reasoning, medical Knowledge search or integration,\\nand natural language processing. Due to limitations in resources, we randomly selected 100 samples from the dataset.\\n\\n**4.1.2** **Baselines**\\n\\nWe include a variety of baselines for comparison. For the GAIA benchmark, there are more baselines available on the\\nGAIA leaderboard [3] .\\n\\n**Octotools [** **9** **]:** OctoTools is a recent framework designed to streamline multi-tool workflows in complex computational\\ntasks. With over 10 standardized tool cards encapsulating various functionalities, the agent gains powerful capabilities\\nto handle multi-domain tasks.\\n\\n**Open Deep Research-smolagents** [4] **[** **25** **]:** Open Deep Research is an open-source agent developed under Hugging\\nFace\u2019s Smolagents project, designed to automate complex multi-step research tasks. Alita\u2019s development is largely\\nbased on the framework of Open Deep Research-smolagents. However, we remove many pre-defined tools and also add\\nthe MCP creation component to follow the design principle of minimal predefinition and maximal self-evolution.\\n\\n**AutoAgent [** **17** **]:** AutoAgent is a zero-code platform designed to facilitate the creation, customization, and deployment\\nof agents powered by LLMs. By providing a natural language interface, it allows users to develop multi-agent systems,\\ndesign workflows, and integrate tools without requiring technical expertise.\\n\\n**OWL [** **8** **]:** OWL is an open-source, multi-agent framework built on the CAMEL-AI platform, designed to support the\\nautomation of complex real-world tasks through dynamic agent collaboration. OWL decomposes tasks into specialized\\nsub-tasks, each of which is managed by a distinct agent type\u2014such as UserAgents, AssistantAgents, and ToolAgents.\\n\\n**A-World [** **12** **]:** A-World is an open-source multi-agent system framework designed to simplify the construction,\\nevaluation, and deployment of general multi-agent tasks. Through its modular design, the framework supports\\nautonomous decision-making, tool usage, and collaboration among agents.\\n\\n**OpenAI Deep Research** [5] **:** OpenAI\u2019s Deep Research is an advanced AI agent integrated with ChatGPT, designed to\\nautonomously perform multi-step research tasks by synthesizing information from diverse online sources. This agentic\\n\\n3 https://huggingface.co/spaces/gaia-benchmark/leaderboard\\n4 https://huggingface.co/blog/open-deep-research\\n5 https://openai.com/index/introducing-deep-research/\\n\\n6\\n\\nframework excels in generating comprehensive reports on complex topics and has shown superior performance on\\nbenchmarks.\\n\\n**4.2** **Results**\\n\\nWe run three rounds of testing on GAIA and achieved the best performance on the GAIA leaderboard, surpassing\\nother agent systems. Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and 87.27% pass@3 accuracy,\\nwhich is top-ranking on the GAIA benchmark validation dataset, outperforming many agent systems with far greater\\ncomplexity. Alita with Claude 3.7 Sonnet + GPT-4o achieves 72.73% pass@1 and 86.06% pass@3 on GAIA, and\\nfurther attains 74.00% and 52.00% pass@1 on the Mathvista and PathVQA benchmarks, respectively, outperforming\\nOctotools and Open Deep Research by smolagents. More detailed results are shown in Table 1.\\n\\nGAIA\\nMathvista PathVQA\\n**Agent** level1 level2 level3 total\\n\\n*Alita (Claude-3.7-Sonnet, GPT-4o) (%)*\\n\\npass@1 81.13 75.58 46.15 72.73 **74** **52**\\npass@2 88.68 80.23 53.85 78.79      -      pass@3 96.23 86.04 65.38 **86.06**      -      \\n*Alita (Claude-Sonnet-4, GPT-4o) (%)*\\n\\npass@1 77.36 76.74 65.38 75.15      -      pass@3 88.68 89.53 76.92 **87.27**      -      \\n*Baselines (%)*\\n\\nOctotools       -       -       - 18.40 68 47\\nODR-smolagents 67.92 53.49 34.62 55.15 65 42\\nAutoAgent 71.70 53.49 26.92 55.15      -      OWL 84.91 67.44 42.31 69.09    -    A-World 86.79 69.77 34.62 69.70      -      OpenAI-DR 74.29 69.06 47.60 67.36      -      \\nTable 1: Performance comparison of Alita and baseline agent systems on the GAIA, Mathvista, and PathVQA\\nbenchmarks. ODR-Smolagents refers to the Open Deep Research agent in the Smolagents framework. OpenAI-DR\\nrefers to OpenAI\u2019s Deep Research. The table presents the accuracy at different levels of difficulty for GAIA, as well as\\nthe overall performance on Mathvista and PathVQA. The pass@1, pass@2, and pass@3 denote the accuracy achieved\\nby running the Alita framework 1, 2, and 3 times, respectively, and selecting the best answer. Alita outperforms all\\nbaseline agents across the GAIA levels, achieving the highest total accuracy.\\n\\n**5** **Analysis**\\n\\n**5.1** **Reuse of Alita-Generated MCPs**\\n\\n**5.1.1** **Overview**\\n\\nWe collect the MCPs generated from running the GAIA dataset using Alita in conjunction with powerful models\\n(Claude-3.7-Sonnet and GPT-4o). The benefits of reusing Alita-generated MCPs are **two-fold** . First, these MCPs can be\\nreused by other agent frameworks and improve their performance since Alita, instead of human developers, designs a\\nset of useful MCPs fit to GAIA by trial and error. Second, these MCPs can be reused by agents with smaller LLMs\\nand **significantly** improve the performance. The reuse of auto-generated MCPs for agents with smaller LLMs can be\\nviewed as a new way of distillation from larger LLMs. Traditionally, distillation might be fine-tuning smaller LLMs on\\ndata generated by larger LLMs. In comparison, the reuse of MCPs generated from agents with larger LLMs is much\\neasier, cheaper, and faster than traditional distillation.\\n\\n7\\n\\n**5.1.2** **Reuse by Open Deep Research-smolagents**\\n\\nWe run open Deep Research-smolagents [ 25 ] on GAIA with and without Alita-generated MCPs based on GPT-4o. The\\nresults are presented in Table 2. From this experiment, we observe that the reuse of Alita-generated MCPs results in\\nbetter performance compared to the base framework for all difficulty levels. This demonstrates that Alita can generate\\nvery useful MCPs, which can be provided to other agents, helping them enhance their capabilities and solve problems\\nthat would otherwise be unsolvable. Additionally, the consistent improvement across all difficulty levels indicates that\\nAlita\u2019s MCPs provide generalizable utility rather than just addressing specific edge cases in the dataset.\\n\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Total**\\n\\nODR-smolagents + GPT-4o(No Alita MCPs) 33.96% 29.07% 11.54% 27.88%\\n\\nODR-smolagents + GPT-4o(With Alita MCPs) 39.62% 36.05% 15.38% **33.94%**\\n\\nTable 2: Comparison of performance between ODR-smolagents with and without Alita-generated MCPs. The results\\nare reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\\nperformance at the respective GAIA levels. The reuse of Alita-generated MCPs can enhance the performance of other\\nagents.\\n\\n**5.1.3** **Reuse by Base Agent on Smaller LLM**\\n\\nWe reuse MCPs in the base framework, i.e., ODR-smolagents [ 25 ], without the MCP creation component in Alita, and\\nalso with some extra pre-defined tools used in ODR-smolagents based on GPT-4o-mini. The results are presented in\\nTable 3.\\n\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Average**\\n\\nBase Framework + GPT-4o-mini (No Alita MCP) 32.08% 20.93% 3.85% 21.82%\\n\\nBase Framework + GPT-4o-mini (With Alita MCP) 39.62% 27.91% 11.54% **29.09%**\\n\\nTable 3: Comparison of performance between the base framework on GPT-4o-mini, with and without Alita-generated\\nMCPs. The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column\\ncorresponds to the performance at the respective GAIA levels. The reuse of Alita-generated MCPs significantly\\nenhances the performance of agents on smaller LLMs.\\n\\nFrom this experiment, we observe that the reuse of Alita-generated MCPs significantly improves performance over the\\nbase framework based on a smaller LLM. This is because the Alita-generated MCPs can be considered MCPs distilled\\nfrom powerful models (Claude-3.7-Sonnet), which are made available for agents on smaller LLMs. This helps bridge\\nthe gap between the agents on smaller LLMs and agents on larger LLMs in certain domains, thereby enhancing its\\ntask-processing capabilities. Especially for Level 3, we observe a particularly dramatic improvement with the accuracy\\ntripling from **3.85** % to **11.54** %. This substantial improvement on the most challenging problems demonstrates that\\nAlita-generated MCPs are especially valuable for complex reasoning tasks where agents on smaller LLMs typically\\nstruggle the most. The MCPs effectively encapsulate sophisticated problem-solving capabilities that the smaller model\\ncan leverage without needing to develop the full reasoning chain independently.\\n\\n**5.2** **Alita on Smaller LLM**\\n\\nWe hypothesize that **Alita will be even stronger with the increasing coding and reasoning capabilities of LLMs in**\\n**the future** . To validate our performance, we run Alita on GAIA using GPT-4o-mini instead of Claude-3.7-Sonnet. The\\nresults can be found in Table 4. Different to the experiment in Section 5.1.3, the agent doesn\u2019t have distilled MCPs - the\\nagent on GPT-4o-mini model must generate its own MCPs. The results are presented in Table 4.\\n\\nFrom this experiment, on one hand, we observe that Alita, after replacing the models with GPT-4o-mini, performs\\nsignificantly worse on GAIA. This substantial performance gap highlights the critical role of the underlying models\u2019\\ncoding capabilities. On the other hand, the performance of Alita increases rapidly as the capabilities of the underlying\\nmodels improve. We can expect that with future updates to the LLMs, Alita\u2019s performance will continue to strengthen,\\nsurpassing its current capabilities. The design of future generalist agents might be much simpler in the future, without\\nany predefined tools and workflows for direct problem-solving. Instead, human developers might focus on designing\\nmodules for enabling and stimulating the creativity and evolution of generalist agents.\\n\\n8\\n\\n**Model Configuration** **Level 1** **Level 2** **Level 3** **Total**\\n\\nAlita (Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% **72.73%**\\n\\nAlita (GPT-4o-mini) 54.72% 44.19% 19.23% 43.64%\\n\\nTable 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results\\nare reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\\nperformance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\\n\\n**5.3** **Case Study**\\n\\nTo investigate Alita\u2019s workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3\\ndifficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe\\nthat Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying\\nand utilizing relevant resources to implement a feasible MCP that aids in completing the task.\\n\\n**6** **Conclusion**\\n\\nIn this work, we introduced **Alita**, a generalist agent designed with the principles of minimal predefinition and maximal\\nself-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving,\\nAlita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach\\ndemonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of\\ngeneralist agents.\\n\\n9\\n\\n**References**\\n\\n[1] OpenAI. Introducing deep research.\\n\\n[2] Noam Kolt. Governing ai agents. *arXiv preprint arXiv:2501.07913*, 2025.\\n\\n[3] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su.\\nTravelplanner: A benchmark for real-world planning with language agents. *arXiv preprint arXiv:2402.01622*,\\n2024.\\n\\n[4] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua, Zhoujun\\nCheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents for open-ended tasks in\\nreal computer environments. *Advances in Neural Information Processing Systems*, 37:52040\u201352094, 2024.\\n\\n[5] Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, and Kam-Fai Wong.\\nAppBench: Planning of multiple APIs from various APPs for complex user instruction. In Yaser Al-Onaizan,\\nMohit Bansal, and Yun-Nung Chen, editors, *Proceedings of the 2024 Conference on Empirical Methods in Natural*\\n*Language Processing*, pages 15322\u201315336, Miami, Florida, USA, November 2024. Association for Computational\\nLinguistics.\\n\\n[6] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin\\nLi, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli\\nMa, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao\\nWang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, and Guang Shi. Ui-tars:\\nPioneering automated gui interaction with native agents, 2025.\\n\\n[7] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research.\\n*arXiv preprint arXiv:2502.04644*, 2025.\\n\\n[8] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru\\nLi, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for\\ngeneral multi-agent assistance in real-world task automation, 2025.\\n\\n[9] Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, and James Zou. Octotools: An agentic framework\\nwith extensible tools for complex reasoning. *arXiv preprint arXiv:2502.11271*, 2025.\\n\\n[10] Gr\u00e9goire Mialon, Cl\u00e9mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for\\ngeneral ai assistants. In *The Twelfth International Conference on Learning Representations*, 2023.\\n\\n[11] Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize\\nChen, et al. Long term memory: The foundation of ai self-evolution. *arXiv preprint arXiv:2410.15665*, 2024.\\n\\n[12] Agent Team at Ant Group. Aworld: A unified agent playground for computer and phone use tasks, 2025.\\n\\n[13] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner,\\nGrace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor\\nDibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, and Saleema Amershi. Magentic-one: A generalist multi-agent\\nsystem for solving complex tasks, 2024.\\n\\n[14] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, B\u00f6rje F Karlsson, Jie Fu, and Yemin Shi.\\nAutoagents: A framework for automatic agent generation. *arXiv preprint arXiv:2309.17288*, 2023.\\n\\n[15] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song,\\nBowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. In\\n*The Thirteenth International Conference on Learning Representations*, 2024.\\n\\n[16] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng,\\nSirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. *arXiv preprint arXiv:2410.10762*,\\n2024.\\n\\n[17] Jiabin Tang, Tianyu Fan, and Chao Huang. Autoagent: A fully-automated and zero-code framework for llm agents.\\n*arXiv e-prints*, pages arXiv\u20132502, 2025.\\n\\n[18] Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, and Heng Ji. Craft: Customizing llms by creating\\nand retrieving from specialized toolsets. *arXiv preprint arXiv:2309.17428*, 2023.\\n\\n[19] Zhiruo Wang, Daniel Fried, and Graham Neubig. Trove: Inducing verifiable and efficient toolboxes for solving\\nprogrammatic tasks. *arXiv preprint arXiv:2401.12869*, 2024.\\n\\n[20] Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. Creator: Tool creation for disentangling\\nabstract and concrete reasoning of large language models. *arXiv preprint arXiv:2305.14318*, 2023.\\n\\n10\\n\\n[21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented\\ngeneration. *arXiv preprint arXiv:2505.03275*, 2025.\\n\\n[22] Fengfei Sun, Ningke Li, Kailong Wang, and Lorenz Goette. Large language models are overconfident and amplify\\nhuman bias. 2025.\\n\\n[23] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang,\\nMichel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual\\ncontexts. In *International Conference on Learning Representations (ICLR)*, 2024.\\n\\n[24] Xuehai He, Yichen Zhang, Luntian Mou, Eric P. Xing, and Pengtao Xie. Pathvqa: 30000+ questions for medical\\nvisual question answering. *ArXiv*, abs/2003.10286, 2020.\\n\\n[25] Aymeric Roucher, Albert Villanova del Moral, Thomas Wolf, Leandro von Werra, and Erik Kaunism\u00e4ki. \u2018smolagents\u2018: a smol library to build great agentic systems. `https://github.com/huggingface/smolagents`,\\n2025.\\n\\n11\\n\\n**A** **Detailed Case Study**\\n\\n\\n\\n**B** **Limitations**\\n\\nAlita highly relies on the coding capability of LLM. When the LLM\u2019s coding capability is really poor, our method will\\nperform worse than traditional generalist agent.\\n\\n12\\n\\n\",\"annotations\":null}",
            "tool_call_id": "call_noxOPOBDvjjbkPZWJBZQGvXU"
        },
        {
            "role": "assistant",
            "content": "title: Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution\narxiv_abs_url: https://arxiv.org/abs/2505.20286\ncode_url: https://github.com/CharlesQ9/Alita"
        }
    ]
}