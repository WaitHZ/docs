---
title: "Academic PDF Report"
description: "Extract first author names and affiliations from papers and save consolidated results as paper_updated.xlsx."
mode: wide
---

<Card>
<div className="tools-container">
<div className="mcp-servers-container">
<div className="mcp-servers-title">
MCP Servers
</div>
<div className="mcp-servers-grid">
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="20" height="20" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg>
<span className="mcp-server-name">excel</span>
</div>
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><path fill="#010202" d="M201.5,22.5C253.575,18.8292,294.909,37.8292,325.5,79.5C348.846,76.447,370.846,80.6137,391.5,92C411.339,105.168,422.339,123.668,424.5,147.5C465.86,161.693,491.694,190.026,502,232.5C508.97,280.701,492.804,318.868,453.5,347C427.526,362.095,399.526,367.929,369.5,364.5C369.988,405.252,369.488,445.919,368,486.5C367.5,487,367,487.5,366.5,488C292.5,488.667,218.5,488.667,144.5,488C144,487.5,143.5,487,143,486.5C141.512,445.919,141.012,405.252,141.5,364.5C106.171,368.921,74.5043,360.421,46.5,339C10.3518,305.536-0.814861,265.036,13,217.5C22.2223,191.95,38.389,172.117,61.5,158C69.8007,153.681,78.134,149.681,86.5,146C92.1136,89.0861,121.447,50.0861,174.5,29C183.492,26.2401,192.492,24.0734,201.5,22.5Z"/></g><g><path fill="#a3d3fe" d="M204.5,36.5C254.543,34.185,292.876,54.0184,319.5,96C340.997,90.9721,361.664,93.3054,381.5,103C401.654,115.47,411.154,133.637,410,157.5C410.903,158.701,412.069,159.535,413.5,160C453.408,170.242,478.242,195.409,488,235.5C493.84,285.282,474.34,321.115,429.5,343C422.574,345.298,415.574,347.298,408.5,349C395.504,349.5,382.504,349.667,369.5,349.5C369.667,302.499,369.5,255.499,369,208.5C367.833,207.333,366.667,206.167,365.5,205C306.833,204.333,248.167,204.333,189.5,205C173,220.167,157.167,236,142,252.5C141.5,284.832,141.333,317.165,141.5,349.5C100.111,355.535,66.2777,342.535,40,310.5C17.3055,276.196,15.6388,240.863,35,204.5C50.4757,180.668,71.9757,165.002,99.5,157.5C101.376,109.215,123.042,73.0487,164.5,49C177.289,42.679,190.622,38.5123,204.5,36.5Z"/></g><g><path fill="#fefefe" d="M354.5,474.5C288.5,474.5,222.5,474.5,156.5,474.5C156.5,403.833,156.5,333.167,156.5,262.5C169.344,262.829,182.011,262.495,194.5,261.5C197.167,260.833,198.833,259.167,199.5,256.5C200.495,244.011,200.829,231.344,200.5,218.5C251.833,218.5,303.167,218.5,354.5,218.5C354.5,303.833,354.5,389.167,354.5,474.5Z"/></g><g><path fill="#979797" d="M354.5,474.5C354.5,389.167,354.5,303.833,354.5,218.5C303.167,218.5,251.833,218.5,200.5,218.5C200.829,231.344,200.495,244.011,199.5,256.5C199.5,243.5,199.5,230.5,199.5,217.5C251.5,217.5,303.5,217.5,355.5,217.5C355.833,303.335,355.499,389.002,354.5,474.5Z"/></g><g><path fill="#dce0e3" d="M185.5,247.5C179.31,247.823,173.31,247.49,167.5,246.5C173.13,240.369,178.964,234.369,185,228.5C185.5,234.825,185.666,241.158,185.5,247.5Z"/></g><g><path fill="#7b7d7e" d="M167.5,246.5C173.31,247.49,179.31,247.823,185.5,247.5C179.322,248.817,172.988,248.817,166.5,247.5C166.624,246.893,166.957,246.56,167.5,246.5Z"/></g><g><path fill="#a3a3a3" d="M194.5,261.5C182.011,262.495,169.344,262.829,156.5,262.5C156.5,333.167,156.5,403.833,156.5,474.5C155.501,403.669,155.167,332.669,155.5,261.5C168.5,261.5,181.5,261.5,194.5,261.5Z"/></g><g><path fill="#030303" d="M252.5,309.5C256.426,309.047,259.592,310.38,262,313.5C262.333,334.833,262.667,356.167,263,377.5C264.979,369.149,269.812,366.649,277.5,370C278.718,371.438,279.385,373.105,279.5,375C274.409,385.346,268.909,395.512,263,405.5C258,413.5,253,413.5,248,405.5C242.091,395.512,236.591,385.346,231.5,375C232.869,369.144,236.536,367.144,242.5,369C244.956,371.408,246.789,374.241,248,377.5C248.333,356.167,248.667,334.833,249,313.5C250.376,312.295,251.542,310.962,252.5,309.5Z"/></g><g><path fill="#050505" d="M199.5,376.5C203.888,375.943,207.055,377.61,209,381.5C209.5,398.83,209.667,416.163,209.5,433.5C240.167,433.5,270.833,433.5,301.5,433.5C301.333,416.163,301.5,398.83,302,381.5C304.553,376.374,308.386,375.207,313.5,378C314.126,378.75,314.626,379.584,315,380.5C315.667,401.5,315.667,422.5,315,443.5C314.626,444.416,314.126,445.25,313.5,446C294.254,447.155,274.921,447.655,255.5,447.5C236.079,447.655,216.746,447.155,197.5,446C196.874,445.25,196.374,444.416,196,443.5C195.333,422.5,195.333,401.5,196,380.5C196.69,378.65,197.856,377.316,199.5,376.5Z"/></g></svg>
<span className="mcp-server-name">fetch</span>
</div>
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48" width="20px" height="20px" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#0277bd" d="M19.847,41.956c-5.629-0.002-11.259,0.024-16.888-0.013c-2.855-0.019-3.374-0.7-2.731-3.525 c2.178-9.58,4.427-19.143,6.557-28.734C7.356,7.112,8.588,5.975,11.312,6C22.57,6.106,33.829,6.034,45.088,6.046 c2.824,0.003,3.298,0.614,2.664,3.511c-2.058,9.406-4.129,18.809-6.236,28.203c-0.789,3.516-1.697,4.187-5.353,4.195 C30.724,41.966,25.285,41.958,19.847,41.956z"/><path fill="#fafafa" d="M25.057 23.922c-.608-.687-1.114-1.267-1.531-1.732-2.43-2.728-4.656-5.27-7.063-7.869-1.102-1.189-1.453-2.344-.13-3.518 1.307-1.16 2.592-1.058 3.791.277 3.34 3.717 6.676 7.438 10.071 11.104 1.268 1.369.972 2.3-.424 3.315-5.359 3.895-10.687 7.833-16.01 11.778-1.196.887-2.337 1.109-3.304-.201-1.066-1.445-.08-2.305 1.026-3.114 3.955-2.893 7.903-5.798 11.834-8.725C23.865 24.83 24.595 24.267 25.057 23.922zM21.75 37C20.625 37 20 36 20 35s.625-2 1.75-2c4.224 0 6.112 0 9.5 0 1.125 0 1.75 1 1.75 2s-.625 2-1.75 2C29.125 37 25 37 21.75 37z"/></svg>
<span className="mcp-server-name">terminal</span>
</div>
<div className="mcp-server-item">
<svg width="20px" height="20px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg>
<span className="mcp-server-name">pdf-tools</span>
</div>
<div className="mcp-server-item">
<svg width="20" height="20" viewBox="0 0 17.732 24.269" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#bdb9b4" d="m6.565 9.368 2.266 2.738 6.674-7.84c.353-.47.52-.717.353-1.117a1.218 1.218 0 0 0-1.061-.748.953.953 0 0 0-.712.262Z"/><path fill="#b31b1b" d="M12.541 10.677 1.935.503a1.413 1.413 0 0 0-.834-.5 1.09 1.09 0 0 0-1.027.66c-.167.4-.047.681.319 1.206l8.44 10.242-6.282 7.716a1.336 1.336 0 0 0-.323 1.3 1.114 1.114 0 0 0 1.04.69.992.992 0 0 0 .748-.365l8.519-7.92a1.924 1.924 0 0 0 .006-2.855Z"/><path fill="#bdb9b4" d="M17.336 22.364 8.811 12.089 6.546 9.352l-1.389 1.254a2.063 2.063 0 0 0 0 2.965L15.969 23.99a.925.925 0 0 0 .742.282 1.039 1.039 0 0 0 .953-.667 1.261 1.261 0 0 0-.328-1.241Z"/></svg>
<span className="mcp-server-name">arxiv_local</span>
</div>
<div className="mcp-server-item">
<svg xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48" width="20px" height="20px" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#4caf50" d="M44,24c0,11.044-8.956,20-20,20S4,35.044,4,24S12.956,4,24,4S44,12.956,44,24z"/><path fill="#ffc107" d="M24,4v20l8,4l-8.843,16c0.317,0,0.526,0,0.843,0c11.053,0,20-8.947,20-20S35.053,4,24,4z"/><path fill="#4caf50" d="M44,24c0,11.044-8.956,20-20,20S4,35.044,4,24S12.956,4,24,4S44,12.956,44,24z"/><path fill="#ffc107" d="M24,4v20l8,4l-8.843,16c0.317,0,0.526,0,0.843,0c11.053,0,20-8.947,20-20S35.053,4,24,4z"/><path fill="#f44336" d="M41.84,15H24v13l-3-1L7.16,13.26H7.14C10.68,7.69,16.91,4,24,4C31.8,4,38.55,8.48,41.84,15z"/><path fill="#dd2c00" d="M7.158,13.264l8.843,14.862L21,27L7.158,13.264z"/><path fill="#558b2f" d="M23.157,44l8.934-16.059L28,25L23.157,44z"/><path fill="#f9a825" d="M41.865,15H24l-1.579,4.58L41.865,15z"/><path fill="#fff" d="M33,24c0,4.969-4.031,9-9,9s-9-4.031-9-9s4.031-9,9-9S33,19.031,33,24z"/><path fill="#2196f3" d="M31,24c0,3.867-3.133,7-7,7s-7-3.133-7-7s3.133-7,7-7S31,20.133,31,24z"/></svg>
<span className="mcp-server-name">playwright_with_chunk</span>
</div>
</div>
</div>
<div className="local-tools-container">
<div className="mcp-servers-title">
Local Tools
</div>
<div className="local-tools-grid">
<div className="local-tool-item">
<svg width="20px" height="20px" viewBox="0 0 100 100" enable-background="new 0 0 100 100" id="Layer_1" version="1.1" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style={{margin: 0, padding: 0, display: 'inline-block'}}><g><g><rect clip-rule="evenodd" fill="#F2F2F2" fill-rule="evenodd" height="83.437" width="67.025" x="9.012" y="7.604"/><path d="M77.454,92.458H7.595V6.187h69.859V92.458z M10.429,89.624H74.62V9.021H10.429V89.624z"/></g><g><rect clip-rule="evenodd" fill="#FF7C24" fill-rule="evenodd" height="10.481" width="17.952" x="46.695" y="34.866"/></g><g><rect height="2.834" width="19.463" x="20.504" y="35.575"/></g><g><rect height="2.834" width="15.561" x="20.718" y="42.508"/></g><g><rect height="2.833" width="15.562" x="20.813" y="49.514"/></g><g><rect height="2.833" width="27.128" x="20.718" y="56.753"/></g><g><rect height="2.833" width="23.51" x="20.718" y="63.688"/></g><g><rect clip-rule="evenodd" fill="#39B6CC" fill-rule="evenodd" height="9.004" width="44.095" x="20.553" y="19.064"/></g><g><rect height="2.833" width="26.272" x="20.718" y="70.32"/></g><g><rect height="2.834" width="32.8" x="20.718" y="77.253"/></g><g><rect height="2.834" width="3.235" x="38.304" y="42.508"/></g><g><path clip-rule="evenodd" d="M77.931,71.902l4.287,4.427l-6.644,6.437l-4.309-4.457    C74.147,76.998,76.504,74.726,77.931,71.902L77.931,71.902z" fill="#F2F2F2" fill-rule="evenodd"/><path d="M75.542,84.77l-6.692-6.92l1.828-0.831c2.579-1.174,4.706-3.218,5.989-5.756l0.897-1.776l6.656,6.874L75.542,84.77z     M73.584,78.669l2.023,2.091l4.605-4.463l-2.007-2.074C76.994,76.012,75.414,77.531,73.584,78.669z"/></g><g><polygon clip-rule="evenodd" fill="#39B6CC" fill-rule="evenodd" points="83.267,75.319 91.984,84.338 83.247,92.779     74.535,83.761   "/><path d="M83.213,94.783L72.531,83.726l10.771-10.41l10.687,11.056L83.213,94.783z M76.538,83.794l6.744,6.981l6.698-6.472    l-6.748-6.981L76.538,83.794z"/></g><g><path clip-rule="evenodd" d="M66.124,50.799c7.742,0,14.018,6.276,14.018,14.019    s-6.275,14.019-14.018,14.019c-7.743,0-14.019-6.276-14.019-14.019S58.381,50.799,66.124,50.799L66.124,50.799z" fill="#F2F2F2" fill-rule="evenodd"/><path d="M66.124,80.253c-8.511,0-15.435-6.924-15.435-15.435s6.924-15.435,15.435-15.435S81.56,56.307,81.56,64.818    S74.635,80.253,66.124,80.253z M66.124,52.216c-6.949,0-12.601,5.653-12.601,12.602s5.651,12.601,12.601,12.601    c6.948,0,12.602-5.652,12.602-12.601S73.072,52.216,66.124,52.216z"/></g><g><rect height="2.833" width="10.313" x="39.902" y="49.514"/></g><g><path d="M76.404,65.586H73.57c0-0.636-0.068-1.255-0.205-1.84c-0.043-0.186-0.096-0.385-0.169-0.63l2.717-0.808    c0.091,0.304,0.158,0.559,0.215,0.801C76.31,63.901,76.404,64.735,76.404,65.586z M72.438,61.433    c-1.489-2.5-4.203-4.058-7.084-4.061l0.004-2.834c3.871,0.005,7.518,2.091,9.516,5.445L72.438,61.433z"/></g></g></svg>
<span className="local-tool-name">history</span>
</div>
<div className="local-tool-item">
<svg width="20px" height="20px" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M861.588238 240.133873v-65.792823c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.631049H314.659414v-65.631049c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.792823c-36.317212 0.868255-65.631049 30.539428-65.63105 67.061417v543.745565c0 37.06772 30.155471 67.223191 67.223191 67.223191h696.886045c37.06772 0 67.223191-30.155471 67.223191-67.223191V307.19529c-0.001024-36.52199-29.315885-66.193162-65.633097-67.061417z m-109.385765-65.792823c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m-546.928824 0c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m678.191947 676.600829c0 12.935767-10.532708 23.468476-23.468476 23.468475H163.111076c-12.935767 0-23.468476-10.532708-23.468476-23.468475V307.19529c0-12.402323 9.677764-22.593054 21.877358-23.415233v65.577807c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.631049h393.789368v65.631049c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.577807c12.19857 0.82218 21.877358 11.012911 21.877358 23.415233v543.746589z" fill="#22C67F" /><path d="M706.719439 478.272194l-48.01715-44.741741-182.28128 195.621482-111.468348-122.615387-48.563905 44.148911 159.469116 172.685427z" fill="#74E8AE" /></svg>
<span className="local-tool-name">claim_done</span>
</div>
<div className="local-tool-item">
<svg height="20" width="20" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg>
<span className="local-tool-name">web_search</span>
</div>
<div className="local-tool-item">
<Icon icon="bars-progress" size={20} color="#4286f6" />
<span className="local-tool-name">manage_context</span>
</div>
<div className="local-tool-item">
<Icon icon="filter-list" size={20} color="#4286f6" />
<span className="local-tool-name">handle_overlong_tool_outputs</span>
</div>
</div>
</div>
</div>
</Card>









## Instruction

I am conducting research on papers for an AI Conference. For each paper, please help me find the full name of the first author, the complete institutional affiliation of the first author exactly as it appears in the paper (including all institutions if multiple are listed, and specifying down to the department level when provided), and the link to the first author‚Äôs Google Scholar profile. You need to fill them in the corresponding excel sheet under my workspace.


## Initial State

### Local Workspace

<div className="file-tree">
<a href="https://github.com/hkust-nlp/mcpbench_dev/tree/finalpool_dev/tasks/finalpool/academic-pdf-report/initial_workspace">workspace</a>/
‚îî‚îÄ‚îÄ paper_initial.csv
</div>

## Model Trajectory

<AccordionGroup>
<Accordion title="claude-4-sonnet">

<Columns cols={3}>
<Card title="Task Completion" icon="check">
Completed
</Card>
<Card title="Tool Calls" icon="wrench">
33
</Card>
<Card title="Turns" icon="arrows-rotate">
33
</Card>
</Columns>

<div className="thinking-box">
üßê`Agent`

I'll help you conduct research on papers for an AI Conference. First, let me check what's in your workspace to locate the Excel sheet with the papers.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48" width="14px" height="14px" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#0277bd" d="M19.847,41.956c-5.629-0.002-11.259,0.024-16.888-0.013c-2.855-0.019-3.374-0.7-2.731-3.525 c2.178-9.58,4.427-19.143,6.557-28.734C7.356,7.112,8.588,5.975,11.312,6C22.57,6.106,33.829,6.034,45.088,6.046 c2.824,0.003,3.298,0.614,2.664,3.511c-2.058,9.406-4.129,18.809-6.236,28.203c-0.789,3.516-1.697,4.187-5.353,4.195 C30.724,41.966,25.285,41.958,19.847,41.956z"/><path fill="#fafafa" d="M25.057 23.922c-.608-.687-1.114-1.267-1.531-1.732-2.43-2.728-4.656-5.27-7.063-7.869-1.102-1.189-1.453-2.344-.13-3.518 1.307-1.16 2.592-1.058 3.791.277 3.34 3.717 6.676 7.438 10.071 11.104 1.268 1.369.972 2.3-.424 3.315-5.359 3.895-10.687 7.833-16.01 11.778-1.196.887-2.337 1.109-3.304-.201-1.066-1.445-.08-2.305 1.026-3.114 3.955-2.893 7.903-5.798 11.834-8.725C23.865 24.83 24.595 24.267 25.057 23.922zM21.75 37C20.625 37 20 36 20 35s.625-2 1.75-2c4.224 0 6.112 0 9.5 0 1.125 0 1.75 1 1.75 2s-.625 2-1.75 2C29.125 37 25 37 21.75 37z"/></svg> `terminal run_command`

<Expandable title="Details">
```json arguments
{
	"command": "ls -la /workspace/dumps/workspace"
}

```

```json output_result
[
{"type": "text", "text": "total 28 drwxr-xr-x 4 root root 4096 Oct 19 04:10 . drwxr-xr-x 4 root root 4096 Oct 19 04:10 .. drwxr-xr-x 2 root root 4096 Oct 19 04:10 .pdf_tools_tempfiles drwxr-xr-x 2 root root 4096 Oct 19 04:10 arxiv_local_storage -rw-r--r-- 1 root root 9322 Oct 15 15:54 paper_initial.xlsx ", "annotations": null},
{"type": "text", "text": " Command completed with return code: 0", "annotations": null}
]
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Great! I found the Excel file `paper_initial.xlsx`. Let me examine its structure to understand what papers need to be researched.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel read_data_from_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1"
}

```

```json output_result
{
  "range": "A1:D7",
  "sheet_name": "Sheet1",
  "cells": [
    {
      "address": "A1",
      "value": "Title",
      "row": 1,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B1",
      "value": "First Author",
      "row": 1,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C1",
      "value": "Affiliation",
      "row": 1,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D1",
      "value": "Google Scholar Profile",
      "row": 1,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A2",
      "value": "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning",
      "row": 2,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B2",
      "value": null,
      "row": 2,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C2",
      "value": null,
      "row": 2,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D2",
      "value": null,
      "row": 2,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A3",
      "value": "Model Immunization from a Condition Number Perspective",
      "row": 3,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B3",
      "value": null,
      "row": 3,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C3",
      "value": null,
      "row": 3,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D3",
      "value": null,
      "row": 3,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A4",
      "value": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows",
      "row": 4,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B4",
      "value": null,
      "row": 4,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C4",
      "value": null,
      "row": 4,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D4",
      "value": null,
      "row": 4,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A5",
      "value": "Learning with Expected Signatures: Theory and Applications",
      "row": 5,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B5",
      "value": null,
      "row": 5,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C5",
      "value": null,
      "row": 5,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D5",
      "value": null,
      "row": 5,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A6",
      "value": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
      "row": 6,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B6",
      "value": null,
      "row": 6,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C6",
      "value": null,
      "row": 6,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D6",
      "value": null,
      "row": 6,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A7",
      "value": "Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction",
      "row": 7,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B7",
      "value": null,
      "row": 7,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C7",
      "value": null,
      "row": 7,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D7",
      "value": null,
      "row": 7,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    }
  ]
}
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! I can see the Excel sheet has 6 papers with titles in column A, and I need to fill in:
- Column B: First Author (full name)
- Column C: Affiliation (complete institutional affiliation)
- Column D: Google Scholar Profile (link)

Let me start researching each paper. I'll search for each paper on arXiv to find the detailed information.

Let me start with the first paper: "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning"
</div>

<div className="result-box">
<svg width="14" height="14" viewBox="0 0 17.732 24.269" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#bdb9b4" d="m6.565 9.368 2.266 2.738 6.674-7.84c.353-.47.52-.717.353-1.117a1.218 1.218 0 0 0-1.061-.748.953.953 0 0 0-.712.262Z"/><path fill="#b31b1b" d="M12.541 10.677 1.935.503a1.413 1.413 0 0 0-.834-.5 1.09 1.09 0 0 0-1.027.66c-.167.4-.047.681.319 1.206l8.44 10.242-6.282 7.716a1.336 1.336 0 0 0-.323 1.3 1.114 1.114 0 0 0 1.04.69.992.992 0 0 0 .748-.365l8.519-7.92a1.924 1.924 0 0 0 .006-2.855Z"/><path fill="#bdb9b4" d="M17.336 22.364 8.811 12.089 6.546 9.352l-1.389 1.254a2.063 2.063 0 0 0 0 2.965L15.969 23.99a.925.925 0 0 0 .742.282 1.039 1.039 0 0 0 .953-.667 1.261 1.261 0 0 0-.328-1.241Z"/></svg> `arxiv_local search_papers`

<Expandable title="Details">
```json arguments
{
	"query": "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning",
	 "max_results": 5
}

```

```json output_result
{
  "total_results": 5,
  "papers": [
    {
      "id": "2510.14981v1",
      "title": "Coupled Diffusion Sampling for Training-Free Multi-View Image Editing",
      "authors": [
        "Hadi Alzayer",
        "Yunzhi Zhang",
        "Chen Geng",
        "Jia-Bin Huang",
        "Jiajun Wu"
      ],
      "abstract": "We present an inference-time diffusion sampling method to perform multi-view\nconsistent image editing using pre-trained 2D image editing models. These\nmodels can independently produce high-quality edits for each image in a set of\nmulti-view images of a 3D scene or object, but they do not maintain consistency\nacross views. Existing approaches typically address this by optimizing over\nexplicit 3D representations, but they suffer from a lengthy optimization\nprocess and instability under sparse view settings. We propose an implicit 3D\nregularization approach by constraining the generated 2D image sequences to\nadhere to a pre-trained multi-view image distribution. This is achieved through\ncoupled diffusion sampling, a simple diffusion sampling technique that\nconcurrently samples two trajectories from both a multi-view image distribution\nand a 2D edited image distribution, using a coupling term to enforce the\nmulti-view consistency among the generated images. We validate the\neffectiveness and generality of this framework on three distinct multi-view\nimage editing tasks, demonstrating its applicability across various model\narchitectures and highlighting its potential as a general solution for\nmulti-view consistent editing.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-10-16T17:59:59+00:00",
      "url": "http://arxiv.org/pdf/2510.14981v1",
      "resource_uri": "arxiv://2510.14981v1"
    },
    {
      "id": "2510.14979v1",
      "title": "From Pixels to Words -- Towards Native Vision-Language Primitives at Scale",
      "authors": [
        "Haiwen Diao",
        "Mingxuan Li",
        "Silei Wu",
        "Linjun Dai",
        "Xiaohua Wang",
        "Hanming Deng",
        "Lewei Lu",
        "Dahua Lin",
        "Ziwei Liu"
      ],
      "abstract": "The edifice of native Vision-Language Models (VLMs) has emerged as a rising\ncontender to typical modular VLMs, shaped by evolving model architectures and\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\nexploration and promotion: (-) What fundamental constraints set native VLMs\napart from modular ones, and to what extent can these barriers be overcome? (-)\nHow to make research in native VLMs more accessible and democratized, thereby\naccelerating progress in the field. In this paper, we clarify these challenges\nand outline guiding principles for constructing native VLMs. Specifically, one\nnative VLM primitive should: (i) effectively align pixel and word\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\nstrengths of formerly separate vision and language modules; (iii) inherently\nembody various cross-modal properties that support unified vision-language\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\nnative VLMs built from first principles, capable of rivaling top-tier modular\ncounterparts across diverse real-world scenarios. With only 390M image-text\nexamples, NEO efficiently develops visual perception from scratch while\nmitigating vision-language conflicts inside a dense and monolithic model\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\nscalable and powerful native VLMs, paired with a rich set of reusable\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-10-16T17:59:58+00:00",
      "url": "http://arxiv.org/pdf/2510.14979v1",
      "resource_uri": "arxiv://2510.14979v1"
    },
    {
      "id": "2510.14980v1",
      "title": "Agentic Design of Compositional Machines",
      "authors": [
        "Wenqian Zhang",
        "Weiyang Liu",
        "Zhen Liu"
      ],
      "abstract": "The design of complex machines stands as both a marker of human intelligence\nand a foundation of engineering practice. Given recent advances in large\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\napproach this question through the lens of compositional machine design: a task\nin which machines are assembled from standardized components to meet functional\ndemands like locomotion or manipulation in a simulated physical environment. To\nsupport this investigation, we introduce BesiegeField, a testbed built on the\nmachine-building game Besiege, which enables part-based construction, physical\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\nrequired for success, including spatial reasoning, strategic assembly, and\ninstruction-following. As current open-source models fall short, we explore\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\ndataset, conduct RL finetuning experiments, and highlight open challenges at\nthe intersection of language, machine design, and physical reasoning.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:58+00:00",
      "url": "http://arxiv.org/pdf/2510.14980v1",
      "resource_uri": "arxiv://2510.14980v1"
    },
    {
      "id": "2510.14978v1",
      "title": "Learning an Image Editing Model without Image Editing Pairs",
      "authors": [
        "Nupur Kumari",
        "Sheng-Yu Wang",
        "Nanxuan Zhao",
        "Yotam Nitzan",
        "Yuheng Li",
        "Krishna Kumar Singh",
        "Richard Zhang",
        "Eli Shechtman",
        "Jun-Yan Zhu",
        "Xun Huang"
      ],
      "abstract": "Recent image editing models have achieved impressive results while following\nnatural language editing instructions, but they rely on supervised fine-tuning\nwith large datasets of input-target pairs. This is a critical bottleneck, as\nsuch naturally occurring pairs are hard to curate at scale. Current workarounds\nuse synthetic training pairs that leverage the zero-shot capabilities of\nexisting models. However, this can propagate and magnify the artifacts of the\npretrained model into the final trained model. In this work, we present a new\ntraining paradigm that eliminates the need for paired data entirely. Our\napproach directly optimizes a few-step diffusion model by unrolling it during\ntraining and leveraging feedback from vision-language models (VLMs). For each\ninput and editing instruction, the VLM evaluates if an edit follows the\ninstruction and preserves unchanged content, providing direct gradients for\nend-to-end optimization. To ensure visual fidelity, we incorporate distribution\nmatching loss (DMD), which constrains generated images to remain within the\nimage manifold learned by pretrained models. We evaluate our method on standard\nbenchmarks and include an extensive ablation study. Without any paired data,\nour method performs on par with various image editing diffusion models trained\non extensive supervised paired data, under the few-step setting. Given the same\nVLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:57+00:00",
      "url": "http://arxiv.org/pdf/2510.14978v1",
      "resource_uri": "arxiv://2510.14978v1"
    },
    {
      "id": "2510.14976v1",
      "title": "Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation",
      "authors": [
        "Shaowei Liu",
        "Chuan Guo",
        "Bing Zhou",
        "Jian Wang"
      ],
      "abstract": "Close-proximity human-human interactive poses convey rich contextual\ninformation about interaction dynamics. Given such poses, humans can\nintuitively infer the context and anticipate possible past and future dynamics,\ndrawing on strong priors of human behavior. Inspired by this observation, we\npropose Ponimator, a simple framework anchored on proximal interactive poses\nfor versatile interaction animation. Our training data consists of\nclose-contact two-person poses and their surrounding temporal context from\nmotion-capture interaction datasets. Leveraging interactive pose priors,\nPonimator employs two conditional diffusion models: (1) a pose animator that\nuses the temporal prior to generate dynamic motion sequences from interactive\nposes, and (2) a pose generator that applies the spatial prior to synthesize\ninteractive poses from a single pose, text, or both when interactive poses are\nunavailable. Collectively, Ponimator supports diverse tasks, including\nimage-based interaction animation, reaction animation, and text-to-interaction\nsynthesis, facilitating the transfer of interaction knowledge from high-quality\nmocap data to open-world scenarios. Empirical experiments across diverse\ndatasets and applications demonstrate the universality of the pose prior and\nthe effectiveness and robustness of our framework.",
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.RO"
      ],
      "published": "2025-10-16T17:59:56+00:00",
      "url": "http://arxiv.org/pdf/2510.14976v1",
      "resource_uri": "arxiv://2510.14976v1"
    }
  ]
}
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

The search didn't return the exact paper I'm looking for. Let me try a more specific search with different keywords.
</div>

<div className="result-box">
<svg width="14" height="14" viewBox="0 0 17.732 24.269" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#bdb9b4" d="m6.565 9.368 2.266 2.738 6.674-7.84c.353-.47.52-.717.353-1.117a1.218 1.218 0 0 0-1.061-.748.953.953 0 0 0-.712.262Z"/><path fill="#b31b1b" d="M12.541 10.677 1.935.503a1.413 1.413 0 0 0-.834-.5 1.09 1.09 0 0 0-1.027.66c-.167.4-.047.681.319 1.206l8.44 10.242-6.282 7.716a1.336 1.336 0 0 0-.323 1.3 1.114 1.114 0 0 0 1.04.69.992.992 0 0 0 .748-.365l8.519-7.92a1.924 1.924 0 0 0 .006-2.855Z"/><path fill="#bdb9b4" d="M17.336 22.364 8.811 12.089 6.546 9.352l-1.389 1.254a2.063 2.063 0 0 0 0 2.965L15.969 23.99a.925.925 0 0 0 .742.282 1.039 1.039 0 0 0 .953-.667 1.261 1.261 0 0 0-.328-1.241Z"/></svg> `arxiv_local search_papers`

<Expandable title="Details">
```json arguments
{
	"query": "Strategy Coopetition Emergence Transience In-Context Learning",
	 "max_results": 10
}

```

```json output_result
{
  "total_results": 10,
  "papers": [
    {
      "id": "2510.14979v1",
      "title": "From Pixels to Words -- Towards Native Vision-Language Primitives at Scale",
      "authors": [
        "Haiwen Diao",
        "Mingxuan Li",
        "Silei Wu",
        "Linjun Dai",
        "Xiaohua Wang",
        "Hanming Deng",
        "Lewei Lu",
        "Dahua Lin",
        "Ziwei Liu"
      ],
      "abstract": "The edifice of native Vision-Language Models (VLMs) has emerged as a rising\ncontender to typical modular VLMs, shaped by evolving model architectures and\ntraining paradigms. Yet, two lingering clouds cast shadows over its widespread\nexploration and promotion: (-) What fundamental constraints set native VLMs\napart from modular ones, and to what extent can these barriers be overcome? (-)\nHow to make research in native VLMs more accessible and democratized, thereby\naccelerating progress in the field. In this paper, we clarify these challenges\nand outline guiding principles for constructing native VLMs. Specifically, one\nnative VLM primitive should: (i) effectively align pixel and word\nrepresentations within a shared semantic space; (ii) seamlessly integrate the\nstrengths of formerly separate vision and language modules; (iii) inherently\nembody various cross-modal properties that support unified vision-language\nencoding, aligning, and reasoning. Hence, we launch NEO, a novel family of\nnative VLMs built from first principles, capable of rivaling top-tier modular\ncounterparts across diverse real-world scenarios. With only 390M image-text\nexamples, NEO efficiently develops visual perception from scratch while\nmitigating vision-language conflicts inside a dense and monolithic model\ncrafted from our elaborate primitives. We position NEO as a cornerstone for\nscalable and powerful native VLMs, paired with a rich set of reusable\ncomponents that foster a cost-effective and extensible ecosystem. Our code and\nmodels are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2025-10-16T17:59:58+00:00",
      "url": "http://arxiv.org/pdf/2510.14979v1",
      "resource_uri": "arxiv://2510.14979v1"
    },
    {
      "id": "2510.14980v1",
      "title": "Agentic Design of Compositional Machines",
      "authors": [
        "Wenqian Zhang",
        "Weiyang Liu",
        "Zhen Liu"
      ],
      "abstract": "The design of complex machines stands as both a marker of human intelligence\nand a foundation of engineering practice. Given recent advances in large\nlanguage models (LLMs), we ask whether they, too, can learn to create. We\napproach this question through the lens of compositional machine design: a task\nin which machines are assembled from standardized components to meet functional\ndemands like locomotion or manipulation in a simulated physical environment. To\nsupport this investigation, we introduce BesiegeField, a testbed built on the\nmachine-building game Besiege, which enables part-based construction, physical\nsimulation and reward-driven evaluation. Using BesiegeField, we benchmark\nstate-of-the-art LLMs with agentic workflows and identify key capabilities\nrequired for success, including spatial reasoning, strategic assembly, and\ninstruction-following. As current open-source models fall short, we explore\nreinforcement learning (RL) as a path to improvement: we curate a cold-start\ndataset, conduct RL finetuning experiments, and highlight open challenges at\nthe intersection of language, machine design, and physical reasoning.",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:58+00:00",
      "url": "http://arxiv.org/pdf/2510.14980v1",
      "resource_uri": "arxiv://2510.14980v1"
    },
    {
      "id": "2510.14978v1",
      "title": "Learning an Image Editing Model without Image Editing Pairs",
      "authors": [
        "Nupur Kumari",
        "Sheng-Yu Wang",
        "Nanxuan Zhao",
        "Yotam Nitzan",
        "Yuheng Li",
        "Krishna Kumar Singh",
        "Richard Zhang",
        "Eli Shechtman",
        "Jun-Yan Zhu",
        "Xun Huang"
      ],
      "abstract": "Recent image editing models have achieved impressive results while following\nnatural language editing instructions, but they rely on supervised fine-tuning\nwith large datasets of input-target pairs. This is a critical bottleneck, as\nsuch naturally occurring pairs are hard to curate at scale. Current workarounds\nuse synthetic training pairs that leverage the zero-shot capabilities of\nexisting models. However, this can propagate and magnify the artifacts of the\npretrained model into the final trained model. In this work, we present a new\ntraining paradigm that eliminates the need for paired data entirely. Our\napproach directly optimizes a few-step diffusion model by unrolling it during\ntraining and leveraging feedback from vision-language models (VLMs). For each\ninput and editing instruction, the VLM evaluates if an edit follows the\ninstruction and preserves unchanged content, providing direct gradients for\nend-to-end optimization. To ensure visual fidelity, we incorporate distribution\nmatching loss (DMD), which constrains generated images to remain within the\nimage manifold learned by pretrained models. We evaluate our method on standard\nbenchmarks and include an extensive ablation study. Without any paired data,\nour method performs on par with various image editing diffusion models trained\non extensive supervised paired data, under the few-step setting. Given the same\nVLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:57+00:00",
      "url": "http://arxiv.org/pdf/2510.14978v1",
      "resource_uri": "arxiv://2510.14978v1"
    },
    {
      "id": "2510.14977v1",
      "title": "Terra: Explorable Native 3D World Model with Point Latents",
      "authors": [
        "Yuanhui Huang",
        "Weiliang Chen",
        "Wenzhao Zheng",
        "Xin Tao",
        "Pengfei Wan",
        "Jie Zhou",
        "Jiwen Lu"
      ],
      "abstract": "World models have garnered increasing attention for comprehensive modeling of\nthe real world. However, most existing methods still rely on pixel-aligned\nrepresentations as the basis for world evolution, neglecting the inherent 3D\nnature of the physical world. This could undermine the 3D consistency and\ndiminish the modeling efficiency of world models. In this paper, we present\nTerra, a native 3D world model that represents and generates explorable\nenvironments in an intrinsic 3D latent space. Specifically, we propose a novel\npoint-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into\na latent point representation, which is subsequently decoded as 3D Gaussian\nprimitives to jointly model geometry and appearance. We then introduce a sparse\npoint flow matching network (SPFlow) for generating the latent point\nrepresentation, which simultaneously denoises the positions and features of the\npoint latents. Our Terra enables exact multi-view consistency with native 3D\nrepresentation and architecture, and supports flexible rendering from any\nviewpoint with only a single generation process. Furthermore, Terra achieves\nexplorable world modeling through progressive generation in the point latent\nspace. We conduct extensive experiments on the challenging indoor scenes from\nScanNet v2. Terra achieves state-of-the-art performance in both reconstruction\nand generation with high 3D consistency.",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:56+00:00",
      "url": "http://arxiv.org/pdf/2510.14977v1",
      "resource_uri": "arxiv://2510.14977v1"
    },
    {
      "id": "2510.14974v1",
      "title": "pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation",
      "authors": [
        "Hansheng Chen",
        "Kai Zhang",
        "Hao Tan",
        "Leonidas Guibas",
        "Gordon Wetzstein",
        "Sai Bi"
      ],
      "abstract": "Few-step diffusion or flow-based generative models typically distill a\nvelocity-predicting teacher into a student that predicts a shortcut towards\ndenoised data. This format mismatch has led to complex distillation procedures\nthat often suffer from a quality-diversity trade-off. To address this, we\npropose policy-based flow models ($\\pi$-Flow). $\\pi$-Flow modifies the output\nlayer of a student flow model to predict a network-free policy at one timestep.\nThe policy then produces dynamic flow velocities at future substeps with\nnegligible overhead, enabling fast and accurate ODE integration on these\nsubsteps without extra network evaluations. To match the policy's ODE\ntrajectory to the teacher's, we introduce a novel imitation distillation\napproach, which matches the policy's velocity to the teacher's along the\npolicy's trajectory using a standard $\\ell_2$ flow matching loss. By simply\nmimicking the teacher's behavior, $\\pi$-Flow enables stable and scalable\ntraining and avoids the quality-diversity trade-off. On ImageNet 256$^2$, it\nattains a 1-NFE FID of 2.85, outperforming MeanFlow of the same DiT\narchitecture. On FLUX.1-12B and Qwen-Image-20B at 4 NFEs, $\\pi$-Flow achieves\nsubstantially better diversity than state-of-the-art few-step methods, while\nmaintaining teacher-level quality.",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2025-10-16T17:59:51+00:00",
      "url": "http://arxiv.org/pdf/2510.14974v1",
      "resource_uri": "arxiv://2510.14974v1"
    },
    {
      "id": "2510.14973v1",
      "title": "Attention Is All You Need for KV Cache in Diffusion LLMs",
      "authors": [
        "Quan Nguyen-Tri",
        "Mukul Ranjan",
        "Zhiqiang Shen"
      ],
      "abstract": "This work studies how to adaptively recompute key-value (KV) caches for\ndiffusion large language models (DLMs) to maximize prediction accuracy while\nminimizing decoding latency. Prior methods' decoders recompute QKV for all\ntokens at every denoising step and layer, despite KV states changing little\nacross most steps, especially in shallow layers, leading to substantial\nredundancy. We make three observations: (1) distant ${\\bf MASK}$ tokens\nprimarily act as a length-bias and can be cached block-wise beyond the active\nprediction window; (2) KV dynamics increase with depth, suggesting that\nselective refresh starting from deeper layers is sufficient; and (3) the\nmost-attended token exhibits the smallest KV drift, providing a conservative\nlower bound on cache change for other tokens. Building on these, we propose\n${\\bf Elastic-Cache}$, a training-free, architecture-agnostic strategy that\njointly decides ${when}$ to refresh (via an attention-aware drift test on the\nmost-attended token) and ${where}$ to refresh (via a depth-aware schedule that\nrecomputes from a chosen layer onward while reusing shallow-layer caches and\noff-window MASK caches). Unlike fixed-period schemes, Elastic-Cache performs\nadaptive, layer-aware cache updates for diffusion LLMs, reducing redundant\ncomputation and accelerating decoding with negligible loss in generation\nquality. Experiments on LLaDA-Instruct, LLaDA-1.5, and LLaDA-V across\nmathematical reasoning and code generation tasks demonstrate consistent\nspeedups: $8.7\\times$ on GSM8K (256 tokens), $45.1\\times$ on longer sequences,\nand $4.8\\times$ on HumanEval, while consistently maintaining higher accuracy\nthan the baseline. Our method achieves significantly higher throughput\n($6.8\\times$ on GSM8K) than existing confidence-based approaches while\npreserving generation quality, enabling practical deployment of diffusion LLMs.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:48+00:00",
      "url": "http://arxiv.org/pdf/2510.14973v1",
      "resource_uri": "arxiv://2510.14973v1"
    },
    {
      "id": "2510.14972v1",
      "title": "TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar",
      "authors": [
        "Yinxi Li",
        "Yuntian Deng",
        "Pengyu Nie"
      ],
      "abstract": "Large language models (LLMs) for code rely on subword tokenizers, such as\nbyte-pair encoding (BPE), learned from mixed natural language text and\nprogramming language code but driven by statistics rather than grammar. As a\nresult, semantically identical code snippets can be tokenized differently\ndepending on superficial factors such as whitespace or identifier naming. To\nmeasure the impact of this misalignment, we introduce TokDrift, a framework\nthat applies semantic-preserving rewrite rules to create code variants\ndiffering only in tokenization. Across nine code LLMs, including large ones\nwith over 30B parameters, even minor formatting changes can cause substantial\nshifts in model behavior. Layer-wise analysis shows that the issue originates\nin early embeddings, where subword segmentation fails to capture grammar token\nboundaries. Our findings identify misaligned tokenization as a hidden obstacle\nto reliable code understanding and generation, highlighting the need for\ngrammar-aware tokenization for future code LLMs.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "cs.SE"
      ],
      "published": "2025-10-16T17:59:45+00:00",
      "url": "http://arxiv.org/pdf/2510.14972v1",
      "resource_uri": "arxiv://2510.14972v1"
    },
    {
      "id": "2510.14969v1",
      "title": "LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training",
      "authors": [
        "Yiming Wang",
        "Da Yin",
        "Yuedong Cui",
        "Ruichen Zheng",
        "Zhiqian Li",
        "Zongyu Lin",
        "Di Wu",
        "Xueqing Wu",
        "Chenchen Ye",
        "Yu Zhou",
        "Kai-Wei Chang"
      ],
      "abstract": "Digital agents require diverse, large-scale UI trajectories to generalize\nacross real-world tasks, yet collecting such data is prohibitively expensive in\nboth human annotation, infra and engineering perspectives. To this end, we\nintroduce $\\textbf{UI-Simulator}$, a scalable paradigm that generates\nstructured UI states and transitions to synthesize training trajectories at\nscale. Our paradigm integrates a digital world simulator for diverse UI states,\na guided rollout process for coherent exploration, and a trajectory wrapper\nthat produces high-quality and diverse trajectories for agent training. We\nfurther propose $\\textbf{UI-Simulator-Grow}$, a targeted scaling strategy that\nenables more rapid and data-efficient scaling by prioritizing high-impact tasks\nand synthesizes informative trajectory variants. Experiments on WebArena and\nAndroidWorld show that UI-Simulator rivals or surpasses open-source agents\ntrained on real UIs with significantly better robustness, despite using weaker\nteacher models. Moreover, UI-Simulator-Grow matches the performance of\nLlama-3-70B-Instruct using only Llama-3-8B-Instruct as the base model,\nhighlighting the potential of targeted synthesis scaling paradigm to\ncontinuously and efficiently enhance the digital agents.",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:38+00:00",
      "url": "http://arxiv.org/pdf/2510.14969v1",
      "resource_uri": "arxiv://2510.14969v1"
    },
    {
      "id": "2510.14970v1",
      "title": "Biology-informed neural networks learn nonlinear representations from omics data to improve genomic prediction and interpretability",
      "authors": [
        "Katiana Kontolati",
        "Rini Jasmine Gladstone",
        "Ian Davis",
        "Ethan Pickering"
      ],
      "abstract": "We extend biologically-informed neural networks (BINNs) for genomic\nprediction (GP) and selection (GS) in crops by integrating thousands of\nsingle-nucleotide polymorphisms (SNPs) with multi-omics measurements and prior\nbiological knowledge. Traditional genotype-to-phenotype (G2P) models depend\nheavily on direct mappings that achieve only modest accuracy, forcing breeders\nto conduct large, costly field trials to maintain or marginally improve genetic\ngain. Models that incorporate intermediate molecular phenotypes such as gene\nexpression can achieve higher predictive fit, but they remain impractical for\nGS since such data are unavailable at deployment or design time. BINNs overcome\nthis limitation by encoding pathway-level inductive biases and leveraging\nmulti-omics data only during training, while using genotype data alone during\ninference. Applied to maize gene-expression and multi-environment field-trial\ndata, BINN improves rank-correlation accuracy by up to 56% within and across\nsubpopulations under sparse-data conditions and nonlinearly identifies genes\nthat GWAS/TWAS fail to uncover. With complete domain knowledge for a synthetic\nmetabolomics benchmark, BINN reduces prediction error by 75% relative to\nconventional neural nets and correctly identifies the most important nonlinear\npathway. Importantly, both cases show highly sensitive BINN latent variables\ncorrelate with the experimental quantities they represent, despite not being\ntrained on them. This suggests BINNs learn biologically-relevant\nrepresentations, nonlinear or linear, from genotype to phenotype. Together,\nBINNs establish a framework that leverages intermediate domain information to\nimprove genomic prediction accuracy and reveal nonlinear biological\nrelationships that can guide genomic selection, candidate gene selection,\npathway enrichment, and gene-editing prioritization.",
      "categories": [
        "cs.LG"
      ],
      "published": "2025-10-16T17:59:38+00:00",
      "url": "http://arxiv.org/pdf/2510.14970v1",
      "resource_uri": "arxiv://2510.14970v1"
    },
    {
      "id": "2510.14968v1",
      "title": "RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks",
      "authors": [
        "Mingxuan Yan",
        "Yuping Wang",
        "Zechun Liu",
        "Jiachen Li"
      ],
      "abstract": "To tackle long-horizon tasks, recent hierarchical vision-language-action\n(VLAs) frameworks employ vision-language model (VLM)-based planners to\ndecompose complex manipulation tasks into simpler sub-tasks that low-level\nvisuomotor policies can easily handle. Typically, the VLM planner is finetuned\nto learn to decompose a target task. This finetuning requires target task\ndemonstrations segmented into sub-tasks by either human annotation or heuristic\nrules. However, the heuristic subtasks can deviate significantly from the\ntraining data of the visuomotor policy, which degrades task performance. To\naddress these issues, we propose a Retrieval-based Demonstration Decomposer\n(RDD) that automatically decomposes demonstrations into sub-tasks by aligning\nthe visual features of the decomposed sub-task intervals with those from the\ntraining data of the low-level visuomotor policies. Our method outperforms the\nstate-of-the-art sub-task decomposer on both simulation and real-world tasks,\ndemonstrating robustness across diverse settings. Code and more results are\navailable at rdd-neurips.github.io.",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "published": "2025-10-16T17:59:37+00:00",
      "url": "http://arxiv.org/pdf/2510.14968v1",
      "resource_uri": "arxiv://2510.14968v1"
    }
  ]
}
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Still not finding the exact paper. Let me try a web search to find these papers and their authors.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Strategy Coopetition Explains the Emergence and Transience of In-Context Learning\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: Strategy Coopetition Explains the Emergence and ...
Link: https://arxiv.org/abs/2503.05631
Snippet: by AK Singh ¬∑ 2025 ¬∑ Cited by 9 ‚Äî Abstract page for arXiv paper 2503.05631: Strategy Coopetition Explains the Emergence and Transience of In-Context Learning.
Sitelinks: No sitelinks

Title: arXiv:2503.05631v2 [cs.LG] 10 Mar 2025
Link: https://arxiv.org/pdf/2503.05631?
Snippet: by AK Singh ¬∑ 2025 ¬∑ Cited by 9 ‚Äî Strategy coopetition explains the emergence and transience of in-context learning. 2015), before being input to the transformer (Singh et ...
Sitelinks: No sitelinks

Title: Revision History for Strategy Coopetition Explains the...
Link: https://openreview.net/revisions?id=ADEnKpNjF7
Snippet: Title: Strategy Coopetition Explains the Emergence and Transience of In-Context Learning. Authors: Aaditya K. Singh, Ted Moskovitz, Sara Dragutinovic, Felix ...
Sitelinks: No sitelinks

Title: Strategy Coopetition Explains the Emergence and Transience of ...
Link: https://chatpaper.com/chatpaper/paper/165004
Snippet: 1. Strategy Coopetition Explains the Emergence and Transience of In-Context Learning ¬∑ ChatDOC. ICML 202518 Jun 2025. Aaditya K Singh, Ted Moskovitz, Sara ...
Sitelinks: No sitelinks

Title: [Literature Review] Strategy Coopetition Explains the ...
Link: https://www.themoonlight.io/en/review/strategy-coopetition-explains-the-emergence-and-transience-of-in-context-learning
Snippet: The paper titled "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning ... https://arxiv.org/pdf/2503.05631.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Great! I found the paper. Let me get the PDF to extract the detailed author information and affiliations.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2503.05631",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 20
Extracted page range: 1-1

=== Page 1 ===
Strategy Coopetition Explains the Emergence
and Transience of In-Context Learning
Aaditya K. Singh1Ted Moskovitz2Sara Dragutinovi ¬¥c3Felix Hill4Stephanie C. Y. Chan* 4
Andrew M. Saxe* 1
Abstract
In-context learning (ICL) is a powerful ability that
emerges in transformer models, enabling them
to learn from context without weight updates.
Recent work has established emergent ICL as a
transient phenomenon that can sometimes dis-
appear after long training times. In this work,
we sought a mechanistic understanding of these
transient dynamics. Firstly, we find that‚Äîafter
the disappearance of ICL‚Äîthe asymptotic strat-
egy is a remarkable hybrid between in-weights
and in-context learning, which we term ‚Äúcontext-
constrained in-weights learning‚Äù (CIWL). CIWL
is in competition with ICL, and eventually re-
places it as the dominant strategy of the model
(thus leading to ICL transience). However, we
also find that the two competing strategies actu-
allyshare sub-circuits, which gives rise to coop-
erative dynamics as well. For example, in our
setup, ICL is unable to emerge quickly on its own,
and can only be enabled through the simultaneous
slow development of asymptotic CIWL. CIWL
thus both cooperates andcompetes with ICL, a
phenomenon we term ‚Äústrategy coopetition‚Äù. We
propose a minimal mathematical model that re-
produces these key dynamics and interactions. In-
formed by this model, we were able to identify a
setup where ICL is truly emergent and persistent.
1. Introduction
Transformer-based large language models (LLMs) show an
impressive propensity for in-context learning (ICL)‚Äîthe
ability to use inputs at inference time to adapt behavior
and solve tasks not seen in training. ICL contrasts with in-
weights learning (IWL), which is standard learning through
*Equal contribution1Gatsby Computational Neuroscience
Unit, University College London2Anthropic AI, work com-
pleted while at the Gatsby Unit, UCL3University of Oxford
4Google DeepMind. Correspondence to: Aaditya K. Singh <aa-
ditya.singh.21@ucl.ac.uk >.weight updates. ICL is striking not only for its power, but
also because it emerges without being explicitly trained
for (as Brown et al. (2020) first observed, when training
transformer models on internet-scale language corpora.).
Newer work has shown that ICL can sometimes in fact
disappear after emerging, i.e. it can be transient over the
course of training (Singh et al., 2023; Anand et al., 2024;
He et al., 2024).
This evolving picture of ICL necessitates a deeper under-
standing of the dynamics of ICL emergence (and transience).
ICL is often viewed to be in competition with other strate-
gies (Nguyen & Reddy, 2024; Park et al., 2024), such as
IWL, with the tradeoff thought to be modulated by data
properties (Chan et al., 2022; 2024), model size (Wei et al.,
2023), and/or training time (Singh et al., 2023). While com-
petition may explain why ICL gives way to other strategies
through the course of training, the question remains: why
does it emerge in the first place (if only to fade away)?
In this work, we aim to extend the mechanistic understand-
ing of ICL, which currently focuses on induction heads
(Olsson et al., 2022) and their emergence dynamics (Singh
et al., 2024), to a richer dynamical setting involving multiple
strategies cycling in and out over the course of learning. To
do so, we reproduce and investigate the key transience result
in a simplified synthetic data setting with a 2-layer attention-
only transformer. Using behavioral evaluators, we find the
asymptotic strategy after the disappearance of ICL is not
pure in-weights learning. Rather, it is a surprising hybrid
strategy that we term context-constrained in-weights learn-
ing (CIWL, Section 4). The implementation of CIWL takes
the form of skip-trigrams (Elhage et al., 2021) distributed
across multiple heads in a form of superposition (Elhage
et al., 2022). Perhaps even more remarkably, we find that
even though CIWL dominates over ICL asymptotically, both
strategies share critical sub-circuits (Section 5.1), indicating
cooperative dynamics between these seemingly competitive
mechanisms‚Äîa phenomenon we term ‚Äústrategy coopeti-
tion.‚Äù We borrow the term ‚Äúcoopetition‚Äù from game theory,
where it describes situations where competitors simultane-
ously cooperate and compete with each other.1Cooperation
1A classic historical examples is Hollywood studios in the early
1arXiv:2503.05631v2  [cs.LG]  10 Mar 2025
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! Now I have the first author information. Let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Aaditya K. Singh\" \"University College London\" \"Gatsby Computational Neuroscience Unit\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Aaditya K Singh
Link: https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en
Snippet: Aaditya K Singh. PhD Student, Gatsby Computational Neuroscience Unit, University College London. Verified email at ucl.ac.uk. Machine Learning.
Sitelinks: No sitelinks

Title: Aaditya K Singh
Link: https://scholar.google.com.hk/citations?user=9OPKqmMAAAAJ&hl=th
Snippet: Aaditya K Singh. PhD Student, Gatsby Computational Neuroscience Unit, University College London. ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà ucl.ac.uk. Machine Learning.
Sitelinks: No sitelinks

Title: Aaditya K Singh
Link: https://openreview.net/profile?id=~Aaditya_K_Singh1
Snippet: Aaditya K Singh. Pronouns: he/him. PhD student, Gatsby Computational Neuroscience Unit, University College London, University of London. Joined February 2020 ...
Sitelinks: No sitelinks

Title: Jin Hwa Lee
Link: https://scholar.google.com/citations?user=QHV2vNgAAAAJ&hl=en
Snippet: Aaditya K SinghPhD Student, Gatsby Computational Neuroscience Unit, University College LondonVerified email at ucl.ac.uk. Follow.
Sitelinks: No sitelinks

Title: ‚Ä™Jin Hwa Lee‚Ä¨ - ‚Ä™Google Scholar‚Ä¨
Link: https://scholar.google.co.kr/citations?user=QHV2vNgAAAAJ&hl=ja
Snippet: Aaditya K SinghPhD Student, Gatsby Computational Neuroscience Unit, University College LondonÁ¢∫Ë™ç„Åó„Åü„É°„Éº„É´ „Ç¢„Éâ„É¨„Çπ: ucl.ac.uk. „Éï„Ç©„É≠„Éº.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Excellent! I found the Google Scholar profile. Now let me update the Excel sheet with this first paper's information and then continue with the other papers.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Aaditya K. Singh",
	"Gatsby Computational Neuroscience Unit,
	 University College London",
	"https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en"]],
	 "start_cell": "B2"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the second paper: "Model Immunization from a Condition Number Perspective"
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Model Immunization from a Condition Number Perspective\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: Model Immunization from a Condition Number Perspective
Link: https://arxiv.org/abs/2505.23760
Snippet: Abstract page for arXiv paper 2505.23760: Model Immunization from a Condition Number Perspective.
Sitelinks: No sitelinks

Title: Model Immunization from a Condition Number Perspective
Link: https://arxiv.org/html/2505.23760v1
Snippet: arXiv:2505.23760v1 [cs.LG] 29 May 2025. Model Immunization from a Condition Number Perspective. Report issue for preceding element. Amber Yijia Zheng Cedar ...
Sitelinks: No sitelinks

Title: Model Immunization from a Condition Number Perspective
Link: https://arxiv.org/pdf/2505.23760
Snippet: Model Immunization from a Condition Number Perspective. Norm ratio ... arXiv preprint arXiv:1911.03030, 2019. He, K., Zhang, X., Ren, S ...
Sitelinks: No sitelinks

Title: Model Immunization from a Condition Number Perspective
Link: https://icml.cc/virtual/2025/poster/43720
Snippet: Model Immunization from a Condition Number Perspective. Amber Yijia Zheng ... arXiv preprint arXiv:1308.3432, 2013. Bengio, Y., Goodfellow, I., and ...
Sitelinks: No sitelinks

Title: Model Immunization from a Condition Number Perspective
Link: https://www.amberyzheng.com/immu_cond_num/
Snippet: Model Immunization from a Condition Number Perspective ... Summary: We provide a theoretical framework for model immunization, showing how the condition number of ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Great! Let me get the PDF to extract the author information.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2505.23760",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 25
Extracted page range: 1-1

=== Page 1 ===
arXiv:2505.23760v1  [cs.LG]  29 May 2025Model Immunization from a Condition Number Perspective
Amber Yijia Zheng* 1Cedar Site Bai* 1Brian Bullins1Raymond A. Yeh1
Abstract
Model immunization aims to pre-train models
that are difficult to fine-tune on harmful tasks
while retaining their utility on other non-harmful
tasks. Though prior work has shown empirical ev-
idence for immunizing text-to-image models, the
key understanding of when immunization is pos-
sible and a precise definition of an immunized
model remain unclear. In this work, we pro-
pose a framework, based on the condition num-
ber of a Hessian matrix, to analyze model im-
munization for linear models. Building on this
framework, we design an algorithm with regular-
ization terms to control the resulting condition
numbers after pre-training. Empirical results on
linear models and non-linear deep-nets demon-
strate the effectiveness of the proposed algorithm
on model immunization. The code is available
athttps://github.com/amberyzheng/
model-immunization-cond-num .
1. Introduction
Model immunization, recently proposed by Zheng & Yeh
(2024), studies how to pre-train a model that is more difficult
to fine-tune on harmful content, but not others. The aim
is to mitigate the risk of misuse (Brundage et al., 2018;
Marchal et al., 2024) associated with open-sourced models
by immunizing them before they are released to the public.
Zheng & Yeh (2024) focus on immunizing text-to-image
models, where they formulate immunization as a bi-level op-
timization. Empirically, they show that pre-trained diffusion
models that undergo immunization are more difficult to fine-
tune on a given harmful concept dataset. To quantify this
difficulty, they compare the generation quality of models
with and without immunization after a fixed number of fine-
tuning iterations. While the empirical results are promising,
*Equal contribution1Department of Computer Science,
Purdue University. Correspondence to: Raymond A. Yeh
<rayyeh@purdue.edu >.
Proceedings of the 42ndInternational Conference on Machine
Learning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).a definition of an immunized model and the circumstances
that make immunization possible remain unclear.
To tackle this issue, we propose a framework to study
model immunization using the condition number (Gloub
& Van Loan, 1996). The effectiveness of immunization can
be characterized by the condition number of the Hessian
matrix. When using gradient-based methods during fine-
tuning, a condition number closer to one indicates faster
convergence (Boyd & Vandenberghe, 2004), i.e., easier to
fine-tune. With this perspective, we observe that the ex-
istence of an effective immunization for linear models is
related to the angle between the singular vectors of the
harmful fine-tuning dataset‚Äôs covariance matrix and the pre-
training dataset‚Äôs covariance matrix.
From this condition number perspective, we propose an
immunization algorithm to find such a model. In detail,
we propose two additional terms to regularize the condi-
tion number during pre-training. Each of the introduced
regularization terms can be shown to ensure a monotonic
increase/decrease of the condition number under gradient
updates.
Beyond the theoretical results, we empirically validate the
proposed algorithm on linear models for regression and
image classification tasks. Lastly, we conduct experiments
using the proposed algorithm on non-linear models, i.e.,
deep-nets. Despite the gap in theory, we observe that the
proposed approach remains effective at model immunization
across ResNet (He et al., 2016) and ViT (Dosovitskiy, 2021).
Our contributions are summarized as follows:
‚Ä¢We introduce a framework based on the condition number
to study the task of model immunization. This framework
leads to a concrete definition of an immunized model
along with a novel experiment setup and evaluation met-
ric to compare the quality of different immunization tech-
niques.
‚Ä¢We propose regularizers to maximize/minimize the con-
dition number, with a guaranteed monotonic increase/de-
crease when updated with the gradient-based method.
‚Ä¢Together with the task objective and regularizers, we
demonstrate that the proposed algorithm effectively im-
munizes linear models and deep-nets on regression/image
classification tasks.
1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Amber Yijia Zheng\" \"Purdue University\" \"Department of Computer Science\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Purdue CS graphics and vision faculty presented 14 papers at ...
Link: https://www.cs.purdue.edu/news/articles/2024/purdue-cs-graphics-and-vision-faculty-presented-13-papers-at-cvpr-2024.html
Snippet: Amber Yijia Zheng, Raymond A. Yeh, Towards Safer AI Content Creation by ... About the Department of Computer Science at Purdue University.
Sitelinks: No sitelinks

Title: Brian Bullins
Link: https://bbullins.github.io/
Snippet: I am an assistant professor in the Department of Computer Science at Purdue University. My research interests lie at the intersection of optimization and ...
Sitelinks: No sitelinks

Title: Raymond A. Yeh: Welcome
Link: https://raymond-yeh.com/
Snippet: I am an Assistant Professor in the Department of Computer Science at Purdue University. ... Amber Yijia Zheng. Chiao-An Yang. Hairong Yin. Haomeng Zhang ...
Sitelinks: No sitelinks

Title: Cedar Site BAI | PhD Student | Doctor of Philosophy
Link: https://www.researchgate.net/profile/Cedar-Site-Bai
Snippet: Amber Yijia Zheng ¬∑ Cedar Site Bai; Brian Bullins ¬∑ Raymond A. Yeh. Model immunization aims to pre ...
Sitelinks: No sitelinks

Title: IMMA: Immunizing Text-to-Image Models Against Malicious ...
Link: https://dl.acm.org/doi/10.1007/978-3-031-72933-1_26
Snippet: by AY Zheng ¬∑ 2024 ¬∑ Cited by 12 ‚Äî Amber Yijia Zheng. Amber Yijia Zheng. Department of Computer Science, Purdue University, West Lafayette, USA ... Google Scholar. [2]. Bengio Y ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me try a more direct search for Amber Yijia Zheng's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Amber Yijia Zheng\" site:scholar.google.com",
	 "num_results": 5
}

```

```json output_result
Title: Amber Yijia Zheng - Google Â≠¶ÊúØÊêúÁ¥¢
Link: https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN
Snippet: Amber Yijia Zheng. ÂÖ∂‰ªñÂßìÂêç Yijia Zheng. PhD Student, Purdue University. Âú®purdue.edu ÁöÑÁîµÂ≠êÈÇÆ‰ª∂ÁªèËøáÈ™åËØÅ- È¶ñÈ°µ ¬∑ Generative ModelsDeep Learning.
Sitelinks: No sitelinks

Title: Cedar Site Bai - Google Scholar
Link: https://scholar.google.com/citations?user=Vnc1dYAAAAAJ&hl=en
Snippet: Amber Yijia ZhengPhD Student, Purdue UniversityVerified email at purdue.edu. Raymond A. YehAssistant Professor of Computer ...
Sitelinks: No sitelinks

Title: Cedar Site Bai - Google Â≠¶ÊúØÊêúÁ¥¢
Link: https://scholar.google.com/citations?user=Vnc1dYAAAAAJ&hl=zh-CN
Snippet: Amber Yijia ZhengPhD Student, Purdue UniversityÂú®purdue.edu ÁöÑÁîµÂ≠êÈÇÆ‰ª∂ÁªèËøáÈ™åËØÅ. Raymond A. YehAssistant Professor of ...
Sitelinks: No sitelinks

Title: Weichen Fan - Google Â≠¶ÊúØÊêúÁ¥¢
Link: https://scholar.google.com/citations?user=ORlELG8AAAAJ&hl=zh-CN
Snippet: Amber Yijia ZhengPhD Student, Purdue UniversityÂú®purdue.edu ÁöÑÁîµÂ≠êÈÇÆ‰ª∂ÁªèËøáÈ™åËØÅ. Raymond A. YehAssistant Professor of ...
Sitelinks: No sitelinks

Title: Weichen Fan
Link: https://scholar.google.com/citations?user=ORlELG8AAAAJ
Snippet: Amber Yijia ZhengPhD Student, Purdue UniversityVerified email at purdue.edu. Raymond A. YehAssistant Professor of Computer ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Great! I found the Google Scholar profile. Let me update the Excel sheet with this information.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Amber Yijia Zheng",
	"Department of Computer Science,
	 Purdue University",
	"https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN"]],
	 "start_cell": "B3"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the third paper: "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows"
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Flowing Datasets with Wasserstein over Wasserstein Gradient Flows\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: [2506.07534] Flowing Datasets with Wasserstein over ...
Link: https://arxiv.org/abs/2506.07534
Snippet: by C Bonet ¬∑ 2025 ¬∑ Cited by 6 ‚Äî Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. Authors:Cl√©ment Bonet, Christophe Vauthier, Anna Korba.
Sitelinks: No sitelinks

Title: Flowing Datasets with Wasserstein over Wasserstein Gradient ...
Link: https://arxiv.org/html/2506.07534v1
Snippet: arXiv:2506.07534v1 [cs.LG] 09 Jun 2025. Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. Report issue for preceding element. Cl√©ment Bonet ...
Sitelinks: No sitelinks

Title: Flowing Datasets with Wasserstein over Wasserstein Gradient ...
Link: https://clbonet.github.io/pdf/Slides/Slides___UBC___18_07_2025.pdf
Snippet: by C Bonet ¬∑ Cited by 4 ‚Äî Hierarchical Integral Probability Metrics: A distance on random probability measures with low sample complexity. arXiv preprint arXiv:2402.00423 ...
Sitelinks: No sitelinks

Title: ICML Poster Flowing Datasets with Wasserstein over ...
Link: https://icml.cc/virtual/2025/poster/45752
Snippet: Flowing Datasets with Wasserstein over Wasserstein Gradient Flows ¬∑ 1. Introduction ¬∑ 2. Background ¬∑ 3. Wasserstein over Wasserstein Space ¬∑ 4. WoW Gradient Flows.
Sitelinks: No sitelinks

Title: (PDF) Flowing Datasets with Wasserstein over ...
Link: https://www.researchgate.net/publication/392529942_Flowing_Datasets_with_Wasserstein_over_Wasserstein_Gradient_Flows
Snippet: Flowing Datasets with Wasserstein over Wasserstein Gradient Flows. June 2025. DOI:10.48550/arXiv.2506.07534. License; CC BY 4.0. Authors: Cl√©ment Bonet at ENSAE.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me get the PDF to extract the detailed author information.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2506.07534",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 57
Extracted page range: 1-1

=== Page 1 ===
arXiv:2506.07534v1  [cs.LG]  9 Jun 2025Flowing Datasets with Wasserstein over Wasserstein Gradient Flows
Cl¬¥ement Bonet* 1Christophe Vauthier* 2Anna Korba1
Abstract
Many applications in machine learning involve
data represented as probability distributions. The
emergence of such data requires radically novel
techniques to design tractable gradient flows on
probability distributions over this type of (infinite-
dimensional) objects. For instance, being able to
flow labeled datasets is a core task for applica-
tions ranging from domain adaptation to transfer
learning or dataset distillation. In this setting, we
propose to represent each class by the associated
conditional distribution of features, and to model
the dataset as a mixture distribution supported on
these classes (which are themselves probability
distributions), meaning that labeled datasets can
be seen as probability distributions over proba-
bility distributions. We endow this space with a
metric structure from optimal transport, namely
the Wasserstein over Wasserstein (WoW) distance,
derive a differential structure on this space, and
define WoW gradient flows. The latter enables to
design dynamics over this space that decrease a
given objective functional. We apply our frame-
work to transfer learning and dataset distillation
tasks, leveraging our gradient flow construction
as well as novel tractable functionals that take
the form of Maximum Mean Discrepancies with
Sliced-Wasserstein based kernels between proba-
bility distributions.
1. Introduction
Probability measures provide a powerful way to represent
many data types. For instance, they allow to naturally repre-
sent documents (Kusner et al., 2015), genes (Bellazzi et al.,
2021), point clouds (Qi et al., 2017; Geuter et al., 2025),
images (Sodini et al., 2025), or single-cell data (Persad et al.,
*Equal contribution1ENSAE, CREST, IP Paris2Universit ¬¥e
Paris-Saclay, Laboratoire de Math ¬¥ematique d‚ÄôOrsay. Correspon-
dence to: Cl ¬¥ement Bonet <clement.bonet@ensae.fr >, Chrisophe
Vauthier <christophe.vauthier@universite-paris-saclay.fr >.
Proceedings of the 42ndInternational Conference on Machine
Learning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).2023; Haviv et al., 2024b). Remarkably, it has been shown
that one can embed any finite dataset with little or no distor-
tion (Andoni et al., 2018; Kratsios et al., 2023) in the Wasser-
stein space, i.e., the space of probability distributions ( e.g.,
over a Euclidean space) equipped with the Wasserstein-2 dis-
tance from Optimal Transport (OT). This has motivated the
use of this space to embed many types of data ranging from
words (Vilnis & McCallum, 2015) to knowledge graphs
(He et al., 2015; Wang et al., 2022), graphs (Bojchevski &
G¬®unnemann, 2018; Petric Maretic et al., 2019), or neuro-
science data (Bonet et al., 2023). Therefore, it is essential to
develop tools to work on the space of probability measures
over probability measures, also known as random measures.
In particular, they provide a natural way to represent labeled
datasets as mixtures (Alvarez-Melis & Fusi, 2020).
A natural distance on this space is the Wasserstein over
Wasserstein distance (WoW) (Nguyen, 2016; Catalano
& Lavenant, 2024), also known as the Hierarchical OT
distance, which lifts the Wasserstein distance between prob-
ability distributions as a ground cost, to define a Wasserstein
distance between random measures. The latter has been used
for generative modeling applications (Dukler et al., 2019),
domain adaptation tasks (El Hamri et al., 2022), comparing
documents (Yurochkin et al., 2019) or multilevel clustering
(Ho et al., 2017). It has also been used to compare Gaussian
mixtures (Chen et al., 2018; Delon & Desolneux, 2020;
Wilson et al., 2024) or generic mixtures (Dusson et al., 2023;
Chen & Zhang, 2024). However, its poor sample complexity
has motivated the development of alternative distance mea-
sures, such as those based on Integral Probability Metrics
(Catalano & Lavenant, 2024). Nonetheless, this space pos-
sesses a rich Riemannian structure, enabling the definition
of concepts like geodesics. This has been leveraged recently
by Haviv et al. (2024a) to perform generative modeling over
the space of probability distributions with Flow Matchings.
While this space naturally supports a range of machine learn-
ing tasks, optimization methods tailored to it have received
limited attention. Yet, this is important for multiple ap-
plications, including variational inference with a Gaussian
mixture family (Lambert et al., 2022; Huix et al., 2024),
computing barycenters (Delon & Desolneux, 2020), or flow-
ing datasets (Alvarez-Melis & Fusi, 2021), e.g., for domain
adaptation, transfer learning (Alvarez-Melis & Fusi, 2021;
Hua et al., 2023) or dataset distillation (Wang et al., 2018).
1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Cl√©ment Bonet\" \"ENSAE\" \"CREST\" \"IP Paris\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Pierre-Cyril Aubin-Frankowski
Link: https://scholar.google.com/citations?user=60oOCO0AAAAJ&hl=fr
Snippet: Th√©o UsciddaCREST - ENSAEAdresse e-mail valid√©e de ensae.fr. Cl√©ment BonetEcole Polytechnique, CMAPAdresse e-mail valid√©e de polytechnique.edu.
Sitelinks: No sitelinks

Title: Anna Korba ‚Äì
Link: https://akorba.github.io/resources/CV_EN.pdf
Snippet: Statistics department, ENSAE, CREST, IP Paris. Sep. 2020‚ÄìPresent. Assistant ... { Postdocs: 2023-?: Omar Chehab, Adrien Vacher, Cl√©ment Bonet. { Interns ...
Sitelinks: No sitelinks

Title: Pierre-Cyril Aubin-Frankowski - Google ÌïôÏà† Í≤ÄÏÉâ
Link: https://scholar.google.com.hk/citations?user=60oOCO0AAAAJ&hl=ko
Snippet: Researcher & Associate professor, ENPC, IP Paris ... Cl√©ment BonetENSAE - CRESTensae.frÏùò Ïù¥Î©îÏùº ÌôïÏù∏Îê® ... Researcher & Associate professor, ENPC, IP Paris.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me try a more direct search for Cl√©ment Bonet's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Cl√©ment Bonet\" site:scholar.google.com",
	 "num_results": 5
}

```

```json output_result
Title: Cl√©ment Bonet
Link: https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en
Snippet: Cl√©ment Bonet. Ecole Polytechnique, CMAP. Verified email at polytechnique.edu - Homepage ¬∑ Optimal TransportGradient FlowsMachine Learning.
Sitelinks: No sitelinks

Title: Pierre-Cyril Aubin-Frankowski
Link: https://scholar.google.com/citations?user=60oOCO0AAAAJ&hl=fr
Snippet: Cl√©ment BonetEcole Polytechnique, CMAPAdresse e-mail valid√©e de polytechnique.edu. Nicolas PetitMINES Paris, PSL University ...
Sitelinks: No sitelinks

Title: Titouan Vayer
Link: https://scholar.google.com/citations?user=PJEv3JgAAAAJ&hl=fr
Snippet: Cl√©ment BonetEcole Polytechnique, CMAPAdresse e-mail valid√©e de polytechnique.edu. Paulo Gon√ßalvesSenior researcher Inria ...
Sitelinks: No sitelinks

Title: Lucas Drumetz
Link: https://scholar.google.com/citations?user=abRvIGAAAAAJ&hl=en
Snippet: Cl√©ment BonetEcole Polytechnique, CMAPVerified email at polytechnique.edu. Ananda Pascual (ORCID: 0000-0001-9476-9272) Ananda Pascual (ORCID ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! I notice there's a discrepancy - the paper shows ENSAE, CREST, IP Paris, but the Google Scholar shows Ecole Polytechnique, CMAP. Let me use the affiliation from the paper as it's the most current. Let me update the Excel sheet.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Cl√©ment Bonet",
	"ENSAE,
	 CREST,
	 IP Paris",
	"https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en"]],
	 "start_cell": "B4"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the fourth paper: "Learning with Expected Signatures: Theory and Applications"
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Learning with Expected Signatures: Theory and Applications\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: Learning with Expected Signatures: Theory and Applications
Link: https://arxiv.org/abs/2505.20465
Snippet: by L Lucchese ¬∑ 2025 ‚Äî Abstract page for arXiv paper 2505.20465: Learning with Expected Signatures: Theory and Applications.
Sitelinks: No sitelinks

Title: Learning with Expected Signatures: Theory and Applications
Link: https://arxiv.org/pdf/2505.20465
Snippet: by L Lucchese ¬∑ 2025 ‚Äî Learning with Expected Signatures: Theory and Applications deduce this limit is the same as its P-limit, i.e. Sk(X)[0,T ]. To show the ...
Sitelinks: No sitelinks

Title: (PDF) Learning with Expected Signatures: Theory and Applications
Link: https://www.researchgate.net/publication/392134299_Learning_with_Expected_Signatures_Theory_and_Applications
Snippet: Content may be subject to copyright. arXiv:2505.20465v1 [stat.ML] 26 May 2025. Learning with Expected Signatures: Theory and Applications. Lorenzo Lucchese 1 ...
Sitelinks: No sitelinks

Title: Learning with Expected Signatures: Theory and Applications ...
Link: https://ribbitribbit.co/paper/arxiv.2505.20465-Learning-with-Expected-Signatures-Theory-and-Applications
Snippet: Learning with Expected Signatures: Theory and Applications. By Lorenzo Lucchese, Almut E. D. Veraart | Learn about this paper‚Äîor listen like a podcast‚Äîon ...
Sitelinks: No sitelinks

Title: Learning with Expected Signatures: Theory and Applications
Link: https://chatpaper.com/paper/164958
Snippet: 1. Learning with Expected Signatures: Theory and Applications ¬∑ ChatDOC. ICML 202518 Jun 2025. Lorenzo Lucchese, Mikko S. Pakkanen, Almut E. D. Veraart.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me get the PDF to extract the author information.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2505.20465",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 61
Extracted page range: 1-1

=== Page 1 ===
arXiv:2505.20465v1  [stat.ML]  26 May 2025Learning with Expected Signatures: Theory and Applications
Lorenzo Lucchese1Mikko S. Pakkanen1Almut E. D. Veraart1
Abstract
The expected signature maps a collection of data
streams to a lower dimensional representation,
with a remarkable property: the resulting fea-
ture tensor can fully characterize the data gener-
ating distribution. This ‚Äúmodel-free‚Äù embedding
has been successfully leveraged to build multi-
ple domain-agnostic machine learning (ML) al-
gorithms for time series and sequential data. The
convergence results proved in this paper bridge
the gap between the expected signature‚Äôs em-
pirical discrete-time estimator and its theoreti-
cal continuous-time value, allowing for a more
complete probabilistic interpretation of expected
signature-based ML methods. Moreover, when
the data generating process is a martingale, we
suggest a simple modification of the expected sig-
nature estimator with significantly lower mean
squared error and empirically demonstrate how it
can be effectively applied to improve predictive
performance.
1. Introduction
The signature transform of a stream of data is an infinite but
countable sequence of its ‚Äúiterated integrals‚Äù summarizing
the input in a top-down fashion, meaning the informational
content of its terms decays factorially. Originally introduced
by Chen (1954) and serving as a fundamental object of
rough path analysis (Lyons et al., 2007), the signature
S={S(X)[0,t]‚ààT((Rd)), t‚àà[0, T]},
of a path X={Xt, t‚àà[0, T]} ‚ààC([0, T],Rd)is a lift
(in the sense that it embeds X) to the space of continuous
functions over the tensor algebra T((Rd))possessing some
nice algebraic and geometric properties. When the path is of
bounded variation, the signature is defined as the sequence
1Department of Mathematics, Imperial College London, Lon-
don, United Kingdom. Correspondence to: Lorenzo Lucchese
<lorenzo.lucchese17@imperial.ac.uk, llucchese6@gmail.com >.
Proceedings of the 42ndInternational Conference on Machine
Learning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).of iterated integrals of X, i.e. for t‚àà[0, T], k‚â•0
Sk(X)[0,t]=Z
¬∑¬∑¬∑Z
0‚â§s1‚â§...‚â§sk‚â§tdXs1‚äó ¬∑¬∑¬∑ ‚äó dXsk.(1)
In many practical applications the path Xis taken to be
the piecewise linear interpolation of a discrete-time stream
of data, which is of bounded variation by construction.
Signature-based machine learning (ML) approaches (Lyons
& McLeod, 2024) thus often restrict the theoretical frame-
work to paths in BV([0, T],Rd). In this setting, two funda-
mental properties of the signature that make it a desirable
non-parametric feature extraction method for sequential
data are the characterization result of Hambly & Lyons
(2005) and the universality approximation theorem of Levin
et al. (2016). Moreover, when the path Xis understood
as a (realization of a) random process with distribution P
over BV([0, T],Rd), the shuffle property of the signature
implies that all moments of the random variable S(X)[0,T]
are determined by its expectation
œï(T) :=E[S(X)[0,T]]‚ààT((Rd)).
A natural question, known as the Hamburger moment prob-
lem (Fawcett, 2003), is thus whether the expectation of
the signature characterizes its law (and thus the law of the
path). When imposing a probability distribution PonX
the assumption of bounded variation paths becomes quite
restrictive: Brownian motion, the basic building block of
many stochastic models, has paths of infinite variation al-
most surely. Even if we observe a discrete-time stream of
data, we often still would like to define the process Xas
a latent stochastic process of which we observe the linear
interpolation over some partition œÄof[0, T], hereafter de-
noted by XœÄ. We hence wish to make sense of the signature
of a stochastic process Xwith paths of unbounded variation.
For a given path X‚ààC([0, T],Rd)of finite p-variation,
once we ‚Äúlift‚Äù the process to a p-rough path (Lyons et al.,
2007, Definition 3.11) then the signature SofXis uniquely
defined1. Without delving into the details of rough path
theory, for our purposes it suffices to interpret the choice of
lift as fixing a notion of integration with respect to X: the
higher order signatures terms are then understood as iterated
integrals of the path Xdefined in this sense.
1This is the first fundamental theorem in the theory of rough
paths (Lyons et al., 2007, Theorem 3.7).
1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Lorenzo Lucchese\" \"Imperial College London\" \"Department of Mathematics\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Lorenzo Lucchese
Link: https://openreview.net/profile?id=~Lorenzo_Lucchese1
Snippet: Department of Mathematics, Imperial College London (imperial.ac.uk). 2021 ... Learning with Expected Signatures: Theory and Applications ¬∑ Lorenzo Lucchese, Mikko ...
Sitelinks: No sitelinks

Title: Lorenzo Lucchese's Instagram, Twitter & Facebook on ...
Link: https://www.idcrawl.com/lorenzo-lucchese
Snippet: Lorenzo Lucchese ... I am a PhD graduate from the Mathematics of Random Systems CDT, a joint programme between the Department of Mathematics at Imperial ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me try a more direct search for Lorenzo Lucchese's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Lorenzo Lucchese\" site:scholar.google.com",
	 "num_results": 5
}

```

```json output_result
Title: Lorenzo Lucchese
Link: https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it
Snippet: Lorenzo Lucchese. PhD student, Imperial College London. Email verificata su imperial.ac.uk - Home page ¬∑ Mathematics of Random Systems. Articoli ...
Sitelinks: No sitelinks

Title: Mikko S. Pakkanen
Link: https://scholar.google.com/citations?user=LGkKGsAAAAAJ&hl=en
Snippet: Lorenzo LucchesePhD student, Imperial College LondonVerified email at imperial.ac.uk. Jose Manuel CorcueraProfesor de ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! Let me update the Excel sheet with this information.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Lorenzo Lucchese",
	"Department of Mathematics,
	 Imperial College London",
	"https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it"]],
	 "start_cell": "B5"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the fifth paper: "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML"
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Link: https://arxiv.org/abs/2410.02958
Snippet: by P Trirat ¬∑ 2024 ¬∑ Cited by 47 ‚Äî AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Authors:Patara Trirat, Wonyong Jeong, Sung Ju Hwang.
Sitelinks: No sitelinks

Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Link: https://arxiv.org/pdf/2410.02958
Snippet: by P Trirat ¬∑ 2024 ¬∑ Cited by 47 ‚Äî AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Table 2. Summary of downstream tasks and datasets. Data Modality. Downstream Task. Dataset ...
Sitelinks: No sitelinks

Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Link: https://icml.cc/virtual/2025/poster/44029
Snippet: AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Patara ... arXiv preprint arXiv:2303.08774, 2023. 3, 7. Baek, J., Jauhar, S. K. ...
Sitelinks: No sitelinks

Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Link: https://deepauto-ai.github.io/automl-agent/
Snippet: AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. Patara Trirat1, Wonyong Jeong1, Sung Ju Hwang1,2. 1DeepAuto.ai, 2KAIST Seoul, South Korea
Sitelinks: No sitelinks

Title: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Link: https://www.semanticscholar.org/paper/AutoML-Agent%3A-A-Multi-Agent-LLM-Framework-for-Trirat-Jeong/efde8940a0b924e93d35184c4a1e8f9670b94fe7
Snippet: DOI:10.48550/arXiv.2410.02958; Corpus ID: 273162376. AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML ... Published in arXiv ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me get the PDF to extract the author information.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2410.02958",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 48
Extracted page range: 1-1

=== Page 1 ===
arXiv:2410.02958v2  [cs.LG]  6 Jun 2025AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML
Patara Trirat1Wonyong Jeong1Sung Ju Hwang1 2
Abstract
Automated machine learning (AutoML) acceler-
ates AI development by automating tasks in the
development pipeline, such as optimal model
search and hyperparameter tuning. Existing Au-
toML systems often require technical expertise
to set up complex tools, which is in general time-
consuming and requires a large amount of human
effort. Therefore, recent works have started ex-
ploiting large language models (LLM) to lessen
such burden and increase the usability of AutoML
frameworks via a natural language interface, al-
lowing non-expert users to build their data-driven
solutions. These methods, however, are usually
designed only for a particular process in the AI
development pipeline and do not efficiently use
the inherent capacity of the LLMs. This paper pro-
poses AutoML-Agent , a novel multi-agent frame-
work tailored for full-pipeline AutoML, i.e., from
data retrieval to model deployment. AutoML-
Agent takes user‚Äôs task descriptions, facilitates
collaboration between specialized LLM agents,
and delivers deployment-ready models. Unlike ex-
isting work, instead of devising a single plan, we
introduce a retrieval-augmented planning strategy
to enhance exploration to search for more optimal
plans. We also decompose each plan into sub-
tasks (e.g., data preprocessing and neural network
design) each of which is solved by a specialized
agent we build via prompting executing in parallel,
making the search process more efficient. More-
over, we propose a multi-stage verification to ver-
ify executed results and guide the code generation
LLM in implementing successful solutions. Ex-
tensive experiments on seven downstream tasks
using fourteen datasets show that AutoML-Agent
achieves a higher success rate in automating the
full AutoML process, yielding systems with good
performance throughout the diverse domains.
1DeepAuto.ai2KAIST, Seoul, South Korea. Correspondence
to: Sung Ju Hwang <sjhwang@deepauto.ai >.
Proceedings of the 42ndInternational Conference on Machine
Learning , Vancouver, Canada. PMLR 267, 2025. Copyright 2025
by the author(s).1. Introduction
Automated machine learning (AutoML) has significantly
reduced the need for technical expertise and human labors
in developing effective data-driven solutions by automating
each process in the AI development pipeline (Yao et al.,
2018; Ren et al., 2020; He et al., 2021), such as feature
engineering, model selection, and hyperparameter optimiza-
tion (HPO). However, current AutoML systems (Gijsbers
et al., 2024) often necessitate programming expertise to
configure complex tools and resources, potentially creating
barriers for a larger pool of users with limited skills and
knowledge, such as domain experts (Sun et al. (2023); ¬ßA).
To make AutoML frameworks more accessible to non-expert
users, many recent studies (Trirat et al., 2021; Viswanathan
et al., 2023; Li et al., 2023; Hollmann et al., 2023b; Liu
et al., 2025; Zhang et al., 2023; Shen et al., 2023; Zhang
et al., 2024a; Hong et al., 2024a; Guo et al., 2024a; Yang
et al., 2025; Chi et al., 2024) have suggested to use natural
language interfaces with large language models (LLM) for
machine learning (ML) and data science (DS) tasks. Nev-
ertheless, these previous LLM-based AutoML frameworks
only considered a limited number of tasks due to their re-
stricted designs, either only for a process in the pipeline (e.g.,
feature engineering (Hollmann et al., 2023b; Li et al., 2024;
Malberg et al., 2024), HPO (Liu et al., 2024a; 2025; Zhang
et al., 2024a), and model selection (Zhang et al., 2023; Shen
et al., 2023)) or for a specific group of downstream tasks
(e.g., natural language processing (Viswanathan et al., 2023)
and computer vision (Yang et al., 2025)). In addition, most
methods overlook the inherent capability of LLMs to search
for promising models by performing actual training of the
candidate models during the search process, making it pro-
hibitively costly and slow.
For an AutoML framework to be truly practical, it should
perform end-to-end AutoML, considering both the data
aspects (retrieval, preprocessing, and feature engineering)
andmodel aspects (selection, HPO, and deployment). This
is because a process in one aspect can affect subsequent
processes in the other, potentially leading to suboptimal so-
lutions when combining results from different frameworks.
Meanwhile, the AutoML framework should be computation-
ally efficient, using strategies to minimize the computational
overhead during search. However, there are two main chal-
lenges in building such a framework.
1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Patara Trirat\" \"DeepAuto.ai\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Patara Trirat
Link: https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en
Snippet: Patara Trirat. Research Scientist at DeepAuto.ai, KAIST. Verified email at kaist.ac.kr - Homepage ¬∑ Agentic AIData MiningAutomated Machine ...
Sitelinks: No sitelinks

Title: Large language models are zero-shot point-of-interest ...
Link: https://link.springer.com/article/10.1007/s10618-025-01148-w
Snippet: DeepAuto.ai, Seoul, Republic of Korea. Patara Trirat. Authors. Joeun Kim. View author publications. Search author on:PubMed Google Scholar.
Sitelinks: No sitelinks

Title: Youngeun Nam
Link: https://scholar.google.com/citations?user=Cz1zyRsAAAAJ&hl=en
Snippet: Patara TriratResearch Scientist at DeepAuto.ai, KAISTVerified email at kaist.ac.kr. Susik YoonKorea UniversityVerified email at ...
Sitelinks: No sitelinks

Title: (PDF) Paper2Code: Automating Code Generation from ...
Link: https://www.researchgate.net/publication/391120156_Paper2Code_Automating_Code_Generation_from_Scientific_Papers_in_Machine_Learning
Snippet: ... DeepAuto.ai2. {minjuseo, jinheon.baek, seongyun, sungju.hwang}@kaist ... com/articles/s41586-023-06747-5. [42]. Patara Trirat, Wonyong ...
Sitelinks: No sitelinks

Title: ICML 2025 Accepted Paper List
Link: https://papercopilot.com/paper-list/icml-paper-list/icml-2025-paper-list/
Snippet: Patara Trirat; Wonyong Jeong; Sung Ju Hwang;, DeepAuto.ai; Korea Advanced Institute of Science and Technology; ;, United States; South Korea; ;, Poster, 20. 7 ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! Let me update the Excel sheet with this information.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Patara Trirat",
	"DeepAuto.ai",
	"https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en"]],
	 "start_cell": "B6"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Finally, let me search for the sixth paper: "Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction"
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction\" arxiv",
	 "num_results": 5
}

```

```json output_result
Title: Learning Smooth and Expressive Interatomic Potentials for ...
Link: https://arxiv.org/abs/2502.12147
Snippet: by X Fu ¬∑ 2025 ¬∑ Cited by 51 ‚Äî Abstract page for arXiv paper 2502.12147: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction.
Sitelinks: No sitelinks

Title: Learning Smooth and Expressive Interatomic Potentials for ...
Link: https://arxiv.org/html/2502.12147v1
Snippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction ... arXiv preprint arXiv:2501.09009, 2025. Artrith ...
Sitelinks: No sitelinks

Title: Learning Smooth and Expressive Interatomic Potentials for ...
Link: https://www.researchgate.net/publication/389130711_Learning_Smooth_and_Expressive_Interatomic_Potentials_for_Physical_Property_Prediction
Snippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction. February 2025. DOI:10.48550/arXiv.2502.12147. License ...
Sitelinks: No sitelinks

Title: Learning Smooth and Expressive Interatomic Potentials for ...
Link: https://raw.githubusercontent.com/mlresearch/v267/main/assets/fu25h/fu25h.pdf
Snippet: by X Fu ¬∑ Cited by 51 ‚Äî Review of computational approaches to predict. 9. Page 10. Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction the ...
Sitelinks: No sitelinks

Title: Learning Smooth and Expressive Interatomic Potentials for ...
Link: https://x.com/VBFC/status/1891798768636363045
Snippet: Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction. arXiv logo. arxiv.org.
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Let me get the PDF to extract the author information.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="-4 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M25.6686 26.0962C25.1812 26.2401 24.4656 26.2563 23.6984 26.145C22.875 26.0256 22.0351 25.7739 21.2096 25.403C22.6817 25.1888 23.8237 25.2548 24.8005 25.6009C25.0319 25.6829 25.412 25.9021 25.6686 26.0962ZM17.4552 24.7459C17.3953 24.7622 17.3363 24.7776 17.2776 24.7939C16.8815 24.9017 16.4961 25.0069 16.1247 25.1005L15.6239 25.2275C14.6165 25.4824 13.5865 25.7428 12.5692 26.0529C12.9558 25.1206 13.315 24.178 13.6667 23.2564C13.9271 22.5742 14.193 21.8773 14.468 21.1894C14.6075 21.4198 14.7531 21.6503 14.9046 21.8814C15.5948 22.9326 16.4624 23.9045 17.4552 24.7459ZM14.8927 14.2326C14.958 15.383 14.7098 16.4897 14.3457 17.5514C13.8972 16.2386 13.6882 14.7889 14.2489 13.6185C14.3927 13.3185 14.5105 13.1581 14.5869 13.0744C14.7049 13.2566 14.8601 13.6642 14.8927 14.2326ZM9.63347 28.8054C9.38148 29.2562 9.12426 29.6782 8.86063 30.0767C8.22442 31.0355 7.18393 32.0621 6.64941 32.0621C6.59681 32.0621 6.53316 32.0536 6.44015 31.9554C6.38028 31.8926 6.37069 31.8476 6.37359 31.7862C6.39161 31.4337 6.85867 30.8059 7.53527 30.2238C8.14939 29.6957 8.84352 29.2262 9.63347 28.8054ZM27.3706 26.1461C27.2889 24.9719 25.3123 24.2186 25.2928 24.2116C24.5287 23.9407 23.6986 23.8091 22.7552 23.8091C21.7453 23.8091 20.6565 23.9552 19.2582 24.2819C18.014 23.3999 16.9392 22.2957 16.1362 21.0733C15.7816 20.5332 15.4628 19.9941 15.1849 19.4675C15.8633 17.8454 16.4742 16.1013 16.3632 14.1479C16.2737 12.5816 15.5674 11.5295 14.6069 11.5295C13.948 11.5295 13.3807 12.0175 12.9194 12.9813C12.0965 14.6987 12.3128 16.8962 13.562 19.5184C13.1121 20.5751 12.6941 21.6706 12.2895 22.7311C11.7861 24.0498 11.2674 25.4103 10.6828 26.7045C9.04334 27.3532 7.69648 28.1399 6.57402 29.1057C5.8387 29.7373 4.95223 30.7028 4.90163 31.7107C4.87693 32.1854 5.03969 32.6207 5.37044 32.9695C5.72183 33.3398 6.16329 33.5348 6.6487 33.5354C8.25189 33.5354 9.79489 31.3327 10.0876 30.8909C10.6767 30.0029 11.2281 29.0124 11.7684 27.8699C13.1292 27.3781 14.5794 27.011 15.985 26.6562L16.4884 26.5283C16.8668 26.4321 17.2601 26.3257 17.6635 26.2153C18.0904 26.0999 18.5296 25.9802 18.976 25.8665C20.4193 26.7844 21.9714 27.3831 23.4851 27.6028C24.7601 27.7883 25.8924 27.6807 26.6589 27.2811C27.3486 26.9219 27.3866 26.3676 27.3706 26.1461ZM30.4755 36.2428C30.4755 38.3932 28.5802 38.5258 28.1978 38.5301H3.74486C1.60224 38.5301 1.47322 36.6218 1.46913 36.2428L1.46884 3.75642C1.46884 1.6039 3.36763 1.4734 3.74457 1.46908H20.263L20.2718 1.4778V7.92396C20.2718 9.21763 21.0539 11.6669 24.0158 11.6669H30.4203L30.4753 11.7218L30.4755 36.2428ZM28.9572 10.1976H24.0169C21.8749 10.1976 21.7453 8.29969 21.7424 7.92417V2.95307L28.9572 10.1976ZM31.9447 36.2428V11.1157L21.7424 0.871022V0.823357H21.6936L20.8742 0H3.74491C2.44954 0 0 0.785336 0 3.75711V36.2435C0 37.5427 0.782956 40 3.74491 40H28.2001C29.4952 39.9997 31.9447 39.2143 31.9447 36.2428Z" fill="#EB5757"/></svg> `pdf-tools read_pdf_pages`

<Expandable title="Details">
```json arguments
{
	"pdf_file_path": "https://arxiv.org/pdf/2502.12147",
	 "start_page": 1,
	 "end_page": 1
}

```

```json output_result
PDF total pages: 20
Extracted page range: 1-1

=== Page 1 ===
Learning Smooth and Expressive Interatomic
Potentials for Physical Property Prediction
Xiang Fu1,Brandon M. Wood1,Luis Barroso-Luque1,Daniel S. Levine1,Meng Gao1,Misko Dzamba1,
C. Lawrence Zitnick1
1Fundamental AI Research (FAIR) at Meta
Machine learning interatomic potentials (MLIPs) have become increasingly effective at approximating
quantum mechanical calculations at a fraction of the computational cost. However, lower errors
on held out test sets do not always translate to improved results on downstream physical property
prediction tasks. We propose testing MLIPs on their practical ability to conserve energy during
molecular dynamic simulations. If passed, improved correlations are found between test errors and
their performance on physical property prediction tasks. We identify choices which may lead to
models failing this test, and use these observations to improve upon highly-expressive models. The
resulting model, eSEN, provides state-of-the-art results on a range of physical property prediction tasks,
including materials stability prediction, thermal conductivity prediction, and phonon calculations.
Correspondence: Xiang Fu ( xiangfu@meta.com ) and C. Lawrence Zitnick ( zitnick@meta.com )
Code: https://github.com/facebookresearch/fairchem
Checkpoints: https://huggingface.co/facebook/OMAT24
1 Introduction
Density Functional Theory (DFT), which models the
electrons in materials and molecules, serves as the
foundation for many modern drug and materials dis-
covery workflows. Unfortunately, DFT calculations
are notoriously computationally intensive, scaling
cubically with the number of electrons in the sys-
tem: O(n3). Machine learning interatomic potentials
(MLIPs) are promising in approximating and expe-
diting DFT calculations. With increasing data set
sizes and model innovations, MLIPs have shown sub-
stantial improvements in accuracy and generalization
capabilities (Batatia et al., 2023; Merchant et al.,
2023; Yang et al., 2024; Barroso-Luque et al., 2024).
Predicting physical properties in chemistry and ma-
terials science often requires complex workflows in-
volving numerous evaluations of DFT or MLIPs. For
example, in molecular dynamics (MD) simulations,
forces are predicted over thousands to millions of
time steps. However, the MLIP literature has mostly
focused on assessing models based on energy and
force predictions over static DFT test sets rather
than directly assessing their performance in complex
simulations. This approach has limitations, as im-
proved accuracy on test sets does not always lead to
better predictions of physical properties (P√≥ta et al.,
2024; Loew et al., 2024).In this paper, we address two questions: Why does
higher test accuracy sometimes fail to enhance a
model‚Äôs ability to predict physical properties, and
how can we improve MLIPs to excel in this area? We
first outline four critical property prediction tasks
and identify the properties required for an MLIP
to succeed in these tasks. These properties entail
learning a conservative model with continuous and
bounded energy derivatives, indicating a smoothly-
varying and physically meaningful energy landscape.
To test whether these properties hold, we propose
testing the ability of MLIPs to practically conserve
energy in MD simulations. We demonstrate models
that pass this test have a higher correlation between
test errors and property prediction accuracy.
Building on these insights, we present a novel MLIP
called eSEN and training approach that achieves
state-of-the-art (SOTA) performance on complex
property prediction tasks. Specifically, our model
is capable of running energy-conserving MD simula-
tions for out-of-distribution systems (Figure 1 (a)).
For materials stability prediction, eSEN achieves a
leading F1 score of 0.831and a Œ∫SRMEof0.340on the
compliant Matbench-Discovery benchmark (Riebe-
sell et al., 2023; P√≥ta et al., 2024). Previous models
are only able to excel in one of these metrics ( Fig-
ure 1 (b,c)). We also achieve a SOTA F1 score of
0.925andŒ∫SRMEof0.170on the non-compliant cate-
1arXiv:2502.12147v2  [physics.comp-ph]  23 Apr 2025
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me search for the first author's Google Scholar profile.
</div>

<div className="result-box">
<svg height="14" width="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style={{margin: 0, padding: 0, display: 'inline-block'}}><g fill="none" fill-rule="evenodd"><rect fill="#fabc05" height="512" rx="42.667" width="512"/><path d="M58.667 293.333L0 209.125V42.663C0 19.1 19.137 0 42.663 0h426.674C492.9 0 512 19.137 512 42.663l-282.667.004S58.667 305.14 58.667 293.333z" fill="#eb4335"/><path d="M303.3 340.528L199.876 512H42.633C19.087 512 0 492.94 0 469.328V209.125l54.537 74.854c28.457 48.33 81.024 80.762 141.167 80.762 40.548 0 77.822-14.86 106.533-39.29l5.348 5.349c-.918 3.235-2.337 6.5-4.284 9.728z" fill="#34a854"/><g fill-rule="nonzero"><path d="M194.667 85.333c-66.667 0-120 52.148-120 117.334C74.667 267.852 128 320 194.667 320c66.666 0 120-52.148 120-117.333 0-65.186-53.334-117.334-120-117.334z" fill="#4285f5"/><path d="M327.59 300.924l28.788 28.787 13.204-14.159 115.751 115.751-59.363 59.364-115.751-115.751 13.553-12.64-28.85-28.85c-27.526 20.496-61.677 32.712-98.52 32.712C105.605 366.138 32 292.532 32 201.735c0-90.796 73.605-164.402 164.402-164.402s164.402 73.606 164.402 164.402c0 37.142-12.414 71.549-33.213 99.19zM196.403 87.92c-63.231 0-113.817 50.585-113.817 113.816 0 63.232 50.586 113.817 113.817 113.817S310.22 264.967 310.22 201.735c0-63.231-50.585-113.816-113.817-113.816z" fill="#fff"/></g></g></svg> `web_search `

<Expandable title="Details">
```json arguments
{
	"query": "\"Xiang Fu\" \"Meta\" \"Fundamental AI Research\" \"FAIR\" Google Scholar",
	 "num_results": 5
}

```

```json output_result
Title: Xiang Fu
Link: https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en
Snippet: WoodFundamental AI Research at MetaVerified email at meta.com ... Muhammed ShuaibiResearch Engineer, FAIR, MetaVerified email at meta.com.
Sitelinks: No sitelinks

Title: Zachary W. Ulissi
Link: https://zulissi.github.io/
Snippet: At Meta's Fundamental AI Research lab I co-lead the FAIR Chemistry team (along with Larry Zitnick!) where we work on AI/ML broadly applied to ...
Sitelinks: No sitelinks

Title: Daniel S Levine
Link: https://scholar.google.com/citations?user=AcE5Wt4AAAAJ&hl=en
Snippet: WoodFundamental AI Research at MetaVerified email at meta.com. Xiang FuMeta FAIRVerified email at meta.com. C. Lawrence Zitnick ...
Sitelinks: No sitelinks

Title: Ricky T. Q. Chen
Link: https://rtqichen.github.io/
Snippet: I'm a Research Scientist at Meta Fundamental AI Research (FAIR) team in New York. ... Xiang Fu, Guan-Horng Liu, Ricky T. Q. Chen International Conference ...
Sitelinks: No sitelinks

Title: Brian Karrer
Link: https://openreview.net/profile?id=~Brian_Karrer1
Snippet: Meta Fundamental AI Research (FAIR) (meta.com). 2022 ‚Äì Present. Researcher ... Xiang Fu, Guan-Horng Liu, Ricky T. Q. Chen. Published: 05 Mar 2025, Last ...
Sitelinks: No sitelinks

```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! Let me update the Excel sheet with this final entry.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel write_data_to_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1",
	 "data": [["Xiang Fu",
	"Fundamental AI Research (FAIR) at Meta",
	"https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en"]],
	 "start_cell": "B7"
}

```

```json output_result
Data written to Sheet1
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Now let me verify the completed Excel sheet by reading it back.
</div>

<div className="result-box">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" width="14" height="14" style={{margin: 0, padding: 0, display: 'inline-block'}}><path fill="#169154" d="M29,6H15.744C14.781,6,14,6.781,14,7.744v7.259h15V6z"/><path fill="#18482a" d="M14,33.054v7.202C14,41.219,14.781,42,15.743,42H29v-8.946H14z"/><path fill="#0c8045" d="M14 15.003H29V24.005000000000003H14z"/><path fill="#17472a" d="M14 24.005H29V33.055H14z"/><g><path fill="#29c27f" d="M42.256,6H29v9.003h15V7.744C44,6.781,43.219,6,42.256,6z"/><path fill="#27663f" d="M29,33.054V42h13.257C43.219,42,44,41.219,44,40.257v-7.202H29z"/><path fill="#19ac65" d="M29 15.003H44V24.005000000000003H29z"/><path fill="#129652" d="M29 24.005H44V33.055H29z"/></g><path fill="#0c7238" d="M22.319,34H5.681C4.753,34,4,33.247,4,32.319V15.681C4,14.753,4.753,14,5.681,14h16.638 C23.247,14,24,14.753,24,15.681v16.638C24,33.247,23.247,34,22.319,34z"/><path fill="#fff" d="M9.807 19L12.193 19 14.129 22.754 16.175 19 18.404 19 15.333 24 18.474 29 16.123 29 14.013 25.07 11.912 29 9.526 29 12.719 23.982z"/></svg> `excel read_data_from_excel`

<Expandable title="Details">
```json arguments
{
	"filepath": "/workspace/dumps/workspace/paper_initial.xlsx",
	 "sheet_name": "Sheet1"
}

```

```json output_result
{
  "range": "A1:D7",
  "sheet_name": "Sheet1",
  "cells": [
    {
      "address": "A1",
      "value": "Title",
      "row": 1,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B1",
      "value": "First Author",
      "row": 1,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C1",
      "value": "Affiliation",
      "row": 1,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D1",
      "value": "Google Scholar Profile",
      "row": 1,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A2",
      "value": "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning",
      "row": 2,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B2",
      "value": "Aaditya K. Singh",
      "row": 2,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C2",
      "value": "Gatsby Computational Neuroscience Unit, University College London",
      "row": 2,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D2",
      "value": "https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en",
      "row": 2,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A3",
      "value": "Model Immunization from a Condition Number Perspective",
      "row": 3,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B3",
      "value": "Amber Yijia Zheng",
      "row": 3,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C3",
      "value": "Department of Computer Science, Purdue University",
      "row": 3,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D3",
      "value": "https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN",
      "row": 3,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A4",
      "value": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows",
      "row": 4,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B4",
      "value": "Cl\u00e9ment Bonet",
      "row": 4,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C4",
      "value": "ENSAE, CREST, IP Paris",
      "row": 4,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D4",
      "value": "https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en",
      "row": 4,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A5",
      "value": "Learning with Expected Signatures: Theory and Applications",
      "row": 5,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B5",
      "value": "Lorenzo Lucchese",
      "row": 5,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C5",
      "value": "Department of Mathematics, Imperial College London",
      "row": 5,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D5",
      "value": "https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it",
      "row": 5,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A6",
      "value": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
      "row": 6,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B6",
      "value": "Patara Trirat",
      "row": 6,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C6",
      "value": "DeepAuto.ai",
      "row": 6,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D6",
      "value": "https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en",
      "row": 6,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "A7",
      "value": "Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction",
      "row": 7,
      "column": 1,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "B7",
      "value": "Xiang Fu",
      "row": 7,
      "column": 2,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "C7",
      "value": "Fundamental AI Research (FAIR) at Meta",
      "row": 7,
      "column": 3,
      "validation": {
        "has_validation": false
      }
    },
    {
      "address": "D7",
      "value": "https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en",
      "row": 7,
      "column": 4,
      "validation": {
        "has_validation": false
      }
    }
  ]
}
```

</Expandable>
</div>

<div className="thinking-box">
üßê`Agent`

Perfect! I have successfully completed the research task for all 6 papers in your AI Conference research. Here's a summary of what I found and filled in the Excel sheet:

## Research Results Summary:

### 1. **Strategy Coopetition Explains the Emergence and Transience of In-Context Learning**
- **First Author**: Aaditya K. Singh
- **Affiliation**: Gatsby Computational Neuroscience Unit, University College London
- **Google Scholar**: https://scholar.google.com/citations?user=9OPKqmMAAAAJ&hl=en

### 2. **Model Immunization from a Condition Number Perspective**
- **First Author**: Amber Yijia Zheng
- **Affiliation**: Department of Computer Science, Purdue University
- **Google Scholar**: https://scholar.google.com/citations?user=SZQIVG0AAAAJ&hl=zh-CN

### 3. **Flowing Datasets with Wasserstein over Wasserstein Gradient Flows**
- **First Author**: Cl√©ment Bonet
- **Affiliation**: ENSAE, CREST, IP Paris
- **Google Scholar**: https://scholar.google.com/citations?user=wjCPk5kAAAAJ&hl=en

### 4. **Learning with Expected Signatures: Theory and Applications**
- **First Author**: Lorenzo Lucchese
- **Affiliation**: Department of Mathematics, Imperial College London
- **Google Scholar**: https://scholar.google.com/citations?user=-dZCdJoAAAAJ&hl=it

### 5. **AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML**
- **First Author**: Patara Trirat
- **Affiliation**: DeepAuto.ai
- **Google Scholar**: https://scholar.google.com/citations?user=fDZjV8EAAAAJ&hl=en

### 6. **Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction**
- **First Author**: Xiang Fu
- **Affiliation**: Fundamental AI Research (FAIR) at Meta
- **Google Scholar**: https://scholar.google.com/citations?user=Cb-ZgHEAAAAJ&hl=en

All the information has been accurately extracted from the original research papers and verified through the authors' Google Scholar profiles. The Excel sheet now contains the complete research data you requested, with full author names, detailed institutional affiliations exactly as they appear in the papers, and direct links to their Google Scholar profiles.
</div>

<div className="result-box">
<svg width="14px" height="14px" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" style={{margin: 0, padding: 0, display: 'inline-block'}}><path d="M861.588238 240.133873v-65.792823c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.631049H314.659414v-65.631049c0-36.191275-29.439775-65.631049-65.631049-65.63105h-21.877358c-36.191275 0-65.631049 29.439775-65.631049 65.63105v65.792823c-36.317212 0.868255-65.631049 30.539428-65.63105 67.061417v543.745565c0 37.06772 30.155471 67.223191 67.223191 67.223191h696.886045c37.06772 0 67.223191-30.155471 67.223191-67.223191V307.19529c-0.001024-36.52199-29.315885-66.193162-65.633097-67.061417z m-109.385765-65.792823c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m-546.928824 0c0-12.060345 9.817012-21.877358 21.877358-21.877358h21.877358c12.060345 0 21.877358 9.817012 21.877358 21.877358v175.016814c0 12.060345-9.817012 21.877358-21.877358 21.877358h-21.877358c-12.060345 0-21.877358-9.817012-21.877358-21.877358V174.34105z m678.191947 676.600829c0 12.935767-10.532708 23.468476-23.468476 23.468475H163.111076c-12.935767 0-23.468476-10.532708-23.468476-23.468475V307.19529c0-12.402323 9.677764-22.593054 21.877358-23.415233v65.577807c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.631049h393.789368v65.631049c0 36.191275 29.439775 65.631049 65.631049 65.631049h21.877358c36.191275 0 65.631049-29.439775 65.631049-65.631049v-65.577807c12.19857 0.82218 21.877358 11.012911 21.877358 23.415233v543.746589z" fill="#22C67F" /><path d="M706.719439 478.272194l-48.01715-44.741741-182.28128 195.621482-111.468348-122.615387-48.563905 44.148911 159.469116 172.685427z" fill="#74E8AE" /></svg> `claim_done `

<Expandable title="Details">
```json arguments
{}

```

```json output_result
you have claimed the task is done!
```

</Expandable>
</div>

</Accordion>

</AccordionGroup>
